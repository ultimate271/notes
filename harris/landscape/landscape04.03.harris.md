# Chapter 3 - Looking for Belief in the Brain
[Metadata]: # {04.03}
[Descriptor]: # {04.03}
[Author]: # {harris}
Chapter 3
Looking for Belief in the Brain
# Looking for Belief in the Brain
For a physical system to be capable of complex behavior, there must be some
meaningful separation between its input and output. As far as we know, this
separation has been most fully achieved in the frontal lobes of the human
brain. Our frontal lobes are what allow us to select among a vast range of
responses to incoming information in light of our prior goals and present
inferences. Such “higher-level” control of emotion and behavior is the stuff of
which human personalities are made. Clearly, the brain’s capacity to believe or
disbelieve statements of fact—You left your wallet on the bar; that white
powder is anthrax; your boss is in love with you—is central to the initiation,
organization, and control of our most complex behaviors.

But we are not likely to find a region of the human brain devoted solely to
belief. The brain is an evolved organ, and there does not seem to be a process
in nature that allows for the creation of new structures dedicated to entirely
novel modes of behavior or cognition. Consequently, the brain’s higher-order
functions had to emerge from lower-order mechanisms. An ancient structure like
the insula, for instance, helps monitor events in our gut, governing the
perception of hunger and primary emotions like disgust. But it is also involved
in pain perception, empathy, pride, humiliation, trust, music appreciation, and
addictive behavior.16 It may also play an important role in both belief
formation and moral reasoning. Such promiscuity of function is a common feature
of many regions of the brain, especially in the frontal lobes.17

No region of the brain evolved in a neural vacuum or in isolation from the
other mutations simultaneously occurring within the genome. The human mind,
therefore, is like a ship that has been built and rebuilt, plank by plank, on
the open sea. Changes have been made to her sails, keel, and rudder even as the
waves battered every inch of her hull. And much of our behavior and cognition,
even much that now seems essential to our humanity, has not been selected for
at all. There are no aspects of brain function that evolved to hold democratic
elections, to run financial institutions, or to teach our children to read. We
are, in every cell, the products of nature—but we have also been born again and
again through culture. Much of this cultural inheritance must be realized
differently in individual brains. The way in which two people think about the
stock market, or recall that Christmas is a national holiday, or solve a puzzle
like the Tower of Hanoi, will almost surely differ between individuals. This
poses an obvious challenge when attempting to identify mental states with
specific brain states.18

Another factor that makes the strict localization of any mental state difficult
is that the human brain is characterized by massive interconnectivity: it is
mostly talking to itself.19 And the information it stores must also be more
fine-grained than the concepts, symbols, objects, or states that we
subjectively experience. Representation results from a pattern of activity
across networks of neurons and does not generally entail stable, one-to-one
mappings of things/events in the world, or concepts in the mind, to discrete
structures in the brain.20 For instance, thinking a simple thought like Jake is
married cannot be the work of any single node in a network of neurons. It must
emerge from a pattern of connections among many nodes. None of this bodes well
for one who would seek a belief “center” in the human brain.

As part of my doctoral research at UCLA, I studied belief, disbelief, and
uncertainty with functional magnetic resonance imaging (fMRI).21 To do this, we
had volunteers read statements from a wide variety of categories while we
scanned their brains. After reading a proposition like, “California is part of
the United States” or “You have brown hair,” participants would judge them to
be “true,” “false,” or “undecidable” with the click of a button. This was, to
my knowledge, the first time anyone had attempted to study belief and disbelief
with the tools of neuroscience. Consequently, we had no basis to form a
detailed hypothesis about which regions of the brain govern these states of
mind.22 It was, nevertheless, reasonable to expect that the prefrontal cortex
(PFC) would be involved, given its wider role in controlling emotion and
complex behavior.23

The seventeenth-century philosopher Spinoza thought that merely understanding a
statement entails the tacit acceptance of its being true, while disbelief
requires a subsequent process of rejection.24 Several psychological studies
seem to support this conjecture.25 Understanding a proposition may be analogous
to perceiving an object in physical space: we may accept appearances as reality
until they prove otherwise. The behavioral data acquired in our research
support this hypothesis, as subjects judged statements to be “true” more
quickly than they judged them to be “false” or “undecidable.”26

When we compared the mental states of belief and disbelief, we found that
belief was associated with greater activity in the medial prefrontal cortex
(MPFC).27 This region of the frontal lobes is involved in linking factual
knowledge with relevant emotional associations,28 in changing behavior in
response to reward,29 and in goal-based actions.30 The MPFC is also associated
with ongoing reality monitoring, and injuries here can cause people to
confabulate—that is, to make patently false statements without any apparent
awareness that they are not telling the truth.31 Whatever its cause in the
brain, confabulation seems to be a condition in which belief processing has run
amok. The MPFC has often been associated with self-representation,32 and one
sees more activity here when subjects think about themselves than when they
think about others.33

The greater activity we found in the MPFC for belief compared to disbelief may
reflect the greater self-relevance and/or reward value of true statements. When
we believe a proposition to be true, it is as though we have taken it in hand
as part of our extended self: we are saying, in effect, “This is mine. I can
use this. This fits my view of the world.” It seems to me that such cognitive
acceptance has a distinctly positive emotional valence. We actually like the
truth, and we may, in fact, dislike falsehood.34

The involvement of the MPFC in belief processing suggests an anatomical link
between the purely cognitive aspects of belief and emotion/reward. Even judging
the truth of emotionally neutral propositions engaged regions of the brain that
are strongly connected to the limbic system, which governs our positive and
negative affect. In fact, mathematical belief (e.g., “2 + 6 + 8 = 16”) showed a
similar pattern of activity to ethical belief (e.g., “It is good to let your
children know that you love them”), and these were perhaps the most dissimilar
sets of stimuli used in our experiment. This suggests that the physiology of
belief may be the same regardless of a proposition’s content. It also suggests
that the division between facts and values does not make much sense in terms of
underlying brain function.35


Of course, we can differentiate my argument concerning the moral landscape from
my fMRI work on belief. I have argued that there is no gulf between facts and
values, because values reduce to a certain type of fact. This is a
philosophical claim, and as such, I can make it before ever venturing into the
lab. However, my research on belief suggests that the split between facts and
values should look suspicious: First, belief appears to be largely mediated by
the MPFC, which seems to already constitute an anatomical bridge between
reasoning and value. Second, the MPFC appears to be similarly engaged,
irrespective of a belief’s content. This finding of content-independence
challenges the fact/value distinction very directly: for if, from the point of
view of the brain, believing “the sun is a star” is importantly similar to
believing “cruelty is wrong,” how can we say that scientific and ethical
judgments have nothing in common?

And we can traverse the boundary between facts and values in other ways. As we
are about to see, the norms of reasoning seem to apply equally to beliefs about
facts and to beliefs about values. In both spheres, evidence of inconsistency
and bias is always unflattering. Similarities of this kind suggest that there
is a deep analogy, if not identity, between the two domains.

