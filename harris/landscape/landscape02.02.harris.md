# Chapter 1 - The Worst Possible Misery for Everyone
[Metadata]: # {02.02}
[Descriptor]: # {02.02}
[Author]: # {harris}
Chapter 1
The Worst Possible Misery for Everyone
# The Worst Possible Misery for Everyone
I have argued that values only exist relative to actual and potential changes
in the well-being of conscious creatures. However, as I have said, many people
seem to have strange associations with the concept of “well-being”—imagining
that it must be at odds with principles like justice, autonomy, fairness,
scientific curiosity, etc., when it simply isn’t. They also worry that the
concept of “well-being” is poorly defined. Again, I have indicated why I do not
think this is a problem (just as it’s not a problem with concepts like “life”
and “health”). However, it is also useful to notice that a universal morality
can be defined with reference to the negative end of the spectrum of conscious
experience: I refer to this extreme as “the worst possible misery for
everyone.”

Even if each conscious being has a unique nadir on the moral landscape, we can
still conceive of a state of the universe in which everyone suffers as much as
he or she (or it) possibly can. If you think we cannot say this would be “bad,”
then I don’t know what you could mean by the word “bad” (and I don’t think you
know what you mean by it either). Once we conceive of “the worst possible
misery for everyone,” then we can talk about taking incremental steps toward
this abyss: What could it mean for life on earth to get worse for all human
beings simultaneously? Notice that this need have nothing to do with people
enforcing their culturally conditioned moral precepts. Perhaps a neurotoxic
dust could fall to earth from space and make everyone extremely uncomfortable.
All we need imagine is a scenario in which everyone loses a little, or a lot,
without there being compensatory gains (i.e., no one learns any important
lessons, no one profits from others’ losses, etc.). It seems uncontroversial to
say that a change that leaves everyone worse off, by any rational standard, can
be reasonably called “bad,” if this word is to have any meaning at all.

We simply must stand somewhere. I am arguing that, in the moral sphere, it is
safe to begin with the premise that it is good to avoid behaving in such a way
as to produce the worst possible misery for everyone. I am not claiming that
most of us personally care about the experience of all conscious beings; I am
saying that a universe in which all conscious beings suffer the worst possible
misery is worse than a universe in which they experience well-being. This is
all we need to speak about “moral truth” in the context of science. Once we
admit that the extremes of absolute misery and absolute flourishing—whatever
these states amount to for each particular being in the end—are different and
dependent on facts about the universe, then we have admitted that there are
right and wrong answers to questions of morality.22

Granted, genuine ethical difficulties arise when we ask questions like, “How
much should I care about other people’s children? How much should I be willing
to sacrifice, or demand that my own children sacrifice, in order to help other
people in need?” We are not, by nature, impartial—and much of our moral
reasoning must be applied to situations in which there is tension between our
concern for ourselves, or for those closest to us, and our sense that it would
be better to be more committed to helping others. And yet “better” must still
refer, in this context, to positive changes in the experience of sentient
creatures.

Imagine if there were only two people living on earth: we can call them Adam
and Eve. Clearly, we can ask how these two people might maximize their
well-being. Are there wrong answers to this question? Of course. (Wrong answer
number 1: smash each other in the face with a large rock.) And while there are
ways for their personal interests to be in conflict, most solutions to the
problem of how two people can thrive on earth will not be zero-sum. Surely the
best solutions will not be zero-sum. Yes, both of these people could be blind
to the deeper possibilities of collaboration: each might attempt to kill and
eat the other, for instance. Would they be wrong to behave this way? Yes, if by
“wrong” we mean that they would be forsaking far deeper and more durable
sources of satisfaction. It seems uncontroversial to say that a man and woman
alone on earth would be better off if they recognized their common
interests—like getting food, building shelter, and defending themselves against
larger predators. If Adam and Eve were industrious enough, they might realize
the benefits of exploring the world, begetting future generations of humanity,
and creating technology, art, and medicine. Are there good and bad paths to
take across this landscape of possibilities? Of course. In fact, there are, by
definition, paths that lead to the worst misery and paths that lead to the
greatest fulfillment possible for these two people—given the structure of their
respective brains, the immediate facts of their environment, and the laws of
Nature. The underlying facts here are the facts of physics, chemistry, and
biology as they bear on the experience of the only two people in existence.
Unless the human mind is fully separable from the principles of physics,
chemistry, and biology, any fact about Adam and Eve’s subjective experience
(morally salient or not) is a fact about (part of) the universe.23

In talking about the causes of Adam and Eve’s first-person experience, we are
talking about an extraordinarily complex interplay between brain states and
environmental stimuli. However complex these processes are, it is clearly
possible to understand them to a greater or lesser degree (i.e., there are
right and wrong answers to questions about Adam’s and Eve’s well-being). Even
if there are a thousand different ways for these two people to thrive, there
will be many ways for them not to thrive—and the differences between
luxuriating on a peak of well-being and languishing in a valley of internecine
horror will translate into facts that can be scientifically understood. Why
would the difference between right and wrong answers suddenly disappear once we
add 6.7 billion more people to this experiment?


Grounding our values in a continuum of conscious states—one that has the worst
possible misery for everyone at its depths and differing degrees of well-being
at all other points—seems like the only legitimate context in which to conceive
of values and moral norms. Of course, anyone who has an alternative set of
moral axioms is free to put them forward, just as they are free to define
“science” any way they want. But some definitions will be useless, or worse—and
many current definitions of “morality” are so bad that we can know, far in
advance of any breakthrough in the sciences of mind, that they have no place in
a serious conversation about how we should live in this world. The Knights of
the Ku Klux Klan have nothing meaningful to say about particle physics, cell
physiology, epidemiology, linguistics, economic policy, etc. How is their
ignorance any less obvious on the subject of human well-being?24

The moment we admit that consciousness is the context in which any discussion
of values makes sense, we must admit that there are facts to be known about how
the experience of conscious creatures can change. Human and animal well-being
are natural phenomena. As such, they can be studied, in principle, with the
tools of science and spoken about with greater or lesser precision. Do pigs
suffer more than cows do when being led to slaughter? Would humanity suffer
more or less, on balance, if the United States unilaterally gave up all its
nuclear weapons? Questions like these are very difficult to answer. But this
does not mean that they don’t have answers.

The fact that it could be difficult or impossible to know exactly how to
maximize human well-being does not mean that there are no right or wrong ways
to do this—nor does it mean that we cannot exclude certain answers as obviously
bad. For instance, there is often a tension between the autonomy of the
individual and the common good, and many moral problems turn on just how to
prioritize these competing values. However, autonomy brings obvious benefit to
people and is, therefore, an important component of the common good. The fact
that it might be difficult to decide exactly how to balance individual rights
against collective interests, or that there might be a thousand equivalent ways
of doing this, does not mean that there aren’t objectively terrible ways of
doing this. The difficulty of getting precise answers to certain moral
questions does not mean that we must hesitate to condemn the morality of the
Taliban—not just personally, but from the point of view of science. The moment
we admit that we know anything about human well-being scientifically, we must
admit that certain individuals or cultures can be absolutely wrong about it.

