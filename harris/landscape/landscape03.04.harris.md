# Chapter 2 - Fairness and Hierarchy
[Metadata]: # {03.04}
[Descriptor]: # {03.04}
[Author]: # {harris}
Chapter 2
Fairness and Hierarchy
# Fairness and Hierarchy
It is widely believed that focusing on the consequences of a person’s actions
is merely one of several approaches to ethics—one that is beset by paradox and
often impossible to implement. Imagined alternatives are either highly
rational, as in the work of a modern philosopher like John Rawls,40 or
decidedly otherwise, as we see in the disparate and often contradictory
precepts that issue from the world’s major religions.

My reasons for dismissing revealed religion as a source of moral guidance have
been spelled out elsewhere,41 so I will not ride this hobbyhorse here, apart
from pointing out the obvious: (1) there are many revealed religions available
to us, and they offer mutually incompatible doctrines; (2) the scriptures of
many religions, including the most well subscribed (i.e., Christianity and
Islam), countenance patently unethical practices like slavery; (3) the faculty
we use to validate religious precepts, judging the Golden Rule to be wise and
the murder of apostates to be foolish, is something we bring to scripture; it
does not, therefore, come from scripture; (4) the reasons for believing that
any of the world’s religions were “revealed” to our ancestors (rather than
merely invented by men and women who did not have the benefit of a
twenty-first-century education) are either risible or nonexistent—and the idea
that each of these mutually contradictory doctrines is inerrant remains a
logical impossibility. Here we can take refuge in Bertrand Russell’s famous
remark that even if we could be certain that one of the world’s religions was
perfectly true, given the sheer number of conflicting faiths on offer, every
believer should expect damnation purely as a matter of probability.

Among the rational challenges to consequentialism, the “contractualism” of John
Rawls has been the most influential in recent decades. In his book A Theory of
Justice Rawls offered an approach to building a fair society that he considered
an alternative to the aim of maximizing human welfare.42 His primary method,
for which this work is duly famous, was to ask how reasonable people would
structure a society, guided by their self-interest, if they couldn’t know what
sort of person they would be in it. Rawls called this novel starting point “the
original position,” from which each person must judge the fairness of every law
and social arrangement from behind a “veil of ignorance.” In other words, we
can design any society we like as long as we do not presume to know, in
advance, whether we will be black or white, male or female, young or old,
healthy or sick, of high or low intelligence, beautiful or ugly, etc.

As a method for judging questions of fairness, this thought experiment is
undeniably brilliant. But is it really an alternative to thinking about the
actual consequences of our behavior? How would we feel if, after structuring
our ideal society from behind a veil of ignorance, we were told by an
omniscient being that we had made a few choices that, though eminently fair,
would lead to the unnecessary misery of millions, while parameters that were
ever-so-slightly less fair would entail no such suffering? Could we be
indifferent to this information? The moment we conceive of justice as being
fully separable from human well-being, we are faced with the prospect of there
being morally “right” actions and social systems that are, on balance,
detrimental to the welfare of everyone affected by them. To simply bite the
bullet on this point, as Rawls seemed to do, saying “there is no reason to
think that just institutions will maximize the good”43 seems a mere embrace of
moral and philosophical defeat.

Some people worry that a commitment to maximizing a society’s welfare could
lead us to sacrifice the rights and liberties of the few wherever these losses
would be offset by the greater gains of the many. Why not have a society in
which a few slaves are continually worked to death for the pleasure of the
rest? The worry is that a focus on collective welfare does not seem to respect
people as ends in themselves. And whose welfare should we care about? The
pleasure that a racist takes in abusing some minority group, for instance,
seems on all fours with the pleasure a saint takes in risking his life to help
a stranger. If there are more racists than saints, it seems the racists will
win, and we will be obliged to build a society that maximizes the pleasure of
unjust men.

But such concerns clearly rest on an incomplete picture of human well-being. To
the degree that treating people as ends in themselves is a good way to
safeguard human well-being, it is precisely what we should do. Fairness is not
merely an abstract principle—it is a felt experience. We all know this from the
inside, of course, but neuroimaging has also shown that fairness drives
reward-related activity in the brain, while accepting unfair proposals requires
the regulation of negative emotion.44 Taking others’ interests into account,
making impartial decisions (and knowing that others will make them), rendering
help to the needy—these are experiences that contribute to our psychological
and social well-being. It seems perfectly reasonable, within a consequentialist
framework, for each of us to submit to a system of justice in which our
immediate, selfish interests will often be superseded by considerations of
fairness. It is only reasonable, however, on the assumption that everyone will
tend to be better off under such a system. As, it seems, they will.45

While each individual’s search for happiness may not be compatible in every
instance with our efforts to build a just society, we should not lose sight of
the fact that societies do not suffer; people do. The only thing wrong with
injustice is that it is, on some level, actually or potentially bad for
people.46 Injustice makes its victims demonstrably less happy, and it could be
easily argued that it tends to make its perpetrators less happy than they would
be if they cared about the well-being of others. Injustice also destroys trust,
making it difficult for strangers to cooperate. Of course, here we are talking
about the nature of conscious experience, and so we are, of necessity, talking
about processes at work in the brains of human beings. The neuroscience of
morality and social emotions is only just beginning, but there seems no
question that it will one day deliver morally relevant insights regarding the
material causes of our happiness and suffering. While there may be some
surprises in store for us down this path, there is every reason to expect that
kindness, compassion, fairness, and other classically “good” traits will be
vindicated neuroscientifically—which is to say that we will only discover
further reasons to believe that they are good for us, in that they generally
enhance our lives.


We have already begun to see that morality, like rationality, implies the
existence of certain norms—that is, it does not merely describe how we tend to
think and behave; it tells us how we should think and behave. One norm that
morality and rationality share is the interchangeability of perspective.47 The
solution to a problem should not depend on whether you are the husband or the
wife, the employer or employee, the creditor or debtor, etc. This is why one
cannot argue for the rightness of one’s views on the basis of mere preference.
In the moral sphere, this requirement lies at the core of what we mean by
“fairness.” It also reveals why it is generally not a good thing to have a
different ethical code for friends and strangers.

We have all met people who behave quite differently in business than in their
personal lives. While they would never lie to their friends, they might lie
without a qualm to their clients or customers. Why is this a moral failing? At
the very least, it is vulnerable to what could be called the principle of the
unpleasant surprise. Consider what happens to such a person when he discovers
that one of his customers is actually a friend: “Oh, why didn’t you say you
were Jennifer’s sister! Uh … Okay, don’t buy that model; this one is a much
better deal.” Such moments expose a rift in a person’s ethics that is always
unflattering. People with two ethical codes are perpetually susceptible to
embarrassments of this kind. They are also less trustworthy—and trust is a
measure of how much a person can be relied upon to safeguard other people’s
well-being. Even if you happen to be a close friend of such a person—that is,
on the right side of his ethics—you can’t trust him to interact with others you
may care about (“I didn’t know she was your daughter. Sorry about that”).

Or consider the position of a Nazi living under the Third Reich, having fully
committed himself to exterminating the world’s Jews, only to learn, as many
did, that he was Jewish himself. Unless some compelling argument for the moral
necessity of his suicide were forthcoming, we can imagine that it would be
difficult for our protagonist to square his Nazi ethics with his actual
identity. Clearly, his sense of right and wrong was predicated on a false
belief about his own genealogy. A genuine ethics should not be vulnerable to
such unpleasant surprises. This seems another way of arriving at Rawls’s
“original position.” That which is right cannot be dependent upon one’s being a
member of a certain tribe—if for no other reason than one can be mistaken about
the fact of one’s membership.

Kant’s “categorical imperative,” perhaps the most famous prescription in all of
moral philosophy, captures some of these same concerns:



Hence there is only one categorical imperative and it is this: “Act only
according to that maxim whereby you can at the same time will that it should
become a universal law.”48




While Kant believed that this criterion of universal applicability was the
product of pure reason, it appeals to us because it relies on basic intuitions
about fairness and justification.49 One cannot claim to be “right” about
anything—whether as a matter of reason or a matter of ethics—unless one’s views
can be generalized to others.50

