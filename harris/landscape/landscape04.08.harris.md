# Chapter 3 - Do We Have Freedom of Belief?
[Metadata]: # {04.08}
[Descriptor]: # {04.08}
[Author]: # {harris}
Chapter 3
Do We Have Freedom of Belief?
# Do We Have Freedom of Belief?
While belief might prove difficult to pinpoint in the brain, many of its mental
properties are plain to see. For instance, people do not knowingly believe
propositions for bad reasons. If you doubt this, imagine hearing the following
account of a failed New Year’s resolution:



This year, I vowed to be more rational, but by the end of January, I found that
I had fallen back into my old ways, believing things for bad reasons.
Currently, I believe that robbing others is a harmless activity, that my dead
brother will return to life, and that I am destined to marry Angelina Jolie,
just because these beliefs make me feel good.



This is not how our minds work. A belief—to be actually believed—entails the
corollary belief that we have accepted it because it seems to be true. To
really believe a proposition—whether about facts or values—we must also believe
that we are in touch with reality in such a way that if it were not true, one
would not believe it. We must believe, therefore, that we are not flagrantly in
error, deluded, insane, self-deceived, etc. While the preceding sentences do
not suffice as a full account of epistemology, they go a long way toward
uniting science and common sense, as well as reconciling their frequent
disagreements. There can be no doubt that there is an important difference
between a belief that is motivated by an unconscious emotional bias (or other
nonepistemic commitments) and a belief that is comparatively free of such bias.

And yet many secularists and academics imagine that people of faith knowingly
believe things for reasons that have nothing to do with their perception of the
truth. A written debate I had with Philip Ball—who is a scientist, a science
journalist, and an editor at Nature—brought this issue into focus. Ball thought
it reasonable for a person to believe a proposition just because it makes him
“feel better,” and he seemed to think that people are perfectly free to acquire
beliefs in this way. People often do this unconsciously, of course, and such
motivated reasoning has been discussed above. But Ball seemed to think that
beliefs can be consciously adopted simply because a person feels better while
under their spell. Let’s see how this might work. Imagine someone making the
following statement of religious conviction:



I believe Jesus was born of a virgin, was resurrected, and now answers prayers
because believing these things makes me feel better. By adopting this faith, I
am merely exercising my freedom to believe in propositions that make me feel
good.



How would such a person respond to information that contradicted his cherished
belief? Given that his belief is based purely on how it makes him feel, and not
on evidence or argument, he shouldn’t care about any new evidence or argument
that might come his way. In fact, the only thing that should change his view of
Jesus is a change in how the above propositions make him feel. Imagine our
believer undergoing the following epiphany:



For the last few months, I’ve found that my belief in the divinity of Jesus no
longer makes me feel good. The truth is, I just met a Muslim woman who I
greatly admire, and I want to ask her out on a date. As Muslims believe Jesus
was not divine, I am worried that my belief in the divinity of Jesus could
hinder my chances with her. As I do not like feeling this way, and very much
want to go out with this woman, I now believe that Jesus was not divine.



Has a person like this ever existed? I highly doubt it. Why do these thoughts
not make any sense? Because beliefs are intrinsically epistemic: they purport
to represent the world as it is. In this case, our man is making specific
claims about the historical Jesus, about the manner of his birth and death, and
about his special connection to the Creator of the Universe. And yet while
claiming to represent the world in this way, it is perfectly clear that he is
making no effort to stay in touch with the features of the world that should
inform his belief. He is only concerned about how he feels. Given this
disparity, it should be clear that his beliefs are not based on any foundation
that would (or should) justify them to others, or even to himself.

Of course, people do often believe things in part because these beliefs make
them feel better. But they do not do this in the full light of consciousness.
Self-deception, emotional bias, and muddled thinking are facts of human
cognition. And it is a common practice to act as if a proposition were true, in
the spirit of: “I’m going to act on X because I like what it does for me and,
who knows, X might be true.” But these phenomena are not at all the same as
knowingly believing a proposition simply because one wants it to be true.

Strangely, people often view such claims about the constraints of rationality
as a sign of “intolerance.” Consider the following from Ball:



I do wonder what [Sam Harris] is implying here. It is hard to see it as
anything other than an injunction that “you should not be free to choose what
you believe.” I guess that if all Sam means is that we should not leave people
so ill-informed that they have no reasonable basis on which to make those
decisions, then fair enough. But it does seem to go further—to say that “you
should not be permitted to choose what you believe, simply because it makes you
feel better.” Doesn’t this sound a little like a Marxist denouncement of “false
consciousness,” with the implication that it needs to be corrected forthwith? I
think (I hope?) we can at least agree that there are different categories of
belief—that to believe one’s children are the loveliest in the world because
that makes you feel better is a permissible (even laudable) thing. But I
slightly shudder at the notion, hinted here, that a well-informed person should
not be allowed to choose their belief freely … surely we cannot let ourselves
become proscriptive to this degree?70



What cognitive freedom is Ball talking about? I happen to believe that George
Washington was the first president of the United States. Have I, on Ball’s
terms, chosen this belief “freely”? No. Am I free to believe otherwise? Of
course not. I am a slave to the evidence. I live under the lash of historical
opinion. While I may want to believe otherwise, I simply cannot overlook the
incessant pairing of the name “George Washington” with the phrase “first
president of the United States” in any discussion of American history. If I
wanted to be thought an idiot, I could profess some other belief, but I would
be lying. Likewise, if the evidence were to suddenly change—if, for instance,
compelling evidence of a great hoax emerged and historians reconsidered
Washington’s biography, I would be helplessly stripped of my belief—again,
through no choice of my own. Choosing beliefs freely is not what rational minds
do.

This does not mean, of course, that we have no mental freedom whatsoever. We
can choose to focus on certain facts to the exclusion of others, to emphasize
the good rather than the bad, etc. And such choices have consequences for how
we view the world. One can, for instance, view Kim Jong-il as an evil dictator;
one can also view him as a man who was once the child of a dangerous
psychopath. Both statements are, to a first approximation, true. (Obviously,
when I speak about “freedom” and “choices” of this sort, I am not endorsing a
metaphysical notion of “free will.”)

As to whether there are “different categories of belief”: perhaps, but not in
the way that Ball suggests. I happen to have a young daughter who does strike
me as the “loveliest in the world.” But is this an accurate account of what I
believe? Do I, in other words, believe that my daughter is really the loveliest
girl in the world? If I learned that another father thought his daughter the
loveliest in the world, would I insist that he was mistaken? Of course not.
Ball has mischaracterized what a proud (and sane and intellectually honest)
father actually believes. Here is what I believe: I believe that I have a
special attachment to my daughter that largely determines my view of her (which
is as it should be). I fully expect other fathers to have a similar bias toward
their own daughters. Therefore, I do not believe that my daughter is the
loveliest girl in the world in any objective sense. Ball is simply describing
what it’s like to love one’s daughter more than other girls; he is not
describing belief as a representation of the world. What I really believe is
that my daughter is the loveliest girl in the world for me.


One thing that both factual and moral beliefs generally share is the
presumption that we have not been misled by extraneous information.71
Situational variables, like the order in which unrelated facts are presented,
or whether identical outcomes are described in terms of gains or losses, should
not influence the decision process. Of course, the fact that such manipulations
can strongly influence our judgment has given rise to some of the most
interesting work in psychology. However, a person’s vulnerability to such
manipulations is never considered a cognitive virtue; rather, it is a source of
inconsistency that cries out for remedy.

Consider one of the more famous cases from the experimental literature, The
Asian Disease Problem:72



Imagine that the United States is preparing for the outbreak of an unusual
Asian disease, which is expected to kill 600 people. Two alternative programs
to combat the disease have been proposed. Assume that the exact scientific
estimates of the consequences of the programs are as follows:



If Program A is adopted, 200 people will be saved.



If Program B is adopted, there is a one-third probability that 600 people will
be saved and a two-thirds probability that no people will be saved.

Which one of the two programs would you favor?

In this version of the problem, a significant majority of people favor Program
A. The problem, however, can be restated this way:



If Program A is adopted, 400 people will die.



If Program B is adopted, there is a one-third probability that nobody will die
and a two-thirds probability that 600 people will die.



Which one of the two programs would you favor?

Put this way, a majority of respondents will now favor Program B. And yet there
is no material or moral difference between these two scenarios, because their
outcomes are the same. What this shows is that people tend to be risk-averse
when considering potential gains and risk seeking when considering potential
losses, so describing the same event in terms of gains and losses evokes
different responses. Another way of stating this is that people tend to
overvalue certainty: finding the certainty of saving life inordinately
attractive and the certainty of losing life inordinately painful. When
presented with the Asian Disease Problem in both forms, however, people agree
that each scenario merits the same response. Invariance of reasoning, both
logical and moral, is a norm to which we all aspire. And when we catch others
departing from this norm, whatever the other merits of their thinking, the
incoherency of their position suddenly becomes its most impressive
characteristic.

Of course, there are many other ways in which we can be misled by context. Few
studies illustrate this more powerfully than one conducted by the psychologist
David L. Rosenhan,73 in which he and seven confederates had themselves
committed to psychiatric hospitals in five different states in an effort to
determine whether mental health professionals could detect the presence of the
sane among the mentally ill. In order to get committed, each researcher
complained of hearing a voice repeating the words “empty,” “hollow,” and
“thud.” Beyond that, each behaved perfectly normally. Upon winning admission to
the psychiatric ward, the pseudopatients stopped complaining of their symptoms
and immediately sought to convince the doctors, nurses, and staff that they
felt fine and were fit to be released. This proved surprisingly difficult.
While these genuinely sane patients wanted to leave the hospital, repeatedly
declared that they experienced no symptoms, and became “paragons of
cooperation,” their average length of hospitalization was nineteen days
(ranging from seven to fifty-two days), during which they were bombarded with
an astounding range of powerful drugs (which they discreetly deposited in the
toilet). None were pronounced healthy. Each was ultimately discharged with a
diagnosis of schizophrenia “in remission” (with the exception of one who
received a diagnosis of bipolar disorder). Interestingly, while the doctors,
nurses, and staff were apparently blind to the presence of normal people on the
ward, actual mental patients frequently remarked on the obvious sanity of the
researchers, saying things like “You’re not crazy. You’re a journalist.”

In a brilliant response to the skeptics at one hospital who had heard of this
research before it was published, Rosenhan announced that he would send a few
confederates their way and challenged them to spot the coming pseudopatients.
The hospital kept vigil, while Rosenhan, in fact, sent no one. This did not
stop the hospital from “detecting” a steady stream of pseudopatients. Over a
period of a few months fully 10 percent of their new patients were deemed to be
shamming by both a psychiatrist and a member of the staff. While we have all
grown familiar with phenomena of this sort, it is startling to see the
principle so clearly demonstrated: expectation can be, if not everything,
almost everything. Rosenhan concluded his paper with this damning summary: “It
is clear that we cannot distinguish the sane from the insane in psychiatric
hospitals.”


There is no question that human beings regularly fail to achieve the norms of
rationality. But we do not merely fail—we fail reliably. We can, in other
words, use reason to understand, quantify, and predict our violations of its
norms. This has moral implications. We know, for instance, that the choice to
undergo a risky medical procedure will be heavily influenced by whether its
possible outcomes are framed in terms of survival rates or mortality rates. We
know, in fact, that this framing effect is no less pronounced among doctors
than among patients.74 Given this knowledge, physicians have a moral obligation
to handle medical statistics in ways that minimize unconscious bias. Otherwise,
they cannot help but inadvertently manipulate both their patients and one
another, guaranteeing that some of the most important decisions in life will be
unprincipled.75

Admittedly, it is difficult to know how we should treat all of the variables
that influence our judgment about ethical norms. If I were asked, for instance,
whether I would sanction the murder of an innocent person if it would guarantee
a cure for cancer, I would find it very difficult to say “yes,” despite the
obvious consequentialist argument in favor of such an action. If I were asked
to impose a one in a billion risk of death on everyone for this purpose,
however, I would not hesitate. The latter course would be expected to kill six
or seven people, and yet it still strikes me as obviously ethical. In fact,
such a diffusion of risk aptly describes how medical research is currently
conducted. And we routinely impose far greater risks than this on friends and
strangers whenever we get behind the wheel of our cars. If my next drive down
the highway were guaranteed to deliver a cure for cancer, I would consider it
the most ethically important act of my life. No doubt the role that probability
is playing here could be experimentally calibrated. We could ask subjects
whether they would impose a 50 percent chance of death upon two innocent
people, a 10 percent chance on ten innocent people, etc. How we should view the
role that probability plays in our moral judgments is not clear, however. It
seems difficult to imagine ever fully escaping such framing effects.


Science has long been in the values business. Despite a widespread belief to
the contrary, scientific validity is not the result of scientists abstaining
from making value judgments; rather, scientific validity is the result of
scientists making their best effort to value principles of reasoning that link
their beliefs to reality, through reliable chains of evidence and argument.
This is how norms of rational thought are made effective.

To say that judgments of truth and goodness both invoke specific norms seems
another way of saying that they are both matters of cognition, as opposed to
mere sentiment. That is why one cannot defend one’s factual or moral position
by reference to one’s preferences. One cannot say that water is H2O or that
lying is wrong simply because one wants to think this way. To defend such
propositions, one must invoke a deeper principle. To believe that X is true or
that Y is ethical is also to believe others should share these beliefs under
similar circumstances.

The answer to the question “What should I believe, and why should I believe
it?” is generally a scientific one. Believe a proposition because it is well
supported by theory and evidence; believe it because it has been experimentally
verified; believe it because a generation of smart people have tried their best
to falsify it and failed; believe it because it is true (or seems so). This is
a norm of cognition as well as the core of any scientific mission statement. As
far as our understanding of the world is concerned—there are no facts without
values.

