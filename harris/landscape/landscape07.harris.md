# NOTES
[Metadata]: # {07}
[Descriptor]: # {07}
[Author]: # {harris}
NOTES
# NOTES
Introduction: The Moral Landscape



1. Bilefsky, 2008; Mortimer & Toader, 2005.

2. For the purposes of this discussion, I do not intend to make a hard
distinction between “science” and other intellectual contexts in which we
discuss “facts”—e.g., history. For instance, it is a fact that John F. Kennedy
was assassinated. Facts of this kind fall within the context of “science,”
broadly construed as our best effort to form a rational account of empirical
reality. Granted, one doesn’t generally think of events like assassinations as
“scientific” facts, but the murder of President Kennedy is as fully
corroborated a fact as can be found anywhere, and it would betray a profoundly
unscientific frame of mind to deny that it occurred. I think “science,”
therefore, should be considered a specialized branch of a larger effort to form
true beliefs about events in our world.

3. This is not to deny that cultural conceptions of health can play an
important role in determining a person’s experience of illness (more so with
some illnesses than others). There is evidence that American notions of mental
health have begun to negatively affect the way people in other cultures suffer
(Waters, 2010). It has even been argued that, with a condition like
schizophrenia, notions of spirit possession are palliative when compared to
beliefs about organic brain disease. My point, however, is that whatever
contributions cultural differences make to our experience of the world can
themselves be understood, in principle, at the level of the brain.

4. Pollard Sacks, 2009.

5. In the interests of both simplicity and relevance, I tend to keep my
references to religion focused on Christianity, Judaism, and Islam. Of course,
most of what I say about these faiths applies to Hinduism, Buddhism, Sikhism,
and to other religions as well.

6. There are many reasons to be pessimistic about the future of Europe: Ye’or,
2005; Bawer, 2006; Caldwell, 2009.

7. Gould, 1997.

8. Nature 432, 657 (2004).

9. I am not the first person to argue that morality can and should be
integrated with our scientific understanding of the natural world. Of late, the
philosophers William Casebeer and Owen Flanagan have each built similar cases
(Casebeer, 2003; Flanagan, 2007). Both Casebeer and Flanagan have resurrected
Aristotle’s concept of eudaimonia, which is generally translated as
“flourishing,” “fulfillment,” or “well-being.” While I rely heavily on these
English equivalents, I have elected not to pay any attention to Aristotle.
While much of what Aristotle wrote in his Nichomachean Ethics is of great
interest and convergent with the case I wish to make, some of it isn’t. And I’d
rather not be beholden to the quirks of the great man’s philosophy. Both
Casebeer and Flanagan also seem to place greater emphasis on morality as a
skill and a form of practical knowledge, arguing that living a good life is
more a matter of “knowing how” than of “knowing that.” While I think this
distinction is often useful, I’m not eager to give up the fight for moral truth
just yet. For instance, I believe that the compulsory veiling of women in
Afghanistan tends to needlessly immiserate them and will breed a new generation
of misogynistic, puritanical men. This is an instance of “knowing that,” and it
is a truth claim about which I am either right or wrong. I am confident that
both Casebeer and Flanagan would agree. The difference in our approaches,
therefore, seems to me to be more a matter of emphasis. In any case, both
Casebeer and Flanagan go into greater philosophical detail than I have on many
points, and both their books are well worth reading. Flanagan also offered very
helpful notes on an early draft of this book.

10. E. O. Wilson, 1998.

11. Keverne & Curley, 2004; Pedersen, Ascher, Monroe, & Prange, 1982; Smeltzer,
Curtis, Aragona, & Wang, 2006; Young & Wang, 2004.

12. Fries, Ziegler, Kurian, Jacoris, & Pollak, 2005.

13. Hume’s argument was actually directed against religious apologists who
sought to deduce morality from the existence of God. Ironically, his reasoning
has since become one of the primary impediments to linking morality to the rest
of human knowledge. However, Hume’s is/ought distinction has always had its
detractors (e.g., Searle, 1964); here is Dennett:



If “ought” cannot be derived from “is,” just what can it be derived from?…
ethics must be somehow based on an appreciation of human nature—on a sense of
what a human being is or might be, and on what a human being might want to have
or want to be. If that is naturalism, then naturalism is no fallacy (Dennett,
p. 468).

14. Moore [1903], 2004.

15. Popper, 2002, pp. 60–62.

16. The list of scientists who have followed Hume and Moore with perfect
obedience is very long and defies citation. For a recent example within
neuroscience, see Edelman (2006, pp. 84–91).

17. Fodor, 2007.

18. I recently had the pleasure of hearing the philosopher Patricia Churchland
draw this same analogy. (Patricia, I did not steal it!)

19. De Grey & Rae, 2007.

20. The problem with using a strictly hedonic measure of the “good” grows more
obvious once we consider some of the promises and perils of a maturing
neuroscience. If, for instance, we can one day manipulate the brain so as to
render specific behaviors and states of mind more pleasurable than they now
are, it seems relevant to wonder whether such refinements would be “good.” It
might be good to make compassion more rewarding than sexual lust, but would it
be good to make hatred the most pleasurable emotion of all? One can’t appeal to
pleasure as the measure of goodness in such cases, because pleasure is what we
would be choosing to reassign.

21. Pinker, 2002, pp. 53–54.

22. It should be clear that the conventional distinction between “belief” and
“knowledge” does not apply here. As will be made clear in chapter 3, our
propositional knowledge about the world is entirely a matter of “belief” in the
above sense. Whether one chooses to say that one “believes” X or that one
“knows” X is merely a difference of emphasis, expressing one’s degree of
confidence. As discussed in this book, propositional knowledge is a form of
belief. Understanding belief at the level of the brain has been the focus of my
recent scientific research, using functional magnetic resonance imaging (fMRI)
(S. Harris et al., 2009; S. Harris, Sheth, & Cohen, 2008).

23. Edgerton, 1992.

24. Cited in Edgerton, 1992, p. 26.

25. Though perhaps even this attributes too much common sense to the field of
anthropology, as Edgerton (1992, p. 105) tells us: “A prevailing assumption
among anthropologists who study the medical practices of small, traditional
societies is that these populations enjoy good health and nutrition … Indeed,
we are often told that seemingly irrational food taboos, once fully understood,
will prove to be adaptive.”

26. Leher, 2010.

27. Filkins, 2010.

28. For an especially damning look at the Bush administration’s Council on
Bioethics, see Steven Pinker’s response to its 555-page report, Human Dignity
and Bioethics (Pinker, 2008a).

29. S. Harris, 2004, 2006a, 2006b; S. Harris, 2006c; S. Harris, 2007a, 2007b.

30. Judson, 2008; Chris Mooney, 2005.

Chapter 1: Moral Truth



1. In February of 2010, I spoke at the TED conference about how we might one
day understand morality in universal, scientific terms
(www.youtube.com/watch?v=Hj9oB4zpHww). Normally, when one speaks at a
conference the resulting feedback amounts to a few conversations in the lobby
during a coffee break. As luck would have it, however, my TED talk was
broadcast on the internet as I was in the final stages of writing this book,
and this produced a blizzard of useful commentary.

Many of my critics fault me for not engaging more directly with the academic
literature on moral philosophy. There are two reasons why I haven’t done this:
First, while I have read a fair amount of this literature, I did not arrive at
my position on the relationship between human values and the rest of human
knowledge by reading the work of moral philosophers; I came to it by
considering the logical implications of our making continued progress in the
sciences of mind. Second, I am convinced that every appearance of terms like
“metaethics,” “deontology,” “noncognitivism,” “antirealism,” “emotivism,” etc.,
directly increases the amount of boredom in the universe. My goal, both in
speaking at conferences like TED and in writing this book, is to start a
conversation that a wider audience can engage with and find helpful. Few things
would make this goal harder to achieve than for me to speak and write like an
academic philosopher. Of course, some discussion of philosophy will be
unavoidable, but my approach is to generally make an end run around many of the
views and conceptual distinctions that make academic discussions of human
values so inaccessible. While this is guaranteed to annoy a few people, the
professional philosophers I’ve consulted seem to understand and support what I
am doing.

2. Given my experience as a critic of religion, I must say that it has been
quite disconcerting to see the caricature of the overeducated, atheistic moral
nihilist regularly appearing in my inbox and on the blogs. I sincerely hope
that people like Rick Warren have not been paying attention.

3. Searle, 1995, p. 8.

4. There has been much confusion on this point, and most of it is still
influential in philosophical circles. Consider the following from J. L. Mackie:



If there were objective values, then they would be entities or qualities or
relations of a very strange sort, utterly different from anything else in the
universe. Correspondingly, if we were aware of them, it would have to be by
some special faculty of moral perception or intuition, utterly different from
our ordinary ways of knowing everything else (Mackie 1977, p. 38).

Clearly, Mackie has conflated the two senses of the term “objective.” We need
not discuss “entities or qualities or relations of a very strange sort, utterly
different from anything else in the universe” in order to speak about moral
truth. We need only admit that the experiences of conscious creatures are
lawfully dependent upon states of the universe—and, therefore, that actions can
cause more harm than good, more good than harm, or be morally neutral. Good and
evil need only consist in this, and it makes no sense whatsoever to claim that
an action that harms everyone affected by it (even its perpetrator) might still
be “good.” We do not require a metaphysical repository of right and wrong, or
actions that are mysteriously right or wrong in themselves, for there to be
right and wrong answers to moral questions; we simply need a landscape of
possible experiences that can be traversed in some orderly way in light of how
the universe actually is. The main criterion, therefore, is that misery and
well-being not be completely random. It seems to me that we already know that
they are not—and, therefore, that it is possible for a person to be right or
wrong about how to move from one state to the other.

5. Is it always wrong to slice open a child’s belly with a knife? No. One might
be performing an emergency appendectomy.

6. One could respond by saying that scientists agree about science more than
ordinary people agree about morality (I’m not sure this is true). But this is
an empty claim, for at least two reasons: (1) it is circular, because anyone
who insufficiently agrees with the majority opinion in any domain of science
won’t count as a “scientist” (so the definition of scientist is question
begging); (2) Scientists are an elite group, by definition. “Moral experts”
would also constitute an elite group, and the existence of such experts is
completely in line with my argument.

7. Obvious exceptions include “socially constructed” phenomena that require
some degree of consensus to be made real. The paper in my pocket really is
“money”—but it is only money because a sufficient number of people are willing
to treat it as such (see Searle, 1995).

8. Practically speaking, I think we have some very useful intuitions on this
front. We care more about creatures that can experience a greater range of
suffering and happiness—and we are right to, because suffering and happiness
(defined in the widest possible sense) are all that can be cared about. Are all
animal lives equivalent? No. Do monkeys suffer more than mice from medical
experiments? If so, all other things being equal, it is worse to run
experiments on monkeys than on mice.

Are all human lives equivalent? No. I have no problem admitting that certain
people’s lives are more valuable than mine (I need only imagine a person whose
death would create much greater suffering and prevent much greater happiness).
However, it also seems quite rational for us to collectively act as though all
human lives were equally valuable. Hence, most of our laws and social
institutions generally ignore differences between people. I suspect that this
is a very good thing. Of course, I could be wrong about this—and that is
precisely the point. If we didn’t behave this way, our world would be
different, and these differences would either affect the totality of human
well-being, or they wouldn’t. Once again, there are answers to such questions,
whether we can ever answer them in practice.

9. At bottom, this is purely a semantic point: I am claiming that whatever
answer a person gives to the question “Why is religion important?” can be
framed in terms of a concern about someone’s well-being (whether misplaced or
not).

10. I do not think that the moral philosophy of Immanuel Kant represents an
exception either. Kant’s categorical imperative only qualifies as a rational
standard of morality given the assumption that it will be generally beneficial
(as J. S. Mill pointed out at the beginning of Utilitarianism). One could
argue, therefore, that what is serviceable in Kant’s moral philosophy amounts
to a covert form of consequentialism. I offer a few more remarks about Kant’s
categorical imperative below.

11. For instance, many people assume that an emphasis on human “well-being”
would lead us to do terrible things like reinstate slavery, harvest the organs
of the poor, periodically nuke the developing world, or nurture our children on
a continuous drip of heroin. Such expectations are the result of not thinking
about these issues seriously. There are rather clear reasons not to do these
things—all of which relate to the immensity of suffering that such actions
would cause and the possibilities of deeper happiness that they would
foreclose. Does anyone really believe that the highest possible state of human
flourishing is compatible with slavery, organ theft, and genocide?

12. Are there trade-offs and exceptions? Of course. There may be circumstances
in which the very survival of a community requires that certain of these
principles be violated. But this doesn’t mean that they aren’t generally
conducive to human well-being.

13. Stewart, 2008.

14. I confess that, as a critic of religion, I have paid too little attention
to the sexual abuse scandal in the Catholic Church. Frankly, it felt somehow
unsportsmanlike to shoot so large and languorous a fish in so tiny a barrel.
This scandal was one of the most spectacular “own goals” in the history of
religion, and there seemed to be no need to deride faith at its most vulnerable
and self-abased. Even in retrospect, it is easy to understand the impulse to
avert one’s eyes: Just imagine a pious mother and father sending their beloved
child to the Church of a Thousand Hands for spiritual instruction, only to have
him raped and terrified into silence by threats of hell. And then imagine this
occurring to tens of thousands of children in our own time—and to children
beyond reckoning for over a thousand years. The spectacle of faith so utterly
misplaced, and so fully betrayed, is simply too depressing to think about.

But there was always more to this phenomenon that should have compelled my
attention. Consider the ludicrous ideology that made it possible: the Catholic
Church has spent two millennia demonizing human sexuality to a degree unmatched
by any other institution, declaring the most basic, healthy, mature, and
consensual behaviors taboo. Indeed, this organization still opposes the use of
contraception: preferring, instead, that the poorest people on earth be blessed
with the largest families and the shortest lives. As a consequence of this
hallowed and incorrigible stupidity, the Church has condemned generations of
decent people to shame and hypocrisy—or to Neolithic fecundity, poverty, and
death by AIDS. Add to this inhumanity the artifice of cloistered celibacy, and
you now have an institution—one of the wealthiest on earth—that preferentially
attracts pederasts, pedophiles, and sexual sadists into its ranks, promotes
them to positions of authority, and grants them privileged access to children.
Finally, consider that vast numbers of children will be born out of wedlock,
and their unwed mothers vilified, wherever Church teaching holds sway—leading
boys and girls by the thousands to be abandoned to Church-run orphanages only
to be raped and terrorized by the clergy. Here, in this ghoulish machinery set
to whirling through the ages by the opposing winds of shame and sadism, we
mortals can finally glimpse how strangely perfect are the ways of the Lord.

In 2009, the Irish Commission to Inquire into Child Abuse (CICA) investigated
such of these events as occurred on Irish soil. Their report runs to 2,600
pages (www.childabusecommission.com/rpt/). Having read only an oppressive
fraction of this document, I can say that when thinking about the
ecclesiastical abuse of children, it is best not to imagine shades of ancient
Athens and the blandishments of a “love that dare not speak its name.” Yes,
there have surely been polite pederasts in the priesthood, expressing anguished
affection for boys who would turn eighteen the next morning. But behind these
indiscretions there is a continuum of abuse that terminates in absolute evil.
The scandal in the Catholic Church—one might now safely say the scandal that is
the Catholic Church—includes the systematic rape and torture of orphaned and
disabled children. Its victims attest to being whipped with belts and sodomized
until bloody—sometimes by multiple attackers—and then whipped again and
threatened with death and hellfire if they breathed a word about their abuse.
And yes, many of the children who were desperate or courageous enough to report
these crimes were accused of lying and returned to their tormentors to be raped
and tortured again.

The evidence suggests that the misery of these children was facilitated and
concealed by the hierarchy of the Catholic Church at every level, up to and
including the prefrontal cortex of the current pope. In his former capacity as
Cardinal Ratzinger, Pope Benedict personally oversaw the Vatican’s response to
reports of sexual abuse in the Church. What did this wise and compassionate man
do upon learning that his employees were raping children by the thousands? Did
he immediately alert the police and ensure that the victims would be protected
from further torments? One still dares to imagine such an effulgence of basic
human sanity might have been possible, even within the Church. On the contrary,
repeated and increasingly desperate complaints of abuse were set aside,
witnesses were pressured into silence, bishops were praised for their defiance
of secular authority, and offending priests were relocated only to destroy
fresh lives in unsuspecting parishes. It is no exaggeration to say that for
decades (if not centuries) the Vatican has met the formal definition of a
criminal organization devoted—not to gambling, prostitution, drugs, or any
other venial sin—but to the sexual enslavement of children. Consider the
following passages from the CICA report:



7.129 In relation to one School, four witnesses gave detailed accounts of
sexual abuse, including rape in all instances, by two or more Brothers and on
one occasion along with an older resident. A witness from the second School,
from which there were several reports, described being raped by three Brothers:
“I was brought to the infirmary … they held me over the bed, they were animals.
… They penetrated me, I was bleeding.” Another witness reported he was abused
twice weekly on particular days by two Brothers in the toilets off the
dormitory:



One Brother kept watch while the other abused me … [sexually]… then they
changed over. Every time it ended with a severe beating. When I told the priest
in Confession, he called me a liar. I never spoke about it again.



I would have to go into his … [Br X’s] … room every time he wanted. You’d get a
hiding if you didn’t, and he’d make me do it … [masturbate] … to him. One night
I didn’t … [masturbate him] … and there was another Brother there who held me
down and they hit me with a hurley and they burst my fingers … [displayed
scar].…



7.232 Witnesses reported being particularly fearful at night as they listened
to residents screaming in cloakrooms, dormitories or in a staff member’s
bedroom while they were being abused. Witnesses were conscious that
co-residents whom they described as orphans had a particularly difficult time:



The orphan children, they had it bad. I knew … [who they were]… by the size of
them, I’d ask them and they’d say they come from … named institution. … They
were there from an early age. You’d hear the screams from the room where Br … X
… would be abusing them.



There was one night, I wasn’t long there and I seen one of the Brothers on the
bed with one of the young boys … and I heard the young lad screaming crying and
Br … X … said to me “if you don’t mind your own business you’ll get the same.”…
I heard kids screaming and you know they are getting abused and that’s a
nightmare in anybody’s mind. You are going to try and break out. … So there was
no way I was going to let that happen to me … I remember one boy and he was
bleeding from the back passage and I made up my mind, there was no way it …
[anal rape]… was going to happen to me. … That used to play on my mind.

This is the kind of abuse that the Church has practiced and concealed since
time out of memory. Even the CICA report declined to name the offending
priests.

I have been awakened from my unconscionable slumber on this issue by recent
press reports (Goodstein and Callender, 2010; Goodstein, 2010a, 2010b; Donadio,
2010a, 2010b; Wakin and McKinley Jr., 2010), and especially by the eloquence of
my colleagues Christopher Hitchens (2010a, 2010b, 2010c, and 2010d), and
Richard Dawkins (2010a, 2010b).

15. The Church even excommunicated the girl’s mother
(http://news.bbc.co.uk/2/hi/americas/7930380.stm).

16. The philosopher Hilary Putnam (2007) has argued that facts and values are
“entangled.” Scientific judgments presuppose “epistemic values”—coherence,
simplicity, beauty, parsimony, etc. Putnam has pointed out, as I do here, that
all the arguments against the existence of moral truth could be applied to
scientific truth without any change.

17. Many people find the idea of “moral experts” abhorrent. Indeed, this
ramification of my argument has been called “positively Orwellian” and a
“recipe for fascism.” Again, these concerns seem to arise from an uncanny
reluctance to think about what the concept of “well-being” actually entails or
how science might shed light on its causes and conditions. The analogy with
health seems important to keep in view: Is there anything “Orwellian” about the
scientific consensus on the link between smoking and lung cancer? Has the
medical community’s insistence that people should not smoke led to “fascism”?
Many people’s reflexive response to the notion of moral expertise is to say, “I
don’t want anyone telling me how to live my life.” To which I can only respond,
“If there were a way for you and those you care about to be much happier than
you now are, would you want to know about it?”

18. This is the subject of that now infamous quotation from Albert Einstein,
endlessly recycled by religious apologists, claiming that “science without
religion is lame, religion without science is blind.” Far from indicating his
belief in God, or his respect for unjustified belief, Einstein was speaking
about the primitive urge to understand the universe, along with the “faith”
that such understanding is possible:



Though religion may be that which determines the goal, it has, nevertheless,
learned from science, in the broadest sense, what means will contribute to the
attainment of the goals it has set up. But science can only be created by those
who are thoroughly imbued with the aspiration toward truth and understanding.
This source of feeling, however, springs from the sphere of religion. To this
there also belongs the faith in the possibility that the regulations valid for
the world of existence are rational, that is, comprehensible to reason. I
cannot conceive of a genuine scientist without that profound faith. This
situation may be expressed by an image: science without religion is lame,
religion without science is blind (Einstein, 1954, p. 49).



19. These impasses are seldom as insurmountable as skeptics imagine. For
instance, Creationist “scientists” can be led to see that the very standards of
reasoning they use to vindicate scripture in light of empirical data also
reveal hundreds of inconsistencies within scripture—thereby undermining their
entire project. The same is true for moral impasses: those who claim to get
their morality from God, without reference to any terrestrial concerns, are
often susceptible to such concerns in the end. In an extreme case, the New York
Times correspondent Thomas Friedman once reported meeting a Sunni militant who
had begun fighting alongside the American military against al-Qaeda in Iraq,
having been persuaded that the infidel troops were the lesser of two evils.
What convinced him? He witnessed a member of al-Qaeda decapitate an
eight-year-old girl (Friedman, 2007). It would seem, therefore, that the
boundary between the crazy values of Islam and the utterly crazy can be
discerned when drawn in the spilled blood of little girls. This is a basis for
hope, of sorts.

In fact, I think that morality will be on firmer ground than any other branch
of science in the end, since scientific knowledge is only valuable because it
contributes to our well-being. Of course, we must include among these
contributions the claims of people who say that they value knowledge “for its
own sake”—for they are merely describing the mental pleasure that comes with
understanding the world, solving problems, etc. It is clear that well-being
must take precedence over knowledge, because we can easily imagine situations
in which it would be better not to know the truth, or when false knowledge
would be desirable. No doubt, there are circumstances in which religious
delusion functions in this way: where, for instance, soldiers are vastly
outnumbered on the battlefield but, being ignorant of the odds against them and
convinced that God is on their side, they manage to draw on emotional resources
that would be unavailable to people with complete information and fully
justified beliefs. However, the fact that a combination of ignorance and false
knowledge can occasionally be helpful is no argument for the general utility of
religious faith (much less for its truth). Indeed, the great weakness of
religion, apart from the obvious implausibility of its doctrines, is that the
cost of holding irrational and divisive beliefs on a global scale is
extraordinarily high.

20. The physicist Sean Carroll finds Hume’s analysis of facts and values so
compelling that he elevates it to the status of mathematical truth:



Attempts to derive ought from is are like attempts to reach an odd number by
adding together even numbers. If someone claims that they’ve done it, you don’t
have to check their math; you know that they’ve made a mistake (Carroll,
2010a).



21. This spurious notion of “ought” can be introduced into any enterprise and
seem to plant a fatal seed of doubt. Asking why we “ought” to value well-being
makes even less sense than asking why we “ought” to be rational or scientific.
And while it is possible to say that one can’t move from “is” to “ought,” we
should be honest about how we get to “is” in the first place. Scientific “is”
statements rest on implicit “oughts” all the way down. When I say, “Water is
two parts hydrogen and one part oxygen,” I have uttered a quintessential
statement of scientific fact. But what if someone doubts this statement? I can
appeal to data from chemistry, describing the outcome of simple experiments.
But in so doing, I implicitly appeal to the values of empiricism and logic.
What if my interlocutor doesn’t share these values? What can I say then? As it
turns out, this is the wrong question. The right question is, why should we
care what such a person thinks about chemistry?

So it is with the linkage between morality and well-being: To say that morality
is arbitrary (or culturally constructed, or merely personal) because we must
first assume that the well-being of conscious creatures is good, is like saying
that science is arbitrary (or culturally constructed, or merely personal)
because we must first assume that a rational understanding of the universe is
good. Yes, both endeavors rest on assumptions (and, as I have said, I think the
former will prove to be more firmly grounded), but this is not a problem. No
framework of knowledge can withstand utter skepticism, for none is perfectly
self-justifying. Without being able to stand entirely outside of a framework,
one is always open to the charge that the framework rests on nothing, that its
axioms are wrong, or that there are foundational questions it cannot answer.
Occasionally some of our basic assumptions do turn out to be wrong or limited
in scope—e.g., the parallel postulate of Euclidean geometry does not apply to
geometry as a whole—but these errors can be detected only by the light of other
assumptions that stand firm.

Science and rationality generally are based on intuitions and concepts that
cannot be reduced or justified. Just try defining “causation” in noncircular
terms. Or try justifying transitivity in logic: if A = B and B = C, then A = C.
A skeptic could say, “This is nothing more than an assumption that we’ve built
into the definition of ‘equality.’ Others will be free to define ‘equality’
differently.” Yes, they will. And we will be free to call them “imbeciles.”
Seen in this light, moral relativism—the view that the difference between right
and wrong has only local validity within a specific culture—should be no more
tempting than physical, biological, mathematical, or logical relativism. There
are better and worse ways to define our terms; there are more and less coherent
ways to think about reality; and there are—is there any doubt about this?—many
ways to seek fulfillment in this life and to not find it.

22. We can, therefore, let this metaphysical notion of “ought” fall away, and
we will be left with a scientific picture of cause and effect. To the degree
that it is in our power to produce the worst possible misery for everyone in
this universe, we can say that if we don’t want everyone to experience the
worst possible misery, we shouldn’t do X. Can we readily conceive of someone
who might hold altogether different values and want all conscious beings,
himself included, reduced to the state of worst possible misery? I don’t think
so. And I don’t think we can intelligibly ask questions like, “What if the
worst possible misery for everyone is actually good?” Such questions seem
analytically confused. We can also pose questions like “What if the most
perfect circle is really a square?” or “What if all true statements are
actually false?” But if someone persists in speaking this way, I see no
obligation to take his views seriously.

23. And even if minds were independent of the physical universe, we could still
speak about facts relative to their well-being. But we would be speaking about
some other basis for these facts (souls, disembodied consciousness, ectoplasm,
etc.).

24. On a related point, the philosopher Russell Blackford wrote in response to
my TED talk, “I’ve never yet seen an argument that shows that psychopaths are
necessarily mistaken about some fact about the world. Moreover, I don’t see how
the argument could run.” While I discuss psychopathy in greater detail in the
next chapter, here is such an argument in brief: We already know that
psychopaths have brain damage that prevents them from having certain deeply
satisfying experiences (like empathy) that seem good for people both personally
and collectively (in that they tend to increase well-being on both counts).
Psychopaths, therefore, don’t know what they are missing (but we do). The
position of a psychopath also cannot be generalized; it is not, therefore, an
alternative view of how human beings should live (this is one point Kant got
right: even a psychopath couldn’t want to live in a world filled with
psychopaths). We should also realize that the psychopath we are envisioning is
a straw man: watch interviews with real psychopaths, and you will find that
they do not tend to claim to be in possession of an alternative morality or to
be living deeply fulfilling lives. These people are generally ruled by
compulsions that they don’t understand and cannot resist. It is absolutely
clear that, whatever they might believe about what they are doing, psychopaths
are seeking some form of well-being (excitement, ecstasy, feelings of power,
etc.), but because of their neurological and social deficits, they are doing a
very bad job of it. We can say that a psychopath like Ted Bundy takes
satisfaction in the wrong things, because living a life purposed toward raping
and killing women does not allow for deeper and more generalizable forms of
human flourishing. Compare Bundy’s deficits to those of a delusional physicist
who finds meaningful patterns and mathematical significance in the wrong
places. The mathematician John Nash, while suffering the symptoms of his
schizophrenia, seems a good example: his “Eureka!” detectors were poorly
calibrated; he saw meaningful patterns where his peers would not—and these
patterns were a very poor guide to the proper goals of science (i.e.,
understanding the physical world). Is there any doubt that Ted Bundy’s “Yes! I
love this!” detectors were poorly coupled to the possibilities of finding deep
fulfillment in this life, or that his obsession with raping and killing young
women was a poor guide to the proper goals of morality (i.e., living a
fulfilling life with others)?

While people like Bundy may want some very weird things out of life, no one
wants utter, interminable misery. People with apparently different moral codes
are still seeking forms of well-being that we recognize—like freedom from pain,
doubt, fear, etc.—and their moral codes, however vigorously they might want to
defend them, are undermining their well-being in obvious ways. And if someone
claims to want to be truly miserable, we are free to treat them like someone
who claims to believe that 2 + 2 = 5 or that all events are self-caused. On the
subject of morality, as on every other subject, some people are not worth
listening to.

25. From the White House press release: www.bioethics.gov/about/creation.html.

26. Oxytocin is a neuroactive hormone that appears to govern social recognition
in animals and the experience of trust (and its reciprocation) in humans (Zak,
Kurzban, & Matzner, 2005; Zak, Stanton, & Ahmadi, 2007).

27. Appiah, 2008, p. 41.

28. The Stanford Encyclopedia of Philosophy has this to say on the subject of
moral relativism:



In 1947, on the occasion of the United Nations debate about universal human
rights, the American Anthropological Association issued a statement declaring
that moral values are relative to cultures and that there is no way of showing
that the values of one culture are better than those of another.
Anthropologists have never been unanimous in asserting this, and in recent
years human rights advocacy on the part of some anthropologists has mitigated
the relativist orientation of the discipline. Nonetheless, prominent
contemporary anthropologists such as Clifford Geertz and Richard A. Shweder
continue to defend relativist positions.
http://plato.stanford.edu/entries/moral-relativism/.



1947? Please note that this was the best the social scientists in the United
States could do with the crematoria of Auschwitz still smoking. My spoken and
written collisions with Richard Shweder, Scott Atran, Mel Konner, and other
anthropologists have convinced me that awareness of moral diversity does not
entail, and is a poor surrogate for, clear thinking about human well-being.

29. Pinker, 2002, p. 273.

30. Harding, 2001.

31. For a more complete demolition of feminist and multicultural critiques of
Western science, see P. R. Gross, 1991; P. R. Gross & Levitt, 1994.

32. Weinberg, 2001, p. 105.

33. Dennett, 1995.

34. Ibid., p. 487.

35. See, for instance, M. D. Hauser, 2006. Experiments show that even
eight-month-old infants want to see aggressors punished (Bloom, 2010).

36.

ww.gallup.com/poll/118378/Majority-Americans-Continue-Oppose-Gay-Marriage.aspx.

37. There is now a separate field called “neuroethics,” formed by a confluence
of neuroscience and philosophy, which loosely focuses on matters of this sort.
Neuroethics is more than bioethics with respect to the brain (that is, it is
more than an ethical framework for the conduct of neuroscience): it encompasses
our efforts to understand ethics itself as a biological phenomenon. There is a
quickly growing literature on neuroethics (recent, book-length introductions
can be found in Gazzaniga, 2005, and Levy, 2007), and there are other
neuroethical issues that are relevant to this discussion: concerns about mental
privacy, lie detection, and the other implications of an advancing science of
neuroimaging; personal responsibility in light of deterministic and random
processes in the brain (neither of which lend any credence to common notions of
“free will”); the ethics of emotional and cognitive enhancement; the
implications of understanding “spiritual” experience in physical terms; etc.

Chapter 2: Good and Evil



1. Consider, for instance, how much time and money we spend to secure our
homes, places of business, and cars against unwanted entry (and to have doors
professionally unlocked when keys are lost). Consider the cost of internet and
credit card security, and the time dissipated in the use and retrieval of
passwords. When phone service is interrupted for five minutes in a modern
society the cost is measured in billions of dollars. I think it safe to say
that the costs of preventing theft are far higher. Add to the expense of
locking doors, the pains we take to prepare formal contracts—locks of another
sort—and the costs soar beyond all reckoning. Imagine a world that had no need
for such prophylactics against theft (admittedly, it is difficult). It would be
a world of far greater disposable wealth (measured in both time and money).

2. There are other ways of thinking about human cooperation, including politics
and law, but I take the normative claims of ethics to be foundational.

3. Hamilton, 1964a, 1964b.

4. McElreath & Boyd, 2007, p. 82.

5. Trivers, 1971.

6. G. F. Miller, 2007.

7. For a recent review that also looks at the phenomenon of indirect
reciprocity (i.e., A gives to B; and then B gives to C, or C gives to A, or
both), see Nowak, 2005. For doubts about the sufficiency of kin selection and
reciprocal altruism to account for cooperation—especially among eusocial
insects—see D. S. Wilson & Wilson, 2007; E. O. Wilson, 2005.

8. Tomasello, 2007.

9. Smith, [1759] 1853, p. 3.

10. Ibid. pp. 192–193.

11. Benedict, 1934, p. 172.

12. Consequentialism has undergone many refinements since the original
utilitarianism of Jeremy Bentham and John Stuart Mill. My discussion will
ignore most of these developments, as they are generally of interest only to
academic philosophers. The Stanford Encyclopedia of Philosophy provides a good
summary article (Sinnott-Armstrong, 2006).

13. J. D. Greene, 2007; J. D. Greene, Nystrom, Engell, Darley, & Cohen, 2004;
J. D. Greene, Sommerville, Nystrom, Darley, & Cohen, 2001.

14. J. D. Greene, 2002, pp. 59–60.

15. Ibid., pp. 204–205.

16. Ibid., p. 264.

17. Let us briefly cover a few more philosophical bases: What would have to be
true for a practice like the forced veiling of women to be objectively wrong?
Would this practice have to cause unnecessary suffering in all possible worlds?
No. It only need cause unnecessary suffering in this world. Must it be
analytically true that compulsory veiling is immoral—that is, must the
wrongness of the act be built into the meaning of the word “veil”? No. Must it
be true a priori—that is, must this practice be wrong independent of human
experience? No. The wrongness of the act very much depends on human experience.
It is wrong to force women and girls to wear burqas because it is unpleasant
and impractical to live fully veiled, because this practice perpetuates a view
of women as being the property of men, and because it keeps the men who enforce
it brutally obtuse to the possibility of real equality and communication
between the sexes. Hobbling half of the population also directly subtracts from
the economic, social, and intellectual wealth of a society. Given the
challenges that face every society, this is a bad practice in almost every
case. Must compulsory veiling be ethically unacceptable without exception in
our world? No. We can easily imagine situations in which forcing one’s daughter
to wear a burqa could be perfectly moral—perhaps to escape the attention of
thuggish men while traveling in rural Afghanistan. Does this slide from brute,
analytic, a priori, and necessary truth to synthetic, a posteriori, contingent,
exception-ridden truth pose a problem for moral realism? Recall the analogy I
drew between morality and chess. Is it always wrong to surrender your Queen in
a game of chess? No. But generally speaking, it is a terrible idea. Even
granting the existence of an uncountable number of exceptions to this rule,
there are still objectively good and objectively bad moves in every game of
chess. Are we in a position to say that the treatment of women in traditional
Muslim societies is generally bad? Absolutely we are. Should there be any
doubt, I recommend that readers consult Ayaan Hirsi Ali’s several fine books on
the subject (A. Hirsi Ali, 2006, 2007, 2010).

18. J. D. Greene, 2002, pp. 287–288.

19. The philosopher Richard Joyce (2006) has argued that the evolutionary
origins of moral beliefs undermine them in ways that the evolutionary origins
of mathematical and scientific beliefs do not. I do not find his reasoning
convincing, however. For instance, Joyce asserts that our mathematical and
scientific intuitions could have been selected for only by virtue of their
accuracy, whereas our moral intuitions were selected for based on an entirely
different standard. In the case of arithmetic (which he takes as his model),
this may seem plausible. But science has progressed by violating many (if not
most) of our innate, proto-scientific intuitions about the nature of reality.
By Joyce’s reasoning, we should view these violations as a likely step away
from the Truth.

20. Greene’s argument actually seems somewhat peculiar. Consequentialism is not
true, because there is simply too much diversity of opinion about morality; but
he seems to believe that most people will converge on consequentialist
principles if given enough time to reflect.

21. Faison, 1996.

22. Dennett, 1995, p. 498.

23. Churchland, 2008a.

24. Slovic, 2007.

25. This seems related to a more general finding in the reasoning literature,
in which people are often found to put more weight on a salient anecdote than
on large-sample statistics (Fong, Krantz, & Nisbett, 1986/07; Stanovich & West,
2000). It also appears to be an especially perverse version of what Kahneman
and Frederick call “extension neglect” (Kahneman & Frederick, 2005): where our
valuations reliably fail to increase with the size of a problem. For instance,
the value most people will place on saving 2,000 lives will be less than twice
as large as the value they will place on 1,000 lives. Slovic’s result, however,
suggests that it could be less valuable (even if the larger group contained the
smaller). If ever there were a nonnormative result in moral psychology, this is
it.

26. There may be some exceptions to this principle: for instance, if you
thought that either child would suffer intolerably if the other died, you might
believe that both dying would be preferable than one dying. Whether such cases
actually exist, they are clearly exceptions to the general rule that negative
consequences should be additive.

27. Does this sound crazy? Jane McGonigal designs games with such real-world
outcomes in mind: www.iftf.org/user/46.

28. Parfit, 1984.

29. While Parfit’s argument is rightfully celebrated, and Reasons and Persons
is a philosophical masterpiece, a very similar observation first appears in
Rawls, [1971] 1999, pp. 140–141.

30. For instance:



How Only France Survives. In one possible future, the worst-off people in the
world soon start to have lives that are well worth living. The quality of life
in different nations then continues to rise. Though each nation has its fair
share of the world’s resources, such things as climate and cultural traditions
give to some nations a higher quality of life. The best-off people, for many
centuries, are the French.





In another possible future, a new infectious disease makes nearly everyone
sterile. French scientists produce just enough of an antidote for all of
France’s population. All other nations cease to exist. This has some bad
effects on the quality of life for the surviving French. Thus there is no new
foreign art, literature, or technology that the French can import. These and
other bad effects outweigh any good effects. Throughout this second possible
future the French therefore have a quality of life that is slightly lower than
it would be in the first possible future (Parfit, ibid., p. 421).

31. P. Singer, 2009, p. 139.

32. Graham Holm, 2010.

33. Kahneman, 2003.

34. LaBoeuf & Shafir, 2005.

35. Tom, Fox, Trepel, & Poldrack, 2007. But as the authors note, this protocol
examined the brain’s appraisal of potential loss (i.e., decision utility)
rather than experienced losses, where other studies suggest that negative
affect and associated amygdala activity can be expected.

36. Pizarro and Uhlmann make a similar observation (D. A. Pizarro & Uhlmann,
2008).

37. Redelmeier, Katz, & Kahneman, 2003.

38. Schreiber & Kahneman, 2000.

39. Kahneman, 2003.

40. Rawls, [1971] 1999; Rawls & Kelly, 2001.

41. S. Harris, 2004, 2006a, 2006d.

42. He later refined his view, arguing that justice as fairness must be
understood as “a political conception of justice rather than as part of a
comprehensive moral doctrine” (Rawls & Kelly, 2001, p. xvi).

43. Rawls, [1971] 1999, p. 27.

44. Tabibnia, Satpute, & Lieberman, 2008.

45. It is not unreasonable, therefore, to expect people who are seeking to
maximize their well-being to also value fairness. Valuing fairness, they will
tend to view its breach as less than ethical—that is, as not being conducive to
their collective well-being. But what if they don’t? What if the laws of nature
allow for different and seemingly antithetical peaks on the moral landscape?
What if there is a possible world in which the Golden Rule has become an
unshakable instinct, while there is another world of equivalent happiness where
the inhabitants reflexively violate it? Perhaps this is a world of perfectly
matched sadists and masochists. Let’s assume that in this world every person
can be paired, one-for-one, with the saints in the first world, and while they
are different in every other way, these pairs are identical in every way
relevant to their well-being. Stipulating all these things, the
consequentialist would be forced to say that these worlds are morally
equivalent. Is this a problem? I don’t think so. The problem lies in how many
details we have been forced to ignore in the process of getting to this point.
What possible reason do we have to worry that the principles of human
well-being are this elastic? This is like worrying that there is a possible
world in which the laws of physics, while as consistent as they are in our
world, are completely antithetical to physics as we know it. Okay, what if?
Exactly how much should this possibility concern us as we try to predict the
behavior of matter in our world?

And the Kantian commitment to viewing people as ends in themselves, while a
very useful moral principle, is difficult to map onto the world with precision.
Not only are the boundaries between self and world hard to define, one’s
individuality with respect to one’s own past and future is somewhat mysterious.
For instance, we are each heirs to our actions and to our failures of action.
Does this have any moral implications? If I am currently disinclined to do some
necessary and profitable work, to eat well, to make regular visits to doctor
and dentist, to avoid dangerous sports, to wear my seat belt, to save money,
etc.—have I committed a series of crimes against the future self who will
suffer the consequences of my negligence? Why not? And if I do live prudently,
despite the pain it causes me, out of concern for the interests of my future
self, is this an instance of my being used as a means to someone else’s end? Am
I merely a resource for the person I will be in the future?

46. Rawls’s notion of “primary goods,” access to which must be fairly allocated
in any just society, seems parasitic upon a general notion of human well-being.
Why are “basic rights and liberties,” “freedom of movement and free choice of
occupation,” “the powers and prerogatives of offices and positions of
authority,” “income and wealth,” and “the social bases of self-respect” of any
interest to us at all if not as constituents of happy human lives? Of course,
Rawls is at pains to say that his conception of the “good” is partial and
merely political—but to the degree that it is good at all, it seems beholden to
a larger conception of human well-being. See Rawls, 2001, pp. 58–60.

47. Cf. Pinker, 2008b.

48. Kant, [1785] 1995, p. 30.

49. As Patricia Churchland notes:



Kant’s conviction that detachment from emotions is essential in characterizing
moral obligation is strikingly at odds with what we know about our biological
nature. From a biological point of view, basic emotions are Mother Nature’s way
of getting us to do what we prudentially ought. The social emotions are a way
of getting us to do what we socially ought, and the reward system is a way of
learning to use past experiences to improve one’s performance in both domains
(Churchland, 2008b).



50. However, one problem that people often have with consequentialism is that
it entails moral hierarchy: certain spheres of well-being (i.e., minds) will be
more important than others. The philosopher Robert Nozick famously observed
that this opens the door to “utility monsters”: hypothetical creatures who
could get enormously greater life satisfaction from devouring us than we would
lose (Nozick 1974, p. 41). But, as Nozick observes, we are just such utility
monsters. Leaving aside the fact that economic inequality allows many of us to
profit from the drudgery of others, most of us pay others to raise and kill
animals so that we can eat them. This arrangement works out rather badly for
the animals. How much do these creatures actually suffer? How different is the
happiest cow, pig, or chicken from those who languish on our factory farms? We
seem to have decided, all things considered, that it is proper that the
well-being of certain species be entirely sacrificed to our own. We might be
right about this. Or we might not. For many people, eating meat is simply an
unhealthy source of fleeting pleasure. It is very difficult to believe,
therefore, that all of the suffering and death we impose on our fellow
creatures is ethically defensible. For the sake of argument, however, let’s
assume that allowing some people to eat some animals yields a net increase in
well-being on planet earth.

In this context, would it be ethical for cows being led to slaughter to defend
themselves if they saw an opportunity—perhaps by stampeding their captors and
breaking free? Would it be ethical for a fish to fight against the hook in
light of the fisherman’s justified desire to eat it? Having judged some
consumption of animals to be ethically desirable (or at least ethically
acceptable), we appear to rule out the possibility of warranted resistance on
their parts. We are their utility monsters.

Nozick draws the obvious analogy and asks if it would be ethical for our
species to be sacrificed for the unimaginably vast happiness of some
superbeings. Provided that we take the time to really imagine the details
(which is not easy), I think the answer is clearly “yes.” There seems no reason
to suppose that we must occupy the highest peak on the moral landscape. If
there are beings who stand in relation to us as we do to bacteria, it should be
easy to admit that their interests must trump our own, and to a degree that we
cannot possibly conceive. I do not think that the existence of such a moral
hierarchy poses any problems for our ethics. And there is no compelling reason
to believe that such superbeings exist, much less ones that want to eat us.

51. Traditional utility theory has been unable to explain why people so often
behave in ways that they know they will later regret. If human beings were
simply inclined to choose the path leading to their most satisfying option,
then willpower would be unnecessary, and self-defeating behavior would be
unheard of. In his fascinating book, Breakdown of Will, the psychiatrist George
Ainslie examines the dynamics of human decision making in the face of competing
preferences. To account for both the necessity of human will, along with its
predictable failures, Ainslie presents a model of decision making in which each
person is viewed as a community of present and future “selves” in competition,
and each “self” discounts future rewards more steeply than seems strictly
rational.

The multiplicity of competing interests in the human mind causes us each to
function as a loose coalition of interests that may be unified only by resource
limitations—like the fact that we have only one body with which to express our
desires, moment to moment. This obvious constraint upon our fulfilling mutually
incompatible ends keeps us bargaining with our “self” across time: “Ulysses
planning for the Sirens must treat Ulysses hearing them as a separate person,
to be influenced if possible and forestalled if not” (Ainslie, 2001, p. 40).

Hyperbolic discounting of future rewards leads to curiosities like “preference
reversal”: for example, most people prefer $10,000 today to $15,000 three years
from now, but prefer $15,000 in thirteen years to $10,000 in ten years. Given
that the latter scenario is simply the first seen at a distance of ten years,
it seems clear that people’s preferences reverse depending on the length of the
delay. The deferral of a reward is less acceptable the closer one gets to the
possibility of enjoying it.

52. I am also not as healthy or as well educated as I could be. I believe that
such statements are objectively true (even where they relate to subjective
facts about me).

53. Haidt, 2001, p. 821.

54. The wisdom of switching doors is seen more easily if you imagine having
made your initial selection among a thousand doors, rather than three. Imagine
you picked Door #17, and Monty Hall then opens every door except for #562,
revealing goats as far as the eye can see. What should you do next? Stick with
Door #17 or switch to Door #562? It should be obvious that your initial choice
was made in a condition of great uncertainty, with a 1-in-1,000 chance of
success and a 999-in-1,000 chance of failure. The opening of 998 doors has
given you an extraordinary amount of information—collapsing the remaining odds
of 999-in-1,000 on door #562.

55. Haidt, 2008.

56. Haidt, 2001, p. 823.

57. http://newspolls.org/question.php?question_id=716. Incidentally, the same
research found that 16 percent of Americans also believe that it is “very
likely” that the “federal government is withholding proof of the existence of
intelligent life from other planets” (http://newspolls.org/question.php?
question_id=715).

58. This is especially obvious in split-brain research, when language areas in
the left hemisphere routinely confabulate explanations for right-hemisphere
behavior (Gazzaniga, 1998; M. S. Gazzaniga, 2005; Gazzaniga, 2008; Gazzaniga,
Bogen, & Sperry, 1962).

59. Blow, 2009.

60. “Multiculturalism ‘drives young Muslims to shun British values.’” The Daily
Mail (January 29, 2007).

61. Moll, de Oliveira-Souza, & Zahn, 2008; 2005.

62. Moll et al., 2008, p. 162.

63. Including the nucleus accumbens, the caudate nucleus, the ventromedial and
orbitofrontal cortex, and the rostral anterior cingulate (Rilling et al.,
2002).

64. Though, as is often the case with neuroimaging work, the results do not
divide as neatly as all that. In fact, one of Moll’s earlier studies on disgust
and moral indignation found medial regions also involved in these negative
states (Moll, de Oliveira-Souza et al., 2005).

65. Koenigs et al., 2007.

66. J. D. Greene et al., 2001.

67. This thought experiment was first introduced by Foot (1967) and later
elaborated by Thompson (1976).

68. J. D. Greene et al., 2001.

69. Valdesolo & DeSteno, 2006.

70. J. D. Greene, 2007.

71. Moll et al., 2008, p. 168. There is the additional concern, which bedevils
much neuroimaging research: the regions that Greene et al. label as “emotional”
have been implicated in other types of processing—memory and language, for
instance (G. Miller, 2008b). This is an instance of the “reverse inference”
problem raised by Poldrack (2006), discussed below in the context of my own
research on belief.

72. While some researchers have sought to differentiate these terms, most use
them interchangeably.

73. Salter, 2003, pp. 98–99. See also Stone, 2009.

74. www.missingkids.com.

75. Twenty percent of male and female prison inmates are psychopaths, and they
are responsible for more than 50 percent of serious crimes (Hare, 1999, p. 87).
The recidivism rate of psychopaths is three times higher than that of other
offenders (and the violent recidivism rate is three to five times higher)
(Blair, Mitchell, & Blair, 2005, p. 16).

76. Nunez, Casey, Egner, Hare, & Hirsch, 2005. For reasons that may have
something to do with the sensationalism just mentioned, psychopathy does not
exist as a diagnostic category, or even as an index entry, in The Diagnostic
and Statistical Manual of Mental Disorders (DSM-IV). The two DSM-IV diagnoses
that seek to address the behavioral correlates of psychopathy—antisocial
personality disorder (ASPD) and conduct disorder—do not capture its
interpersonal and emotional components at all. Antisocial behavior is common to
several disorders, and people with ASPD may not score high on the PCL-R (de
Oliveira-Souza et al., 2008; Narayan et al., 2007). The inadequacies of the
DSM-IV’s treatment of the syndrome are very well brought out in Blair et al.,
2005. There are many motives for antisocial behavior and many routes to
becoming a violent felon. The hallmark of psychopathy isn’t bad behavior per
se, but an underlying spectrum of emotional and interpersonal impairments. And
psychopathy, as a construct, is far more predictive of specific behaviors
(e.g., recidivism) than the DSM-IV criteria are.

77. It would appear, however, that the same could be said of the great Erwin
Schrödinger (Teresi, 2010).

78. Frontal lobe injury can result in a condition known as “acquired
sociopathy,” which shares some of the features of developmental psychopathy.
While they are often mentioned in the same context, acquired sociopathy and
psychopathy differ, especially with regard to the type of aggression they
produce. Reactive aggression is triggered by an annoying or threatening stimuli
and is often associated with anger. Instrumental aggression is purposed toward
a goal. The man who lashes out after being jostled on the street has expressed
reactive aggression; the man who attacks another man to steal his wallet or to
impress his fellow gang members has displayed instrumental aggression. Subjects
suffering from acquired sociopathy, who have generally sustained injuries to
their orbitofrontal lobes, display poor impulse control and tend to exhibit
increased levels of reactive aggression. However, they do not show a heightened
tendency toward instrumental aggression. Psychopaths are prone to aggression of
both types. Most important, instrumental aggression seems most closely linked
to the callousness/unemotional (CU) trait that is the hallmark of the disorder.
Studies of same-sex twins suggest that the CU trait is also most associated
with heritable causes of antisocial behavior (Viding, Jones, Frick, Moffitt, &
Plomin, 2008).

Moll, de Oliveira-Souza, and colleagues found that the correlation between gray
matter reductions and psychopathy extends beyond the frontal cortex, and this
would explain why acquired sociopathy and psychopathy are distinct disorders.
Psychopathy was correlated with gray matter reductions in a wide network of
structures: including the bilateral insula, the superior temporal sulci, the
supra-marginal/angular gyri, the caudate (head), the fusiform cortex, the
middle frontal gyri, among others. It would be exceedingly unlikely to injure
such a wide network selectively.

79. Kiehl et al., 2001; Glenn, Raine, & Schug, 2009. However, when given
personal vs. impersonal moral dilemmas to solve, unlike MPFC patients,
psychopaths tend to produce the same answers as normal controls, albeit without
the same emotional response (Glenn, Raine, Schug, Young, & Hauser, 2009).

80. Hare, 1999, p. 76.

81. Ibid., p. 132.

82. Blair et al., 2005.

83. Buckholtz et al., 2010.

84. Richell et al., 2003.

85. Dolan & Fullam, 2004.

86. Dolan & Fullam, 2006; Blair et al., 2005.

87. Blair et al., 2005. The first book-length treatment of psychopathy appears
to be Cleckley’s The Mask of Sanity. While it is currently out of print, this
book is still widely referenced and much revered. It is worth reading, if only
for the author’s highly (and often inadvertently) amusing prose. Hare, 1999,
Blair et al., 2005, and Babiak & Hare, 2006, provide more recent book-length
discussions of the disorder.

88. Blair et al., 2005. The developmental literature suggests that, because
punishment (the unconditioned stimulus) rarely follows a specific transgression
(the conditioned stimulus) closely in time, the aversive conditioning brought
on by corporal punishment tends to get associated with the person who metes it
out, rather than with the behavior in need of correction. Blair also observes
that if punishment were the primary source of moral instruction, children would
be unable to observe the difference between conventional transgressions (e.g.,
talking in class) and moral ones (e.g., hitting another student), as breaches
of either sort tend to elicit punishment. And yet healthy children can readily
distinguish between these forms of misbehavior. Thus, it would seem that they
receive their correction directly from the distress that others exhibit when
true moral boundaries have been crossed. Other mammals also find the suffering
of their conspecifics highly aversive. We know this from work in monkeys
(Masserman, Wechkin, & Terris, 1964) and rats (Church, 1959) that would seem
scarcely ethical to perform today. For instance, the conclusion of the former
study reads: “A majority of rhesus monkeys will consistently suffer hunger
rather than secure food at the expense of electroshock to a conspecific.”

89. Subsequent reviews of the neuroimaging literature have produced a somewhat
muddled view of the underlying neurology of psychopathy (Raine & Yaling, 2006).
While individual studies have found anatomical and functional abnormalities in
a wide variety of brain regions—including the amygdala, hippocampus, corpus
callosum, and putamen—the only result common to all studies is that psychopaths
tend to show reduced gray matter in the prefrontal cortex (PFC). Reductions in
gray matter in three regions of the PFC—the medial and lateral orbital areas
and the frontal poles—correlate with psychopathy scores, and these regions have
been shown in other work to be directly involved in the regulation of social
conduct (de Oliveira-Souza et al., 2008). Recent findings suggest that the
correlation between cortical thinning and psychopathy may be significant only
for the right hemisphere (Yang, Raine, Colletti, Toga, & Narr, 2009). The
brains of psychopaths also show reduced white matter connections between
orbital frontal regions and the amygdala (M. C. Craig et al., 2009). In fact,
the difference in the average volume of gray matter in orbitofrontal regions
seems to account for half of the variation in antisocial behavior between the
sexes: men and women don’t seem to differ in their experience of anger, but
women tend to be both more fearful and more empathetic—and are thus better able
to control their antisocial impulses (Jones, 2008).

90. Blair et al. hypothesize that the orbitofrontal deficits of psychopathy
underlie the propensity for reactive aggression, while the amygdala dysfunction
leads to “impairments in aversive conditioning, instrumental learning, and the
processing of fearful and sad expressions” that allow for learned, instrumental
aggression and make normal socialization impossible. Kent Kiehl, author of the
first fMRI study on psychopathy, now believes that the functional neuroanatomy
of the disorder includes a network of structures including the orbital frontal
cortex, insula, anterior and posterior cingulate, amygdala, parahippocampal
gyrus, and anterior superior temporal gyrus (Kiehl et al., 2001). He refers to
this network as the “the paralimbic system” (Kiehl, 2006). Kiehl is currently
engaged in a massive and ongoing fMRI study of incarcerated psychopaths, using
a 1.5 Tesla scanner housed in a tractor-trailer that can be moved from prison
to prison. He hopes to build a neuroimaging database of 10,000 subjects (G.
Miller, 2008a; Seabrook, 2008).

91. Trivers, 2002, p. 53. For an extensive discussion of the details here, see
Dawkins, [1976] 2006, pp. 202–233.

92. Jones, 2008.

93. Diamond, 2008. Pinker, 2007, makes the same point: “If the wars of the
twentieth century had killed the same proportion of the population that die in
the wars of a typical tribal society, there would have been two billion deaths,
not 100 million.”

It is easy to conclude that life is cheap in an honor culture, ruled by
vengeance and the law of talion (“eye for an eye”), but, as William Ian Miller
observes, by at least one measure these societies value life even more than we
do. Our modern economies thrive because we tend to limit personal liability. If
I sell you a defective ladder, and you fall and break your neck, I may have to
pay you some compensation. But I will not have to pay you nearly as much as I
would be willing to pay to avoid having my own neck broken. In our society we
are constrained by the value a court places on the other guy’s neck; in a
culture ruled by talion law, we are constrained by the value we place on our
own (W. I. Miller, 2006).

94. Bowles, 2006, 2008, 2009.

95. Churchland, 2008a.

96. Libet, Gleason, Wright, & Pearl, 1983.

97. Soon, Brass, Heinze, & Haynes, 2008. Libet later argued that while we don’t
have free will with respect to initiating behavior, we might have free will to
veto an intention before it becomes effective (Libet, 1999, 2003). I think his
reasoning was clearly flawed, as there is every reason to think that a
conscious veto must also arise on the basis of unconscious neural events.

98. Fisher, 2001; Wegner, 2002; Wegner, 2004.

99. Heisenberg, 2009; Kandel, 2008; Karczmar, 2001; Libet, 1999; McCrone, 2003;
Planck & Murphy, 1932; Searle, 2001; Sperry, 1976.

100. Heisenberg, 2009.

101. One problem with this approach is that quantum mechanical effects are
probably not, as a general rule, biologically salient. Quantum effects do drive
evolution, as high-energy particles like cosmic rays cause point mutations in
DNA, and the behavior of such particles passing through the nucleus of a cell
is governed by the laws of quantum mechanics. Evolution, therefore, seems
unpredictable in principle (Silver, 2006).

102. The laws of nature do not strike most of us as incompatible with free will
because we have not imagined how human action would appear if all
cause-and-effect relationships were understood. But imagine that a mad
scientist has developed a means of controlling the human brain at a distance:
What would it be like to watch him send a person to and fro on the wings of her
“will”? Would there be even the slightest temptation to impute freedom to her?
No. But this mad scientist is nothing more than causal determinism personified.
What makes his existence so inimical to our notion of free will is that when we
imagine him lurking behind a person’s thoughts and actions—tweaking electrical
potentials, manufacturing neurotransmitters, regulating genes, etc.—we cannot
help but let our notions of freedom and responsibility travel up the puppet’s
strings to the hand that controls them. To see that the addition of randomness
does nothing to change this situation, we need only imagine the scientist
basing the inputs to his machine on a shrewd arrangement of roulette wheels.
How would such unpredictable changes in the states of a person’s brain
constitute freedom?

Swapping any combination of randomness and natural law for a mad scientist, we
can see that all the relevant features of a person’s inner life would be
conserved—thoughts, moods, and intentions would still arise and beget
actions—and yet we are left with the undeniable fact that the conscious mind
cannot be the source of its own thoughts and intentions. This discloses the
real mystery of free will: if our experience is compatible with its utter
absence, how can we say that we see any evidence for it in the first place?

103. Dennett, 2003.

104. The phrase “alien hand syndrome” describes a variety of neurological
disorders in which a person no longer recognizes ownership of one of his hands.
Actions of the nondominant hand in the split-brain patient can have this
character, and in the acute phase after surgery this can lead to overt,
intermanual conflict. Zaidel et al. (2003) prefer the phrase “autonomous hand,”
as patients typically experience their hand to be out of control but do not
ascribe ownership of it to someone else. Similar anomalies can be attributed to
other neurological causes: for instance, in sensory alien hand syndrome
(following a stroke in the right posterior cerebral artery) the right arm will
sometimes choke or otherwise attack the left side of the body (Pryse-Philips,
2003).

105. See S. Harris, 2004, pp. 272–274.

106. Burns & Bechara, 2007, p. 264.

107. Others have made a similar argument. See Burns & Bechara, 2007, p. 264; J.
Greene & Cohen, 2004, p. 1776.

108. Cf. Levy, 2007.

109. The neuroscientist Michael Gazzaniga writes:



Neuroscience will never find the brain correlate of responsibility, because
that is something we ascribe to humans—to people—not to brains. It is a moral
value we demand of our fellow, rule-following human beings. Just as
optometrists can tell us how much vision a person has (20/20 or 20/200) but
cannot tell us when someone is legally blind or has too little vision to drive
a school bus, so psychiatrists and brain scientists might be able to tell us
what someone’s mental state or brain condition is but cannot tell us (without
being arbitrary) when someone has too little control to be held responsible.
The issue of responsibility (like the issue of who can drive school buses) is a
social choice. In neuroscientific terms, no person is more or less responsible
than any other for actions. We are all part of a deterministic system that
someday, in theory, we will completely understand. Yet the idea of
responsibility, a social construct that exists in the rules of a society, does
not exist in the neuronal structures of the brain (Gazzaniga, 2005, pp.
101–102).



While it is true that responsibility is a social construct attributed to people
and not to brains, it is a social construct that can make more or less sense
given certain facts about a person’s brain. I think we can easily imagine
discoveries in neuroscience, as well as brain imaging technology, that would
allow us to attribute responsibility to persons in a far more precise way than
we do at present. A “Twinkie defense” would be entirely uncontroversial if we
learned that there was something in the creamy center of every Twinkie that
obliterated the frontal lobe’s inhibitory control over the limbic system.

But perhaps “responsibility” is simply the wrong construct: for Gazzaniga is
surely correct to say that “in neuroscientific terms, no person is more or less
responsible than any other for actions.” Conscious actions arise on the basis
of neural events of which we are not conscious. Whether they are predictable or
not, we do not cause our causes.

110. Diamond, 2008.

111. In the philosophical literature, one finds three approaches to the
problem: determinism, libertarianism, and compatibilism. Both determinism and
libertarianism are often referred to as “incompatibilist” views, in that both
maintain that if our behavior is fully determined by background causes, free
will is an illusion. Determinists believe that we live in precisely such a
world; libertarians (no relation to the political view that goes by this name)
believe that our agency rises above the field of prior causes—and they
inevitably invoke some metaphysical entity, like a soul, as the vehicle for our
freely acting wills. Compatibilists, like Daniel Dennett, maintain that free
will is compatible with causal determinism (see Dennett, 2003; for other
compatibilist arguments see Ayer, Chisholm, Strawson, Frankfurt, Dennett, and
Watson—all in Watson, 1982). The problem with compatibilism, as I see it, is
that it tends to ignore that people’s moral intuitions are driven by deeper,
metaphysical notions of free will. That is, the free will that people presume
for themselves and readily attribute to others (whether or not this freedom is,
in Dennett’s sense, “worth wanting”) is a freedom that slips the influence of
impersonal, background causes. The moment you show that such causes are
effective—as any detailed account of the neurophysiology of human thought and
behavior would—proponents of free will can no longer locate a plausible hook
upon which to hang their notions of moral responsibility. The neuroscientists
Joshua Greene and Jonathan Cohen make the same point:



Most people’s view of the mind is implicitly dualist and libertarian and not
materialist and compatibilist … [I]ntuitive free will is libertarian, not
compatibilist. That is, it requires the rejection of determinism and an
implicit commitment to some kind of magical mental causation … contrary to
legal and philosophical orthodoxy, determinism really does threaten free will
and responsibility as we intuitively understand them (J. Greene & Cohen, 2004,
pp. 1779–1780).



Chapter 3: Belief



1. Brains do not fossilize, so we cannot examine the brains of our ancient
ancestors. But comparing the neuroanatomy of living primates offers some
indication of the types of physical adaptations that might have led to the
emergence of language. For instance, diffusion-tensor imaging of macaque,
chimpanzee, and human brains reveals a gradual increase in the connectivity of
the arcuate fasciculus—the fiber tract linking the temporal and frontal lobes.
This suggests that the relevant adaptations were incremental, rather than
saltatory (Ghazanfar, 2008).

2. N. Patterson, Richter, Gnerre, Lander, & Reich, 2006, 2008.

3. Wade, 2006.

4. Sarmiento, Sawyer, Milner, Deak, & Tattersall, 2007; Wade, 2006.

5. It seems, however, that the Neanderthal copy of the FOXP2 gene carried the
same two crucial mutations that distinguish modern humans from other primates
(Enard et al., 2002; Krause et al., 2007). FOXP2 is now known to play a central
role in spoken language, and its disruption leads to severe linguistic
impairments in otherwise healthy people (Lai, Fisher, Hurst, Vargha-Khadem, &
Monaco, 2001). The introduction of a human FOXP2 gene into mice changes their
ultrasonic vocalizations, decreases exploratory behavior, and alters
cortico-basal ganglia circuits (Enard et al., 2009). The centrality of FOXP2
for language development in humans has led some researchers to conclude that
Neanderthals could speak (Yong, 2008). In fact, one could argue that the
faculty of speech must precede Homo sapiens, as “it is difficult to imagine the
emergence of complex subsistence behaviors and selection for a brain size
increase of approximately 75 percent, both since about 800,000 years ago,
without complex social communication” (Trinkaus, 2007).

Whether or not they could speak, the Neanderthals were impressive creatures.
Their average cranial capacity was 1,520 cc, slightly larger than that of their
Homo sapien contemporaries. In fact, human cranial capacity has decreased by
about 150 cc over the millennia to its current average of 1,340 cc (Gazzaniga,
2008). Generally speaking, the correlation between brain size and cognitive
ability is less than straightforward, as there are several species that have
larger brains than we do (e.g., elephants, whales, dolphins) without exhibiting
signs of greater intelligence. There have been many efforts to find some
neuroanatomical measure that reliably tracks cognitive ability, including
allometric brain size (brain size proportional to body mass), “encephalization
quotient” (brain size proportional to the expected brain size for similar
animals, corrected for body mass; for primates EQ = [brain weight] / [0.12 ×
body weight0.67]), the size of the neocortex relative to the rest of the brain,
etc. None of these metrics has proved especially useful. In fact, among
primates, there is no better predictor of cognitive ability than absolute brain
size, irrespective of body mass (Deaner, Isler, Burkart, & van Schaik, 2007).
By this measure, our competition with Neanderthals looks especially daunting.

There are several genes involved in brain development that have been found to
be differentially regulated in human beings compared to other primates; two of
special interest are microcephalin and ASPM (the abnormal spindlelike
microcephaly-associated gene). The modern variant of microcephalin, which
regulates brain size, appeared approximately 37,000 years ago (more or less
coincident with the ascendance of modern humans) and has increased in frequency
under positive selection pressure ever since (P. D. Evans et al., 2005). One
modern variant of ASPM, which also regulates brain size, has spread with great
frequency in the last 5,800 years (Mekel-Bobrov et al., 2005). As these authors
note, this can be loosely correlated with the spread of cities and the
development of written language. The possible significance of these findings is
also discussed in Gazzaniga (2008).

6. Fitch, Hauser, & Chomsky, 2005; Hauser, Chomsky, & Fitch, 2002; Pinker &
Jackendoff, 2005.

7. Regrettably, language is also the basis of our ability to wage war
effectively, to perpetrate genocide, and to render our planet uninhabitable.

8. While general information sharing has been undeniably useful, there is good
reason to think that the communication of specifically social information has
driven the evolution of language (Dunbar, 1998, 2003). Humans also transmit
social information (i.e., gossip) in greater quantity and with higher fidelity
than nonsocial information (Mesoudi, Whiten, & Dunbar, 2006).

9. Cf. S. Harris, 2004, pp. 243–244.

10. A. R. Damasio, 1999.

11. Westbury & Dennett, 1999.

12. Bransford & McCarrell, 1977.

13. Rumelhart, 1980.

14. Damasio draws a similar distinction (A. R. Damasio, 1999).

15. For the purposes of studying belief in the lab, therefore, there seems to
be little problem in defining the phenomenon of interest: believing a
proposition is the act of accepting it as “true” (e.g., marking it as “true” on
a questionnaire); disbelieving a proposition is the act of rejecting it as
“false”; and being uncertain about the truth value of a proposition is the
disposition to do neither of these things, but to judge it, rather, as
“undecidable.”

In our search for the neural correlates of subjective states like belief and
disbelief, we are bound to rely on behavioral reports. Therefore, having
presented an experimental subject with a written statement—e.g., the United
States is larger than Guatemala—and watched him mark it as “true,” it may occur
to us to wonder whether we can take him at his word. Does he really believe
that the United States is larger than Guatemala? Does this statement, in other
words, really seem true to him? This is rather like worrying, with reference to
a subject who has just performed a lexical decision task, whether a given
stimulus really seems like a word to him. While it may seem reasonable to worry
that experimental subjects might be poor judges of what they believe, or that
they might attempt to deceive experimenters, such concerns seem misplaced—or if
appropriate here, they should haunt all studies of human perception and
cognition. As long as we are content to rely on subjects to report their
perceptual judgments (about when, or whether, a given stimulus appeared), or
their cognitive ones (about what sort of stimulus it was), there seems to be no
special problem taking reports of belief, disbelief, and uncertainty at face
value. This does not ignore the possibility of deception (or self-deception),
implicit cognitive conflict, motivated reasoning, and other sources of
confusion.

16. Blakeslee, 2007.

17. These considerations run somewhat against David Marr’s influential thesis
that any complex information-processing system should be understood first at
the level of “computational theory” (i.e., the level of highest abstraction) in
terms of its “goals” (Marr, 1982). Thinking in terms of goals can be extremely
useful, of course, in that it unifies (and ignores) a tremendous amount of
bottom-up detail: the goal of “seeing,” for instance, is complicated at the
level of its neural realization and, what is more, it has been achieved by at
least forty separate evolutionary routes (Dawkins, 1996, p. 139). Consequently,
thinking about “seeing” in terms of abstract computational goals can make a lot
of sense. In a structure like the brain, however, the “goals” of the system can
never be fully specified in advance. We currently have no inkling what else a
region like the insula might be “for.”

18. There has been a long debate in neuroscience over whether the brain is best
thought of as a collection of discrete modules or as a distributed, dynamical
system. It seems clear, however, that both views are correct, depending on
one’s level of focus (J. D. Cohen & Tong, 2001). Some degree of modularity is
now an undeniable property of brain organization, as damage to one brain region
can destroy a specific ability (e.g., the recognition of faces) while sparing
most others. There are also distinct differences in cell types and patterns of
connectivity that articulate sharp borders between regions. And some degree of
modularity is ensured by limitations on information transfer over large
distances in the brain.

While regional specialization is a general fact of brain organization, strict
partitioning generally isn’t: as has already been said, most regions of the
brain serve multiple functions. And even within functionally specific regions,
the boundaries between their current function and their possible functions are
provisional, fuzzy, and in the case of any individual brain, guaranteed to be
idiosyncratic. For instance, the brain shows a general capacity to recover from
focal injuries, and this entails the recruitment and repurposing of other
(generally adjacent) brain areas. Such considerations suggest that we cannot
expect true isomorphism between brains—or even between a brain and itself
across time.

There is legitimate concern, however, that current methods of neuroimaging tend
to beg the question in favor of the modularity thesis—leading, among uncritical
consumers of this research, to a naïve picture of functional segregation in the
brain. Consider functional magnetic resonance imaging (fMRI), which is the most
popular method of neuroimaging at present. This technique does not give us an
absolute measure of neural activity. Rather, it allows us to compare changes in
blood flow throughout the brain between two experimental conditions. We can,
for example, compare instances in which subjects believe statements to be true
to instances in which they believe statements to be false. The resulting image
reveals which regions of the brain are more active in one condition or the
other. Because fMRI allows us to detect signal changes throughout the brain, it
is not, in principle, blind to widely distributed or combinatorial processing.
But its dependence on blood flow as a marker for neural activity reduces
spatial and temporal resolution, and the statistical techniques we use to
analyze our data require that we focus on relatively large clusters of
activity. It is, therefore, in the very nature of the tool to deliver images
that appear to confirm the modular organization of brain function (cf. Henson,
2005). The problem, as far as critics are concerned, is that this method of
studying the brain ignores the fact that the whole brain is active in both
experimental conditions (e.g., during belief and disbelief), and regions that
don’t survive this subtractive procedure may well be involved in the relevant
information processing.

Functional magnetic resonance imaging (fMRI) also rests on the assumption that
there is a more or less linear relationship between changes in blood flow, as
measured by blood-oxygen-level-dependent (BOLD) changes in the MR signal, and
changes in neuronal activity. While the validity of fMRI seems generally well
supported (Logothetis, Pauls, Augath, Trinath, & Oeltermann, 2001), there is
some uncertainty about whether the assumed linear relationship between blood
flow and neuronal activity holds for all mental processes (Sirotin & Das,
2009). There are also potential problems with comparing one brain state to
another on the assumption that changes in brain function are additive in the
way that the components of an experimental task may be (this is often referred
to as the problem of “pure insertion”) (Friston et al., 1996). There are also
questions about what “activity” is indicated by changes in the BOLD signal. The
principal correlate of blood-flow changes in the brain appears to be
presynaptic/neuromodulatory activity (as measured by local field potentials),
not axonal spikes. This fact poses a few concerns related to the interpretation
of fMRI data: fMRI cannot readily differentiate activity that is specific to a
given task and neuromodulation; nor can it differentiate bottom-up from
top-down processing. In fact, fMRI may be blind to the difference between
excitatory and inhibitory signals, as metabolism also increases with
inhibition. It seems quite possible, for instance, that increases in recurrent
inhibition in a given region might be associated with greater BOLD signal but
decreased neuronal firing. For a discussion of these and other limitations of
the technology, see Logothetis, 2008; M. S. Cohen, 1996, 2001. Such concerns
notwithstanding, fMRI remains the most important tool for studying brain
function in human beings noninvasively.

A more sophisticated, neural network analysis of fMRI data has shown that
representational content—which can appear, under standard methods of data
analysis, to be strictly segregated (e.g., face-vs.-object perception in the
ventral temporal lobe)—is actually intermingled and dispersed across a wider
region of the cortex. Information encoding appears to depend not on strict
localization, but on a combinatorial pattern of variations in the intensity of
the neural response across regions once thought to be functionally distinct
(Hanson, Matsuka, & Haxby, 2004).

There are also epistemological questions about what it means to correlate any
mental state with physiological changes in the brain. And yet, while I consider
the so-called “hard problem” of consciousness (Chalmers, 1996) a real barrier
to scientific explanation, I do not think it will hinder the progress of
cognitive neuroscience generally. The distinction between consciousness and its
contents seems paramount. It is true that we do not understand how
consciousness emerges from the unconscious activity of neural networks—or even
how it could emerge. But we do not need such knowledge to compare states of
mind through neuroimaging. To consider one among countless examples from the
current literature: neuroscientists have begun to investigate how envy and
schadenfreude are related in neuroanatomical terms. One group found activity in
the ACC (anterior cingulate cortex) to be correlated with envy, and the
magnitude of signal change was predictive of activity in the striatum (a region
often associated with reward) when subjects witnessed those they envied
experiencing misfortune (signifying the pleasure of schadenfreude) (Takahashi
et al., 2009). This reveals something about the relationship between these
mental states that may not be obvious by introspection. The finding that
right-sided lesions in the MPFC impair the perception of envy (a negative
emotion), while analogous left-sided lesions impair the perception of
schadenfreude (a positive emotion) fills in a few more details (Shamay-Tsoory,
Tibi-Elhanany, & Aharon-Peretz, 2007)—as there is a wider literature on the
lateralization of positive and negative mental states. Granted, the
relationship between envy and schadenfreude was somewhat obvious without our
learning their neural correlates. But improvements in neuroimaging may one day
allow us to understand the relationship between such mental states with great
precision. This may deliver conceptual surprises and even personal epiphanies.
And if the mental states and capacities most conducive to human well-being are
ever understood in terms of their underlying neurophysiology, neuroimaging may
become an integral part of any enlightened approach to ethics.

It seems to me that progress on this front does not require that we solve the
“hard problem” of consciousness (or that it even admit of a solution). When
comparing mental states, the reality of human consciousness is a given. We need
not understand how consciousness relates to the behavior of atoms to
investigate how emotions like love, compassion, trust, greed, fear, and anger
differ (and interact) in neurophysiological terms.

19. Most inputs to cortical dendrites come from neurons in the same region of
cortex: very few arrive from other cortical regions or from ascending pathways.
For instance, only 5 percent to 10 percent of inputs to layer 4 of visual
cortex arrive from the thalamus (R. J. Douglas & Martin, 2007).

20. The apparent (qualified) existence of “grandmother cells” notwithstanding
(Quiroga, Reddy, Kreiman, Koch, & Fried, 2005). For a discussion of the limits
of traditional “connectionist” accounts of mental representation, see Doumas &
Hummel, 2005.

21. These data were subsequently published as Harris, S., Sheth, & Cohen 2008.

22. The post-hoc analysis of neuroimaging data is a limitation of many studies,
and in our original paper we acknowledged the importance of distinguishing
between results predicted by a specific model of brain function and those that
arise in the absence of a prior hypothesis. This caveat notwithstanding, I
believe that too much has been made of the distinction between descriptive and
hypothesis-driven research in science generally and in neuroscience in
particular. There must always be a first experimental observation, and one gets
no closer to physical reality by running a follow-up study. To have been the
first person to observe blood-flow changes in the right fusiform gyrus in
response to visual stimuli depicting faces (Sergent, Ohta, & MacDonald,
1992)—and to have concluded, on the basis of these data, that this region of
cortex plays a role in facial recognition—was a perfectly legitimate instance
of scientific induction. Subsequent corroboration of these results increased
our collective confidence in this first set of data (Kanwisher, McDermott, &
Chun, 1997) but did not constitute an epistemological advance over the first
study. All subsequent hypothesis-driven research that has taken the fusiform
gyrus as a region of interest derives its increased legitimacy from the
descriptive study upon which it is based (or, as has often been the case in
neuroscience, from the purely descriptive, clinical literature). If the initial
descriptive study was in error, then any hypothesis based on it would be empty
(or only accidentally correct); if the initial work was valid, then follow-up
work would merely corroborate it and, perhaps, build upon it. The injuries
suffered by Phineas Gage and H.M. were inadvertent, descriptive experiments,
and the wealth of information learned from these cases—arguably more than was
learned from any two experiments in the history of neuroscience—did not suffer
for lack of prior hypothesis. Indeed, these clinical observations became the
basis of all subsequent hypotheses about the function of the frontal and medial
temporal lobes.

23. E. K. Miller & Cohen, 2001; Desimone & Duncan, 1995. While damage to the
PFC can result in a range of deficits, the most common is haphazard,
inappropriate, and impulsive behavior, along with the inability to acquire new
behavioral rules (Bechara, Damasio, & Damasio, 2000). As many parents can
attest, the human capacity for self-regulation does not fully develop until
after adolescence; this is when the white-matter connections in the PFC finally
mature (Sowell, Thompson, Holmes, Jernigan, & Toga, 1999).

24. Spinoza, [1677] 1982.

25. D. T. K. Gilbert, 1991; D. T. K. Gilbert, Douglas, & Malone, 1990; J. P.
Mitchell, Dodson, & Schacter, 2005.

26. This truth bias may interact with (or underlie) what has come to be known
as the “confirmation bias” or “positive test strategy” heuristic in reasoning
(Klayman & Ha, 1987): people tend to seek evidence that confirms an hypothesis
rather than evidence that refutes it. This strategy is known to produce
frequent reasoning errors. Our bias toward belief may also explain the
“illusory-truth effect,” where mere exposure to a proposition, even when it was
revealed to be false or attributed to an unreliable source, increases the
likelihood that it will later be remembered as being true (Begg, Robertson,
Gruppuso, Anas, & Needham, 1996; J. P. Mitchell et al., 2005).

27. This was due to a greater decrease in signal during disbelief trials than
during belief trials. This region of the brain is known to have a high level of
resting-state activity and to show reduced activity compared to baseline for a
wide variety of cognitive tasks (Raichle et al., 2001).

28. Bechara et al., 2000. The MPFC is also activated by reasoning tasks that
incorporate high emotional salience (Goel & Dolan, 2003b; Northoff et al.,
2004). Individuals with MPFC lesions test normally on a variety of executive
function tasks but often fail to integrate appropriate emotional responses into
their reasoning about the world. They also fail to habituate normally to
unpleasant somatosensory stimuli (Rule, Shimamura, & Knight, 2002). The
circuitry in this region that links decision making to emotions seems rather
specific, as MPFC lesions do not disrupt fear conditioning or the normal
modulation of memory by emotionally charged stimuli (Bechara et al., 2000).
While reasoning appropriately about the likely consequences of their actions,
these persons seem unable to feel the difference between good and bad choices.

29. Hornak et al., 2004; O’Doherty, Kringelbach, Rolls, Hornak, & Andrews,
2001.

30. Matsumoto & Tanaka, 2004.

31. Schnider, 2001.

32. Northoff et al., 2006.

33. Kelley et al., 2002.

34. When compared with both belief and uncertainty, disbelief was associated in
our study with bilateral activation of the anterior insula, a primary region
for the sensation of taste (Faurion, Cerf, Le Bihan, & Pillias, 1998;
O’Doherty, Rolls, Francis, Bowtell, & McGlone, 2001). This area is widely
thought to be involved with negatively valenced feelings like disgust (Royet,
Plailly, Delon-Martin, Kareken, & Segebarth, 2003; Wicker et al., 2003), harm
avoidance (Paulus, Rogalsky, Simmons, Feinstein, & Stein, 2003), and the
expectation of loss in decision tasks (Kuhnen & Knutson, 2005). The anterior
insula has also been linked to pain perception (Wager et al., 2004) and even to
the perception of pain in others (T. Singer et al., 2004). The frequent
association between activity in the anterior insula and negative affect appears
to make at least provisional sense of the emotional tone of disbelief.

While disgust is regularly classed as a primary human emotion, infants and
toddlers do not appear to feel it (Bloom, 2004, p. 155). This would account for
some of their more arresting displays of incivility. Interestingly, people
suffering from Huntington’s disease, as well as presymptomatic carriers of the
HD allele, exhibit reduced feelings of disgust and are generally unable to
recognize the emotion in others (Calder, Keane, Manes, Antoun, & Young, 2000;
Gray, Young, Barker, Curtis, & Gibson, 1997; Halligan, 1998; Hayes, Stevenson,
& Coltheart, 2007; I. J. Mitchell, Heims, Neville, & Rickards, 2005;
Sprengelmeyer, Schroeder, Young, & Epplen, 2006). The recognition deficit has
been correlated with reduced activity in the anterior insula (Hennenlotter et
al., 2004; Kipps, Duggins, McCusker, & Calder, 2007)—though other work has
found that HD patients and carriers are impaired in processing a range of
(predominantly negative) emotions: including disgust, anger, fear, sadness, and
surprise (Henley et al., 2008; Johnson et al., 2007; Snowden et al., 2008).

We must be careful not to draw too strong a connection between disbelief and
disgust (or any other mental state) on the basis of these data. While a
connection between these states of mind seems intuitively plausible, equating
disbelief with disgust represents a “reverse inference” of a sort known to be
problematic in the field of neuroimaging (Poldrack, 2006). One cannot reliably
infer the presence of a mental state on the basis of brain data alone, unless
the brain regions in question are known to be truly selective for a single
mental state. If it were known, for instance, that the anterior insulae were
active if and only if subjects experienced disgust, then we could draw quite a
strong inference about the role of disgust in disbelief. But there are very few
regions of the brain whose function is so selective as to justify inferences of
this kind. The anterior insula, for instance, appears to be involved in a wide
range of neutral/positive states—including time perception, music appreciation,
self-recognition, and smiling (A. D. Craig, 2009).

And there may also be many forms of disgust: While subjects tend to rate a wide
range of stimuli as equivalently “disgusting,” one group found that disgust
associated with pathogen-related acts, social-sexual acts (e.g., incest), and
nonsexual moral violations activated different (but overlapping) brain networks
(J. S. Borg, Lieberman, & Kiehl, 2008). To further complicate matters, they did
not find the insula implicated in any of this disgust processing, with the
exception of the subjects’ response to incest. This group is not alone in
suggesting that the insula may not be selective for disgust and may be more
generally sensitive to other factors, including self-monitoring and emotional
salience. As the authors note, the difficulty in interpreting these results is
compounded by the fact that their subjects were engaged in a memory task and
not required to explicitly evaluate how disgusting a stimulus was until after
the scanning session. This may have selected against insular activity; at least
one other study suggests that the insula may only be preferentially active in
response to attended stimuli (Anderson, Christoff, Panitz, De Rosa, & Gabrieli,
2003).

35. These results seem to pull the rug out from under one widely subscribed
view in moral philosophy, generally described as “non-cognitivism.”
Non-cognitivists hold that moral claims lack propositional content and,
therefore, do not express genuine beliefs about the world. Unfortunately for
this view, our brains appear to be unaware of this breakthrough in metaethics:
we seem to accept the truth of moral assertions in the same way as we accept
any other statements of fact.

In this first experiment on belief, we also analyzed the brain’s response to
uncertainty: the mental state in which the truth value of a proposition cannot
be judged. Not knowing what one believes to be true—Is the hotel north of Main
Street, or south of Main Street? Was he talking to me, or to the man behind
me?—has obvious behavioral/emotional consequences. Uncertainty prevents the
link between thought and subsequent behavior/emotion from forming. It can be
distinguished readily from belief and disbelief in this regard, because in the
latter states, the mind has settled upon a specific, actionable representation
of the world. The results of our study suggest two mechanisms that might
account for this difference.

The contrasts—uncertainty minus belief and uncertainty minus disbelief—yielded
signal in the anterior cingulate cortex (ACC). This region of the brain has
been widely implicated in error detection (Schall, Stuphorn, & Brown, 2002) and
response conflict (Gehring & Fencsik, 2001), and it regularly responds to
increases in cognitive load and interference (Bunge, Ochsner, Desmond, Glover,
& Gabrieli, 2001). It has also been shown to play a role in the perception of
pain (Coghill, McHaffie, & Yen, 2003).

The opposite contrasts, belief minus uncertainty and disbelief minus
uncertainty, showed increased signal in the caudate nucleus, which is part of
the basal ganglia. One of the primary functions of the basal ganglia is to
provide a route by which cortical association areas can influence motor action.
The caudate has displayed context-specific, anticipatory, and reward-related
activity in a variety of animal studies (Mink, 1996) and has been associated
with cognitive planning in humans (Monchi, Petrides, Strafella, Worsley, &
Doyon, 2006). It has also been shown to respond to feedback in both reasoning
and guessing tasks when compared to the same tasks without feedback (Elliott,
Frith, & Dolan, 1997).

In cognitive terms, one of the principal features of feedback is that it
systematically removes uncertainty. The fact that both belief and disbelief
showed highly localized signal changes in the caudate, when compared to
uncertainty, appears to implicate basal ganglia circuits in the acceptance or
rejection of linguistic representations of the world. Delgado et al. showed
that the caudate response to feedback can be modulated by prior expectations
(Delgado, Frank, & Phelps, 2005). In a trust game played with three
hypothetical partners (neutral, bad, and good), they found that the caudate
responded strongly to violations of trust by a neutral partner, to a lesser
degree with a bad partner, but not at all when the partner was assumed to be
morally good. On their account, it seems that the assumption of moral goodness
in a partner led subjects to ignore or discount feedback. This result seems
convergent with our own: one might say that subjects in their study were
uncertain of what to conclude when a trusted collaborator failed to cooperate.

The ACC and the caudate display an unusual degree of connectivity, as the
surgical lesioning of the ACC (a procedure known as a cingulotomy) causes
atrophy of the caudate, and the disruption of this pathway is thought to be the
basis of the procedure’s effect in treating conditions like
obsessive-compulsive disorder (Rauch et al., 2000; Rauch et al., 2001).

There are, however, different types of uncertainty. For instance, there is a
difference between expected uncertainty—where one knows that one’s observations
are unreliable—and unexpected uncertainty, where something in the environment
indicates that things are not as they seem. The difference between these two
modes of cognition has been analyzed within a Bayesian statistical framework in
terms of their underlying neurophysiology. It appears that expected uncertainty
is largely mediated by acetylcholine and unexpected uncertainty by
norepinephrine (Yu & Dayan, 2005). Behavioral economists sometimes distinguish
between “risk” and “ambiguity”: the former being a condition where probability
can be assessed, as in a game of roulette, the latter being the uncertainty
borne of missing information. People are generally more willing to take even
very low-probability bets in a condition of risk than they are to act in a
condition of missing information. One group found that ambiguity was negatively
correlated with activity in the dorsal striatum (caudate/putamen) (Hsu, Bhatt,
Adolphs, Tranel, & Camerer, 2005). This result fits very well with our own, as
the uncertainty provoked by our stimuli would have taken the form of
“ambiguity” rather than “risk.”

36. There are many factors that bias our judgment, including: arbitrary anchors
on estimates of quantity, availability biases on estimates of frequency,
insensitivity to the prior probability of outcomes, misconceptions of
randomness, nonregressive predictions, insensitivity to sample size, illusory
correlations, overconfidence, valuing of worthless evidence, hindsight bias,
confirmation bias, biases based on ease of imaginability, as well as other
nonnormative modes of thinking. See Baron, 2008; J. S. B. T. Evans, 2005;
Kahneman, 2003; Kahneman, Krueger, Schkade, Schwarz, & Stone, 2006; Kahneman,
Slovic, & Tversky, 1982; Kahneman & Tversky, 1996; Stanovich & West, 2000;
Tversky & Kahneman, 1974.

37. Stanovich & West, 2000.

38. Fong et al., 1986/07. Once again, asking whether something is rationally or
morally normative is distinct from asking whether it has been evolutionarily
adaptive. Some psychologists have sought to minimize the significance of the
research on cognitive bias by suggesting that subjects make decisions using
heuristics that conferred adaptive fitness on our ancestors. As Stanovich and
West (2000) observe, what serves the genes does not necessarily advance the
interests of the individual. We could also add that what serves the individual
in one context may not serve him in another. The cognitive and emotional
mechanisms that may (or may not) have optimized us for face-to-face conflict
(and its resolution) have clearly not prepared us to negotiate conflicts waged
from afar—whether with email or other long-range weaponry.

39. Ehrlinger, Johnson, Banner, Dunning, & Kruger, 2008; Kruger & Dunning,
1999.

40. Jost, Glaser, Kruglanski, & Sulloway, 2003. Amodio et al. (2007) used EEG
to look for differences in neurocognitive function between liberals and
conservatives on a Go/No-Go task. They found that liberalism correlated with
increased event-related potentials in the anterior cingulate cortex (ACC).
Given the ACC’s well-established role in mediating cognitive conflict, they
concluded that this difference might, in part, explain why liberals are less
set in their ways than conservatives, and more aware of nuance, ambiguity, etc.
Inzlicht (2009) found a nearly identical result for religious nonbelievers
versus believers.

41. Rosenblatt, Greenberg, Solomon, Pyszczynski, & Lyon, 1989.

42. Jost et al., 2003, p. 369.

43. D. A. Pizarro & Uhlmann, 2008.

44. Kruglanski, 1999. The psychologist Drew Westen describes motivated
reasoning as “a form of implicit affect regulation in which the brain converges
on solutions that minimize negative and maximize positive affect states”
(Westen, Blagov, Harenski, Kilts, & Hamann, 2006). This seems apt.

45. The fact that this principle often breaks down, spectacularly and
unselfconsciously, in the domain of religion is precisely why one can
reasonably question whether the world’s religions are in touch with reality at
all.

46. Bechara et al., 2000; Bechara, Damasio, Tranel, & Damasio, 1997; A.
Damasio, 1999.

47. S. Harris et al., 2008.

48. Burton, 2008.

49. Frith, 2008, p. 45.

50. Silver, 2006, pp. 77–78.

51. But this allele has also been linked to a variety of psychological traits,
like novelty seeking and extraversion, which might also account for its
persistence in the genome (Benjamin et al., 1996).

52. Burton, 2008, pp. 188–195.

53. Joseph, 2009.

54. Houreld, 2009; LaFraniere, 2007; Harris, 2009.

55. Mlodinow, 2008.

56. Wittgenstein, 1969, p. 206.

57. Analogical reasoning is generally considered a form of induction (Holyoak,
2005).

58. Sloman & Lagnado, 2005; Tenenbaum, Kemp, & Shafto, 2007.

59. For a review of the literature on deductive reasoning see Evans, 2005.

60. Cf. J. S. B. T. Evans, 2005, pp. 178–179.

61. For example, Canessa et al., 2005; Goel, Gold, Kapur, & Houle, 1997;
Osherson et al., 1998; Prabhakaran, Rypma, & Gabrieli, 2001; Prado, Noveck, &
Van Der Henst, 2009; Rodriguez-Moreno & Hirsch, 2009; Strange, Henson, Friston,
& Dolan, 2001. Goel and Dolan (2003a) found that when syllogistic reasoning was
modulated by a strong belief bias, the ventromedial prefrontal cortex was
preferentially engaged, while such reasoning without an effective belief bias
appeared to be driven by a greater activation of the (right) lateral prefrontal
cortex. Elliot et al. (1997) found that guessing appears to be mediated by the
ventromedial prefrontal cortex. Bechara et al. (1997) report that patients
suffering ventromedial prefrontal damage fail to act according to their correct
conceptual beliefs while engaged in a gambling task. Prior to our 2008 study,
it was unclear how these findings would relate to belief and disbelief per se.
They suggested, however, that the medial prefrontal cortex would be among our
regions of interest.

While decision making is surely related to belief processing, the “decisions”
that neuroscientists have tended to study are those that precede voluntary
movements in tests of sensory discrimination (Glimcher, 2002). The initiation
of such movements requires the judgment that a target stimulus has appeared—we
might even say that this entails the “belief” that an event has occurred—but
such studies are not designed to examine belief as a propositional attitude.
Decision making in the face of potential reward is obviously of great interest
to anyone who would understand the roots of human and animal behavior, but the
link to belief per se appears tenuous. For instance, in a visual-decision task
(in which monkeys were trained to detect the coherent motion of random dots and
signal their direction with eye movements), Gold and Shadlen found that the
brain regions responsible for this sensory judgment were the very regions that
subsequently initiated the behavioral response (Gold & Shadlen, 2000, 2002;
Shadlen & Newsome, 2001). Neurons in these regions appear to act as integrators
of sensory information, initiating the trained behavior whenever a threshold of
activation has been reached. We might be tempted to say, therefore, that the
“belief” that a stimulus is moving to the left is located in the lateral
intraparietal area, the frontal eye fields, and the superior colliculus—as
these are the brain regions responsible for initiating eye movements. But here
we are talking about the “beliefs” of a monkey—a monkey that has been trained
to reproduce a stereotyped response to a specific stimulus in expectation of an
immediate reward. This is not the kind of “belief” that has been the subject of
my research.

The literature on decision making has generally sought to address the link
between voluntary action, error detection, and reward. Insofar as the brain’s
reward system involves a prediction that a specific behavior will lead to
future reward, we might say that this is a matter of belief formation—but there
is nothing to indicate that such beliefs are explicit, linguistically mediated,
or propositional. We know that they cannot be, as most studies of reward
processing have been done in rodents, monkeys, titmice, and pigeons. This
literature has investigated the link between sensory judgments and motor
responses, not the difference between belief and disbelief in matters of
propositional truth. This is not to minimize the fascinating progress that has
occurred in this field. In fact, the same economic modeling that allows
behavioral ecologists to account for the foraging behavior of animal groups
also allows neurophysiologists to describe the activity of the neuronal
assemblies that govern an individual animal’s response to differential rewards
(Glimcher, 2002). There is also a growing literature on neuroeconomics, which
examines human decision making (as well as trust and reciprocity) using
neuroimaging. Some of these findings are discussed here.

62. This becomes especially feasible using more sophisticated techniques of
data analysis, like multivariate pattern classification (Cox & Savoy, 2003; P.
K. Douglas, Harris, & Cohen, 2009). Most analyses of fMRI data are univariate
and merely look for correlations between the activity at each point in the
brain and the task paradigm. This approach ignores the interrelationships that
surely exist between regions. Cox and Savoy demonstrated that a multivariate
approach, in which statistical pattern recognition methods are used to look for
correlations across all regions, allows for a very subtle analysis of fMRI data
in a way that is far more sensitive to distributed patterns of activity (Cox &
Savoy, 2003). With this approach, they were able to determine which visual
stimulus a subject was viewing (out of ten possible types) by examining a mere
20 seconds of his experimental run.

Pamela Douglas, a graduate student in Mark Cohen’s cognitive neuroscience lab
at UCLA, recently took a similar approach to analyzing my original belief data
(P. K. Douglas, Harris, & Cohen, 2009). She created an unsupervised
machine-learning classifier by first performing an independent component (IC)
analysis on each of our subjects’ three scanning sessions. She then selected
the IC time-course values that corresponded to the maximum value of the
hemodynamic response function (HRF) following either “belief” or “disbelief”
events. These values were fed into a selection process, whereby ICs that were
“good predictors” were promoted as features in a classification network for
training a Naïve Bayes classifier. To test the accuracy of her classification,
Douglas performed a leave-one-out cross-validation. Using this criterion, her
Naïve Bayes classifier correctly labeled the “left out” trial 90 percent of the
time. Given such results, it does not seem far-fetched that, with further
refinements in both hardware and techniques of data analysis, fMRI could become
a means for accurate lie detection.

63. Holden, 2001.

64. Broad, 2002.

65. Pavlidis, Eberhardt, & Levine, 2002.

66. Allen & Iacono, 1997; Farwell & Donchin, 1991. Spence et al. (2001) appear
to have published the first neuroimaging study on deception. Their research
suggests that “deception” is associated with bilateral increases in activity in
the ventrolateral prefrontal cortex (BA 47), a region often associated with
response inhibition and the suppression of inappropriate behavior (Goldberg,
2001).

The results of the Spence study were susceptible to some obvious limitations,
however—perhaps most glaring was the fact that the subjects were told precisely
when to lie by being given a visual cue. Needless to say, this did much to rob
the experiment of verisimilitude. The natural ecology of deception is one in
which a potential liar must notice when questions draw near to factual terrain
that he is committed to keeping hidden, and he must lie as the situation
warrants, while respecting the criteria for logical coherence and consistency
that he and his interlocutor share. (It is worth noting that unless one
respects the norms of reasoning and belief formation, it is impossible to lie
successfully. This is not an accident.) To be asked to lie automatically in
response to a visual cue simply does not simulate ordinary acts of deception.
Spence et al. did much to remedy this problem in a subsequent study, where
subjects could lie at their own discretion and on subjects related to their
personal histories (Spence, Kaylor-Hughes, Farrow, & Wilkinson, 2008). This
study largely replicated their findings with respect to the primary involvement
of the ventrolateral PFC (though now almost entirely in the left hemisphere).
There have been other neuroimaging studies of deception—as “guilty knowledge”
(Langleben et al., 2002), “feigned memory impairment” (Lee et al., 2005),
etc.—but the challenge, apart from reliably finding the neural correlates of
any of these states, is to find a result that generalizes to all forms of
deception.

It is not entirely obvious that these studies have given us a sound basis for
detecting deception through neuroimaging. Focusing on the neural correlates of
belief and disbelief might obviate whatever differences exist between types of
deception, the mode of stimulus presentation, etc. Is there a difference, for
instance, between denying what is true and asserting what is false? Recasting
the question in terms of a proposition to be believed or disbelieved might
circumvent any problem posed by the “directionality” of a lie. Another group
(Abe et al., 2006) took steps to address the directionality issue by asking
subjects to alternately deny true knowledge and assert false knowledge.
However, this study suffered from the usual limitations, in that subjects were
directed when to lie, and their lies were limited to whether they had
previously viewed an experimental stimulus.

A functional neuroanatomy of belief might also add to our understanding of the
placebo response—which can be both profound and profoundly unhelpful to the
process of vetting pharmaceuticals. For instance, 65 percent to 80 percent of
the effect of antidepressant medication seems attributable to positive
expectation (Kirsch, 2000). There are even forms of surgery that, while
effective, are no more effective than sham procedures (Ariely, 2008). While
some neuroimaging work has been done in this area, the placebo response is
currently operationalized in terms of symptom relief, without reference to a
subject’s underlying state of mind (Lieberman et al., 2004; Wager et al.,
2004). Finding the neural correlates of belief might allow us to eventually
control for this effect during the process of drug design.

67. Stoller & Wolpe, 2007.

68. Grann, 2009.

69. There are, however, reasons to doubt that our current methods of
neuroimaging, like fMRI, will yield a practical mind-reading technology.
Functional MRI studies as a group have several important limitations. Perhaps
first and most important are those of statistical power and sensitivity. If one
chooses to analyze one’s data at extremely conservative thresholds to exclude
the possibility of type I (false positive) detection errors, this necessarily
increases one’s type II (false negative) error. Further, most studies
implicitly assume uniform detection sensitivity throughout the brain, a
condition known to be violated for the low-bandwidth, fast-imaging scans used
for fMRI. Field inhomogeneity also tends to increase the magnitude of motion
artifacts. When motion is correlated to the stimuli, this can produce false
positive activations, especially in the cortex.

We may also discover that the underlying physics of neuroimaging grants only so
much scope for human ingenuity. If so, an era of cheap, covert lie detection
might never dawn, and we will be forced to rely upon some relentlessly costly,
cumbersome technology. Even so, I think it safe to say that the time is not far
off when lying, on the weightiest matters—in court, before a grand jury, during
important business negotiations, etc.—will become a practical impossibility.
This fact will be widely publicized, of course, and the relevant technology
will be expected to be in place, or accessible, whenever the stakes are high.
This very assurance, rather than the incessant use of these machines, will
change us.

70. Ball, 2009.

71. Pizarro & Uhlmann, 2008.

72. Kahneman, 2003.

73. Rosenhan, 1973.

74. McNeil, Pauker, Sox, & Tversky, 1982.

75. There are other reasoning biases that can affect medical decisions. It is
well known, for instance, that the presence of two similar options can create
“decisional conflict,” biasing a choice in favor of a third alternative. In one
experiment, neurologists and neurosurgeons were asked to determine which
patients to admit to surgery first. Half the subjects were given a choice
between a woman in her early fifties and a man in his seventies. The other half
were given the same two patients, plus another woman in her fifties who was
difficult to distinguish from the first: 38 percent of doctors chose to operate
on the older man in the first scenario; 58 percent chose him in the second
(LaBoeuf & Shafir, 2005). This is a bigger change in outcomes than might be
apparent at first glance: in the first case, the woman’s chance of getting the
surgery is 62 percent; in the second it is 21 percent.

Chapter 4: Religion



1. Marx, [1843] 1971.

2. Freud, [1930] 1994; Freud & Strachey, [1927] 1975.

3. Weber, [1922] 1993.

4. Zuckerman, 2008.

5. Norris & Inglehart, 2004.

6. Finke & Stark, 1998.

7. Norris & Inglehart, 2004, p. 108.

8. It does not seem, however, that socioeconomic inequality explains religious
extremism in the Muslim world, where radicals are, on average, wealthier and
more educated than moderates (Atran, 2003; Esposito, 2008).

9. http://pewglobal.org/reports/display.php?ReportID=258.

10. http://pewforum.org/surveys/campaign08/.

11. Pyysiäinen & Hauser, 2010.

12. Zuckerman, 2008.

13. Paul, 2009.

14. Hall, Matz, & Wood, 2010.

15. Decades of cross-cultural research on “subjective well-being” (SWB) by the
World Values Survey (www.worldvaluessurvey.org) indicate that religion may make
an important contribution to human happiness and life satisfaction at low
levels of societal development, security, and freedom. The happiest and most
secure societies, however, tend to be the most secular. The greatest predictors
of a society’s mean SWB are social tolerance (of homosexuals, gender equality,
other religions, etc.) and personal freedom (Inglehart, Foa, Peterson, &
Welzel, 2008). Of course, tolerance and personal freedom are directly linked,
and neither seems to flourish under the shadow of orthodox religion.

16. Paul, 2009.

17. Culotta, 2009.

18. Buss, 2002.

19. I am indebted to the biologist Jerry Coyne for pointing this out (personal
communication). The neuroscientist Mark Cohen has further observed (personal
communication), however, that many traditional societies are far more tolerant
of male promiscuity than female—for instance, the sanction for being raped has
often been as bad, or worse, than for initiating a rape. Cohen speculates that
in such cases religion may offer a post-hoc justification for a biological
imperative. This may be so. I would only add that here, as elsewhere, the task
of maximizing human well-being is clearly separable from Pleistocene biological
imperatives.

20. Foster & Kokko, 2008.

21. Fincher, Thornhill, Murray, & Schaller, 2008.

22. Dawkins, 1994; D. Dennett, 1994; D. C. Dennett, 2006; D. S. Wilson &
Wilson, 2007; E. O. Wilson, 2005; E. O. Wilson & Holldobler, 2005, pp. 169–172;
Dawkins, 2006.

23. Boyer, 2001; Durkheim & Cosman, [1912] 2001.

24. Stark, 2001, pp. 180–181.

25. Livingston, 2005.

26. Dennett, 2006.

27. http://pewforum.org/docs/?DocID=215.

28. http://pewforum.org/docs/?DocID=153.

29. Boyer, 2001, p. 302.

30. Barrett, 2000.

31. Bloom, 2004.

32. Brooks, 2009.

33. E. M. Evans, 2001.

34. Hood, 2009.

35. D’Onofrio, Eaves, Murrelle, Maes, & Spilka, 1999.

36. Previc, 2006.

37. In addition, the densities of a specific type of serotonin receptor have
been inversely correlated with high scores on the “spiritual acceptance”
subscale of the Temperament and Character Inventory (J. Borg, Andree,
Soderstrom, & Farde, 2003).

38. Asheim, Hansen & Brodtkorb, 2003; Blumer, 1999; Persinger & Fisher, 1990.

39. Brefczynski-Lewis, Lutz, Schaefer, Levinson, & Davidson, 2007; Lutz,
Brefczynski-Lewis, Johnstone, & Davidson, 2008; Lutz, Greischar, Rawlings,
Ricard, & Davidson, 2004; Lutz, Slagter, Dunne, & Davidson, 2008; A. Newberg et
al., 2001.

40. Anastasi & Newberg, 2008; Azari et al., 2001; A. Newberg, Pourdehnad,
Alavi, & d’Aquili, 2003; A. B. Newberg, Wintering, Morgan, & Waldman, 2006;
Schjoedt, Stodkilde-Jorgensen, Geertz, & Roepstorff, 2008, 2009.

41. S. Harris et al., 2008.

42. Kapogiannis et al., 2009.

43. S. Harris et al., 2009.

44. D’Argembeau et al., 2008; Moran, Macrae, Heatherton, Wyland, & Kelley,
2006; Northoff et al., 2006; Schneider et al., 2008.

45. Bechara et al., 2000.

46. Hornak et al., 2004; O’Doherty et al., 2003; Rolls, Grabenhorst, & Parris,
2008.

47. Matsumoto & Tanaka, 2004.

48. A direct comparison of belief minus disbelief in Christians and
nonbelievers did not show any significant group differences for nonreligious
stimuli. For religious stimuli, there were additional regions of the brain that
did differ by group; however, these results seem best explained by a common
reaction in both groups to statements that violate religious doctrines (i.e.,
“blasphemous” statements).

The opposite contrast, disbelief minus belief, yielded increased signal in the
superior frontal sulcus and the precentral gyrus. The engagement of these areas
is not readily explained on the basis of prior work. However, a
region-of-interest analysis revealed increased signal in the insula for this
contrast. This partially replicates our previous finding for this contrast and
supports the work of Kapogiannis et al., who also found signal in the insula to
be correlated with the rejection of religious statements deemed false. The
significance of the anterior insula for negative affect/appraisal has been
discussed above. Because Kapogiannis et al. did not include a nonreligious
control condition in their experiment, they interpreted the insula’s
recruitment as a sign that violations of religious doctrine might provoke
“aversion, guilt, or fear of loss” in people of faith. Whereas, our prior work
suggests that the insula is active for disbelief generally.

In our study, Christians appeared to make the largest contribution to the
insula signal bilaterally, while the pooled data from both groups produced
signal in the left hemisphere exclusively. Kapogiannis et al. also found that
religious subjects produced bilateral insula signal on disbelief trials, while
data from both believers and nonbelievers yielded signal only on the left.
Taken together, these findings suggest that there may be a group difference
between religious believers and nonbelievers with respect to insular activity.
In fact, Inbar et al. found that heightened feelings of disgust are predictive
of social conservatism (as measured by self-reported disgust in response to
homosexuality) (Inbar, Pizarro, Knobe, & Bloom, 2009). Our finding of bilateral
insula signal for this contrast in our first study might be explained by the
fact that we did not control for religious belief (or political orientation)
during recruitment. Given the rarity of nonbelievers in the United States, even
on college campuses, one would expect that most of the subjects in our first
study possessed some degree of religious faith.

49. We obtained these results, despite the fact that our two groups accepted
and rejected diametrically opposite statements in half of our experimental
trials. This would seem to rule out the possibility that our data could be
explained by any property of the stimuli apart from their being deemed “true”
or “false” by the participants in our study.

50. Wager et al., 2004.

51. T. Singer et al., 2004.

52. Royet et al., 2003; Wicker et al., 2003.

53. Izuma, Saito, & Sadato, 2008.

54. Another key region that appears to be preferentially engaged by religious
thinking is the posterior medial cortex. This area is part of the “resting
state” network that shows greater activity during both rest and
self-referential tasks (Northoff et al., 2006). It is possible that one
difference between responding to religious and nonreligious stimuli is that,
for both groups, a person’s answers serve to affirm his or her identity: i.e.,
for every religious trial, Christians were explicitly affirming their religious
worldview, while nonbelievers were explicitly denying the truth claims of
religion.

The opposite contrast, nonreligious minus religious statements, produced
greater signal in left hemisphere memory networks, including the hippocampus,
the parahippocampal gyrus, middle temporal gyrus, temporal pole, and
retrosplenial cortex. It is well known that the hippocampus and the
parahippocampal gyrus are involved in memory retrieval (Diana, Yonelinas, &
Ranganath, 2007). The anterior temporal lobe is also engaged by semantic memory
tasks (K. Patterson, Nestor, & Rogers, 2007), and the retrosplenial cortex
displays especially strong reciprocal connectivity with structures in the
medial temporal lobe (Buckner, Andrews-Hanna, & Schacter, 2008). Thus,
judgments about the nonreligious stimuli presented in our study seemed more
dependent upon those brain systems involved in accessing stored knowledge.

Among our religious stimuli, the subset of statements that ran counter to
Christian doctrine yielded greater signal for both groups in several brain
regions, including the ventral striatum, paracingulate cortex, middle frontal
gyrus, the frontal poles, and inferior parietal cortex. These regions showed
greater signal both when Christians rejected stimuli contrary to their doctrine
(e.g., The Biblical god is a myth) and when nonbelievers affirmed the truth of
those same statements. In other words, these brain areas responded
preferentially to “blasphemous” statements in both subject groups. The ventral
striatum signal in this contrast suggests that decisions about these stimuli
may have been more rewarding for both groups: Nonbelievers may take special
pleasure in making assertions that explicitly negate religious doctrine, while
Christians may enjoy rejecting such statements as false.

55. Festinger, Riecken, & Schachter, [1956] 2008.

56. Atran, 2006a.

57. Atran, 2007.

58. Bostom, 2005; Butt, 2007; Ibrahim, 2007; Oliver & Steinberg, 2005; Rubin,
2009; Shoebat, 2007.

59. Atran, 2006b.

60. Gettleman, 2008.

61. Ariely, 2008, p. 177.

62. Pierre, 2001.

63. Larson & Witham, 1998.

64. Twenty-one percent of American adults (and 14 percent of those born on
American soil) are functionally illiterate
(www.nifl.gov/nifl/facts/reading_facts.html), while only 3 percent of Americans
agree with the statement “I don’t believe in God.” Despite their near
invisibility, atheists are the most stigmatized minority in the United
States—beyond homosexuals, African Americans, Jews, Muslims, Asians, or any
other group. Even after September 11, 2001, more Americans would vote for a
Muslim for president than would vote for an atheist (Edgell, Geteis, &
Hartmann, 2006).

65. Morse, 2009.

66. And if there were a rider to this horse, he would be entirely without
structure and oblivious to the details of perception, cognition, emotion, and
intention that owe their existence to electrochemical activity in specific
regions of the brain. If there is a “pure consciousness” that might occupy such
a role, it will bear little resemblance to what most religious people mean by a
“soul.” A soul this diaphanous would be just as at home in the brain of a hyena
(and seems just as likely to be there) as it would in the brain of a human
being.

67. Levy (2007) poses the same question.

68. Collins, 2006.

69. It is worth recalling in this context that it is, in fact, possible for an
established scientist to destroy his career by saying something stupid. James
Watson, the codiscoverer of the structure of DNA, a Nobel laureate, and the
original head of the Human Genome Project, recently accomplished this feat by
asserting in an interview that people of African descent appear to be innately
less intelligent than white Europeans (Hunte-Grubbe, 2007). A few sentences,
spoken off the cuff, resulted in academic defenestration: lecture invitations
were revoked, award ceremonies canceled, and Watson was forced to immediately
resign his post as chancellor of Cold Spring Harbor Laboratory.

Watson’s opinions on race are disturbing, but his underlying point was not, in
principle, unscientific. There may very well be detectable differences in
intelligence between races. Given the genetic consequences of a population
living in isolation for tens of thousands of years, it would be very surprising
if there were no differences between racial or ethnic groups waiting to be
discovered. I say this not to defend Watson’s fascination with race, or to
suggest that such race-focused research might be worth doing. I am merely
observing that there is, at least, a possible scientific basis for his views.
While Watson’s statement was obnoxious, one cannot say that his views are
utterly irrational or that, by merely giving voice to them, he has repudiated
the scientific worldview and declared himself immune to its further
discoveries. Such a distinction would have to be reserved for Watson’s
successor at the Human Genome Project, Dr. Francis Collins.

70. Collins, 2006, p. 225.

71. Van Biema, 2006; Paulson, 2006.

72. Editorial, 2006.

73. Collins, 2006, p. 178.

74. Ibid., pp. 200–201.

75. Ibid., p. 119.

76. It is true that the mysterious effectiveness of mathematics for describing
the physical world has lured many scientists to mysticism, philosophical
Platonism, and religion. The physicist Eugene Wigner famously posed the problem
in a paper entitled “The Unreasonable Effectiveness of Mathematics in the
Natural Sciences” (Wigner, 1960). While I’m not at all sure that it exhausts
this mystery, I think there is something to be said for Craik’s idea (Craik,
1943) that an isomorphism between brain processes and the processes in the
world that they represent might account for the utility of numbers and certain
mathematical operations. Is it really so surprising that certain patterns of
brain activity (i.e., numbers) can map reliably onto the world?

77. Collins also has a terrible tendency of cherry-picking and misrepresenting
the views of famous scientists like Stephen Hawking and Albert Einstein. For
instance he writes:



Even Albert Einstein saw the poverty of a purely naturalistic worldview.
Choosing his words carefully, he wrote, “science without religion is lame,
religion without science is blind.”



The one choosing words carefully here is Collins. As we saw above, when read in
context (Einstein, 1954, pp. 41–49), this quote reveals that Einstein did not
in the least endorse theism and that his use of the word “God” was a poetical
way of referring to the laws of nature. Einstein had occasion to complain about
such deliberate distortions of his work:



It was, of course, a lie what you read about my religious convictions, a lie
which is being systematically repeated. I do not believe in a personal God and
I have never denied this but have expressed it clearly. If something is in me
which can be called religious then it is the unbounded admiration for the
structure of the world so far as our science can reveal it (cited in R.
Dawkins, 2006, p. 36).



78. Wright, 2003, 2008.

79. Polkinghorne, 2003; Polkinghorne & Beale, 2009.

80. Polkinghorne, 2003, pp. 22–23.

81. In 1996, the physicist Alan Sokal submitted the nonsense paper
“Transgressing the Boundaries: Towards a Transformative Hermeneutics of Quantum
Gravity” to the journal Social Text. While the paper was patently insane, this
journal, which still stands “at the forefront of cultural theory,” avidly
published it. The text is filled with gems like following:



[T]he discourse of the scientific community, for all its undeniable value,
cannot assert a privileged epistemological status with respect to
counter-hegemonic narratives emanating from dissident or marginalized
communities … In quantum gravity, as we shall see, the space-time manifold
ceases to exist as an objective physical reality; geometry becomes relational
and contextual; and the foundational conceptual categories of prior
science—among them, existence itself—become problematized and relativized. This
conceptual revolution, I will argue, has profound implications for the content
of a future postmodern and liberatory science (Sokal, 1996, p. 218).



82. Ehrman, 2005. Bible scholars agree that the earliest Gospels were written
decades after the life of Jesus. We don’t have the original texts of any of the
Gospels. What we have are copies of copies of copies of ancient Greek
manuscripts that differ from one another in literally thousands of places. Many
show signs of later interpolation—which is to say that people have added
passages to these texts over the centuries, and these passages have found their
way into the canon. In fact, there are whole sections of the New Testament,
like the Book of Revelation, that were long considered spurious, that were
included in the Bible only after many centuries of neglect; and there are other
books, like the Shepherd of Hermas, that were venerated as part of the Bible
for hundreds of years only to be rejected finally as false scripture.
Consequently, it is true to say that generations of Christians lived and died
having been guided by scripture that is now deemed to be both mistaken and
incomplete by the faithful. In fact, to this day, Roman Catholics and
Protestants cannot agree on the full contents of the Bible. Needless to say,
such a haphazard and all-too-human process of cobbling together the
authoritative word of the Creator of the Universe seems a poor basis for
believing that the miracles of Jesus actually occurred.

The philosopher David Hume made a very nice point about believing in miracles
on the basis of testimony: “No testimony is sufficient to establish a miracle,
unless the testimony be of such a kind, that its falsehood would be more
miraculous, than the fact, which it endeavours to establish …” (Hume, 1996,
vol. IV, p. 131). This is a good rule of thumb. Which is more likely, that
Mary, the mother of Jesus, would have sex outside of wedlock and then feel the
need to lie about it, or that she would conceive a child through
parthenogenesis the way aphids and Komodo dragons do? On the one hand, we have
the phenomenon of lying about adultery—in a context where the penalty for
adultery is death—and on the other, we have a woman spontaneously mimicking the
biology of certain insects and reptiles. Hmm …

83. Editorial, 2008.

84. Maddox, 1981.

85. Sheldrake, 1981.

86. I have publicly lamented this double standard on a number of occasions (S.
Harris, 2007a; S. Harris & Ball, 2009)

87. Collins, 2006, p. 23.

88. Langford et al., 2006.

89. Masserman et al., 1964.

90. Our picture of chimp notions of fairness is somewhat muddled. There is no
question that they notice inequity, but they do not seem to care if they profit
from it (Brosnan, 2008; Brosnan, Schiff, & de Waal, 2005; Jensen, Call, &
Tomasello, 2007; Jensen, Hare, Call, & Tomasello, 2006; Silk et al., 2005).

91. Range et al., 2009.

92. Siebert, 2009.

93. Silver, 2006, p. 157.

94. Ibid., p. 162.

95. Collins, 2006.

96. Of course, I also received much support, especially from scientists, and
even from scientists at the NIH.

97. Miller, it should be noted, is also a believing Christian and the author of
Finding Darwin’s God (K. R. Miller, 1999). For all its flaws, this book
contains an extremely useful demolition of “intelligent design.”

98. C. Mooney & S. Kirshenbaum, 2009, pp. 97–98.

99. The claim is ubiquitous, even at the highest levels of scientific
discourse. From a recent editorial in Nature, insisting on the reality of human
evolution:



The vast majority of scientists, and the majority of religious people, see
little potential for pleasure or progress in the conflicts between religion and
science that are regularly fanned into flame by a relatively small number on
both sides of the debate. Many scientists are religious, and perceive no
conflict between the values of their science—values that insist on
disinterested, objective inquiry into the nature of the Universe—and those of
their faith (Editorial, 2007).



From the National Academy of Sciences:



Science can neither prove nor disprove religion … Many scientists have written
eloquently about how their scientific studies have increased their awe and
understanding of a creator … The study of science need not lessen or compromise
faith (National Academy of Sciences [U.S.] & Institute of Medicine [U.S.],
2008, p. 54).



Chapter 5: The Future of Happiness



1. Allen, 2000.

2. Los Angeles Times, July 5, 1910.

3. As indicated above, I think it is reasonably clear that concerns about
angering God and/or suffering an eternity in hell are based on specific notions
of harm. Not believing in God or hell leaves one blissfully unconcerned about
such liabilities. Under Haidt’s analysis, concerns about God and the afterlife
would seem to fall under the categories of “authority” and/or “purity.” I think
such assignments needlessly parcel what is, at bottom, a more general concern
about harm.

4. Inbar et al., 2009.

5. Schwartz, 2004.

6. D. T. Gilbert, 2006.

7. www.ted.com/talks/daniel_kahneman_the_riddle_of_experience_vs_memory.html.

8. Ibid.

9. Lykken & Tellegen, 1996.

10. D. T. Gilbert, 2006, pp. 220–222.

11. Simonton, 1994.

12. Rilling et al., 2002.





REFERENCES





Aaronovitch, D. (2010). Voodoo histories: The role of the conspiracy theory in
shaping modern history. New York: Riverhead Books.



Abe, N., Suzuki, M., Tsukiura, T., Mori, E., Yamaguchi, K., Itoh, M., et al.
(2006). Dissociable roles of prefrontal and anterior cingulate cortices in
deception. Cereb Cortex, 16 (2), 192–199.



Abraham, A., & von Cramon, D. Y. (2009). Reality = relevance? Insights from
spontaneous modulations of the brain’s default network when telling apart
reality from fiction. PLoS ONE, 4 (3), e4741.



Abraham, A., von Cramon, D. Y., & Schubotz, R. I. (2008). Meeting George Bush
versus meeting Cinderella: The neural response when telling apart what is real
from what is fictional in the context of our reality. J Cogn Neurosci, 20 (6),
965–976.



Adolphs, R., Tranel, D., Koenigs, M., & Damasio, A. R. (2005). Preferring one
taste over another without recognizing either. Nat Neurosci, 8 (7), 860–861.



Ainslie, G. (2001). Breakdown of will. Cambridge, UK: Cambridge University
Press.



Allen, J. (2000). Without sanctuary: Lynching photography in America. Santa Fe,
NM: Twin Palms.



Allen, J. J., & Iacono, W. G. (1997). A comparison of methods for the analysis
of event-related potentials in deception detection. Psychophysiology, 34 (2),
234–240.



Amodio, D. M., Jost, J. T., Master, S. L., & Yee, C. M. (2007). Neurocognitive
correlates of liberalism and conservatism. Nat Neurosci, 10 (10), 1246–1247.



Anastasi, M. W., & Newberg, A. B. (2008). A preliminary study of the acute
effects of religious ritual on anxiety. J Altern Complement Med, 14 (2),
163–165.



Anderson, A. K., Christoff, K., Panitz, D., De Rosa, E., & Gabrieli, J. D.
(2003). Neural correlates of the automatic processing of threat facial signals.
J Neurosci, 23 (13), 5627–5633.



Andersson, J. L. R., Jenkinson, M., & Smith, S. M. (2007). Non-linear
registration, aka spatial normalisation. FMRIB technical report, TR07JA2.



Andersson, J. L. R., Jenkinson, M., & Smith, S. M. (2007). Non-linear
optimisation. FMRIB technical report, TR07JA1.



Appiah, A. (2008). Experiments in ethics. Cambridge, MA: Harvard University
Press.



Ariely, D. (2008). Predictably irrational. New York: Harper Collins.



Asheim Hansen, B., & Brodtkorb, E. (2003). Partial epilepsy with “ecstatic”
seizures. Epilepsy Behav, 4 (6), 667–673.



Atchley, R. A., Ilardi, S. S., & Enloe, A. (2003). Hemispheric asymmetry in the
processing of emotional content in word meanings: The effect of current and
past depression. Brain Lang, 84 (1), 105–119.



Atran, S. (2003, May 5). Who wants to be a martyr? New York Times.



Atran, S. (2006a). Beyond belief: Further discussion. Retrieved June 11, 2008,
from www.edge.org/discourse/bb.html.



Atran, S. (2006b). What would Gandhi do today? Nonviolence in an age of
terrorism. Retrieved from
http://sitemaker.umich.edu/satran/relevant_articles_on_terrorism.



Atran, S. (2007). Paper presented at the Beyond Belief: Enlightenment 2.0.
Retrieved from



p://thesciencenetwork.org/programs/beyond-belief-enlightenment-2-0/scott-atran.



Azari, N. P., Nickel, J., Wunderlich, G., Niedeggen, M., Hefter, H., Tellmann,
L., et al. (2001). Neural correlates of religious experience. Eur J Neurosci,
13 (8), 1649–1652.



Baars, B. J., & Franklin, S. (2003). How conscious experience and working
memory interact. Trends Cogn Sci, 7 (4), 166–172.



Babiak, P., & Hare, R. D. (2006). Snakes in suits: When psychopaths go to work
(1st ed.). New York: Regan Books.



Ball, P. (2009, June 25). And another thing … Retrieved July 6, 2009, from
http://philipball.blogspot.com.



Baron, A. S., & Banaji, M. R. (2006). The development of implicit attitudes.
Evidence of race evaluations from ages 6 and 10 and adulthood. Psychol Sci, 17
(1), 53–58.



Baron, J. (2008). Thinking and deciding (4th ed.). New York: Cambridge
University Press.



Baron-Cohen, S. (1995). Mindblindness: An essay on autism and theory of mind.
Cambridge, MA: MIT Press.



Barrett, J. L. (2000). Exploring the natural foundations of religion. Trends
Cogn Sci, 4 (1), 29–34.



Bauby, J.-D. (1997). The diving bell and the butterfly (1st U.S. ed.). New
York: A. A. Knopf.



Baumeister, R. F. (2001). Violent pride. Sci Am, 284 (4), 96–101.



Baumeister, R. F., Campbell, J. D., Krueger, J. I., & Vohs, K. D. (2005).
Exploding the self-esteem myth. Sci Am, 292 (1), 70–77.



Bawer, B. (2006). While Europe slept: How radical Islam is destroying the West
from within (1st ed.). New York: Doubleday.



Bechara, A., Damasio, H., & Damasio, A. R. (2000). Emotion, decision making and
the orbitofrontal cortex. Cereb Cortex, 10 (3), 295–307.



Bechara, A., Damasio, H., Tranel, D., & Damasio, A. R. (1997). Deciding
advantageously before knowing the advantageous strategy. Science, 275 (5304),
1293–1295.



Begg, I. M., Robertson, R. K., Gruppuso, V., Anas, A., & Needham, D. R. (1996).
The Illusory-knowledge effect. Journal of Memory and Language, 35, 410–433.



Benedetti, F., Mayberg, H. S., Wager, T. D., Stohler, C. S., & Zubieta, J. K.
(2005). Neurobiological mechanisms of the placebo effect. J Neurosci, 25 (45),
10390–10402.



Benedict, R. (1934). Patterns of culture. Boston, New York: Houghton Mifflin.



Benjamin, J., Li, L., Patterson, C., Greenberg, B. D., Murphy, D. L., & Hamer,
D. H. (1996). Population and familial association between the D4 dopamine
receptor gene and measures of novelty seeking. Nat Genet, 12 (1), 81–84.



Bilefsky, D. (2008, July 10). In Albanian feuds, isolation engulfs families.
New York Times.



Blackmore, S. J. (2006). Conversations on consciousness: What the best minds
think about the brain, free will, and what it means to be human. Oxford, UK;
New York: Oxford University Press.



Blair, J., Mitchell, D. R., & Blair, K. (2005). The psychopath: Emotion and the
brain. Malden, MA: Blackwell.



Blakemore, S. J., & Frith, C. (2003). Self-awareness and action. Curr Opin
Neurobiol, 13 (2), 219–224.



Blakemore, S. J., Oakley, D. A., & Frith, C. D. (2003). Delusions of alien
control in the normal brain. Neuropsychologia, 41 (8), 1058–1067.



Blakemore, S. J., Rees, G., & Frith, C. D. (1998). How do we predict the
consequences of our actions? A functional imaging study. Neuropsychologia, 36
(6), 521–529.



Blakeslee, S. (2007, February 6). A small part of the brain, and its profound
effects. New York Times.



Block, N. (1995). On a confusion about the function of consciousness.
Behavioral and Brain Sciences, 18, 227–247.



Block, N., Flanagan, O., & Güzeldere, G. (1997). The Nature of Consciousness:
Philosophical Debates. Cambridge, MA: The MIT Press.



Bloom, P. (2004). Descartes’ baby: How the science of child development
explains what makes us human. New York: Basic Books.



Bloom, P. (2010, May 9). The moral life of babies. New York Times Magazine.



Blow, C. M. (2009, June 26). The prurient trap. New York Times.



Blumer, D. (1999). Evidence supporting the temporal lobe epilepsy personality
syndrome. Neurology, 53 (5 Suppl 2), S9–12.



Bogen, G. M., & Bogen, J. E. (1986). On the relationship of cerebral duality to
creativity. Bull Clin Neurosci, 51, 30–32.



Bogen, J. E. (1986). Mental duality in the intact brain. Bull Clin Neurosci,
51, 3–29.



Bogen, J. E. (1995a). On the neurophysiology of consciousness: Pt. II.
Constraining the semantic problem. Conscious Cogn, 4 (2), 137–158.



Bogen, J. E. (1995b). On the neurophysiology of consciousness: Pt. I. An
overview. Conscious Cogn, 4 (1), 52–62.



Bogen, J. E. (1997). Does cognition in the disconnected right hemisphere
require right hemisphere possession of language? Brain Lang, 57 (1), 12–21.



Bogen, J. E. (1998). My developing understanding of Roger Wolcott Sperry’s
philosophy. Neuropsychologia, 36 (10), 1089–1096.



Bogen, J. E., Sperry, R. W., & Vogel, P. J. (1969). Addendum: Commissural
section and propagation of seizures. In Jasper et al. (Ed.), Basic mechanisms
of the epilepsies. Boston: Little, Brown and Company, 439.



Bok, H. (2007). The implications of advances in neuroscience for freedom of the
will. Neurotherapeutics, 4 (3), 555–559.



Borg, J., Andree, B., Soderstrom, H., & Farde, L. (2003). The serotonin system
and spiritual experiences. Am J Psychiatry, 160 (11), 1965–1969.



Borg, J. S., Lieberman, D., & Kiehl, K. A. (2008). Infection, incest, and
iniquity: investigating the neural correlates of disgust and morality. J Cogn
Neurosci, 20 (9), 1529–1546.



Bostom, A. G. (2005). The legacy of Jihad: Islamic holy war and the fate of
non-Muslims. Amherst, NY: Prometheus Books.



Bostrom, N. (2003). Are we living in a computer simulation? Philosophical
Quarterly, 53 (211), 243–255.



Bostrom, N., & Ord, T. (2006). The reversal test: Eliminating status quo bias
in applied ethics. Ethics 116, 656–679.



Bouchard, T. J., Jr. (1994). Genes, environment, and personality. Science, 264
(5166), 1700–1701.



Bouchard, T. J., Jr., Lykken, D. T., McGue, M., Segal, N. L., & Tellegen, A.
(1990). Sources of human psychological differences: The Minnesota study of
twins reared apart. Science, 250 (4978), 223–228.



Bouchard, T. J., Jr., McGue, M., Lykken, D., & Tellegen, A. (1999). Intrinsic
and extrinsic religiousness: genetic and environmental influences and
personality correlates. Twin Res, 2 (2), 88–98.



Bowles, S. (2006). Group competition, reproductive leveling, and the evolution
of human altruism. Science, 314 (5805), 1569–1572.



Bowles, S. (2008). Being human: Conflict: Altruism’s midwife. Nature, 456
(7220), 326–327.



Bowles, S. (2009). Did warfare among ancestral hunter-gatherers affect the
evolution of human social behaviors? Science, 324 (5932), 1293–1298.



Boyer, P. (2001). Religion explained: The evolutionary origins of religious
thought. New York: Basic Books.



Boyer, P. (2003). Religious thought and behaviour as by-products of brain
function. Trends Cogn Sci, 7 (3), 119–124.



Bransford, J. D., & McCarrell, N. S. (1977). A sketch of a cognitive approach
to comprehension: Some thoughts about understanding what it means to
comprehend. In P. N. Johnson-Laird & P. C. Wason (Eds.), Thinking (pp.
377–399). Cambridge, UK: Cambridge University Press.



Brefczynski-Lewis, J. A., Lutz, A., Schaefer, H. S., Levinson, D. B., &
Davidson, R. J. (2007). Neural correlates of attentional expertise in long-term
meditation practitioners. Proc Natl Acad Sci USA, 104 (27), 11483–11488.



Broad, W. J. (2002, October, 9). Lie-detector tests found too flawed to
discover spies. New York Times.



Broks, P. (2004). Into the silent land: Travels in neuropsychology. New York:
Atlantic Monthly Press.



Brooks, M. (2009). Born believers: How your brain creates God. New Scientist
(2694) Feb. 4, 30–33.



Brosnan, S. F. (2008). How primates (including us!) respond to inequity. Adv
Health Econ Health Serv Res, 20, 99–124.



Brosnan, S. F., Schiff, H. C., & de Waal, F. B. (2005). Tolerance for inequity
may increase with social closeness in chimpanzees. Proc Biol Sci, 272 (1560),
253–258.



Buckholtz, J. W., Treadway, M. T., Cowan, R. L., Woodward, N. D., Benning, S.
D., Li, R., et al. (2010). Mesolimbic dopamine reward system hypersensitivity
in individuals with psychopathic traits. Nat Neurosei, 13 (4), 419–421.



Buckner, R. L., Andrews-Hanna, J. R., & Schacter, D. L. (2008). The brain’s
default network: Anatomy, function, and relevance to disease. Ann NY Acad Sci,
1124, 1–38.



Buehner, M. J., & Cheng, P. W. (2005). Causal learning. In K. J. Holyoak & R.
G. Morrison (Eds.), The Cambridge handbook of thinking and reasoning (pp.
143–168). New York: Cambridge University Press.



Bunge, S. A., Ochsner, K. N., Desmond, J. E., Glover, G. H., & Gabrieli, J. D.
(2001). Prefrontal regions involved in keeping information in and out of mind.
Brain, 124 (Pt. 10), 2074–2086.



Burgess, P. W., & McNeil, J. E. (1999). Content-specific confabulation. Cortex,
35 (2), 163–182.



Burns, K., & Bechara, A. (2007). Decision making and free will: a neuroscience
perspective. Behav Sci Law, 25 (2), 263–280.



Burton, H., Snyder, A. Z., & Raichle, M. E. (2004). Default brain functionality
in blind people. Proc Natl Acad Sci USA, 101 (43), 15500–15505.



Burton, R. A. (2008). On being certain: Believing you are right even when
you’re not (1st ed.). New York: St. Martin’s Press.



Buss, D. (2002). Sex, marriage, and religion: What adaptive problems do
religious phenomena solve? Psychological Inquiry, 13 (3), 201–203.



Butt, H. (2007, July 2). I was a fanatic … I know their thinking, says former
radical Islamist. Daily Mail.



Calder, A. J., Keane, J., Manes, F., Antoun, N., & Young, A. W. (2000).
Impaired recognition and experience of disgust following brain injury. Nat
Neurosci, 3 (11), 1077–1078.



Caldwell, C. (2009). Reflections on the revolution in Europe: Immigration,
Islam, and the West. New York: Doubleday.



Camerer, C. F. (2003). Psychology and economics. Strategizing in the brain.
Science, 300 (5626), 1673–1675.



Canessa, N., Gorini, A., Cappa, S. F., Piattelli-Palmarini, M., Danna, M.,
Fazio, F., et al. (2005). The effect of social content on deductive reasoning:
An fMRI study. Hum Brain Mapp, 26 (1), 30–43.



Canli, T., Brandon, S., Casebeer, W., Crowley, P. J., Du Rousseau, D., Greely,
H. T., et al. (2007a). Neuroethics and national security. Am J Bioeth, 7 (5),
3–13.



Canli, T., Brandon, S., Casebeer, W., Crowley, P. J., Durousseau, D., Greely,
H. T., et al. (2007b). Response to open peer commentaries on “Neuroethics and
national security.” Am J Bioeth, 7 (5), W1–3.



Canli, T., Sivers, H., Whitfield, S. L., Gotlib, I. H., & Gabrieli, J. D.
(2002). Amygdala response to happy faces as a function of extraversion.
Science, 296 (5576), 2191.



Carroll, S. (2010). Science and morality: You can’t derive “ought” from “is.”
NPR: 13.7 Cosmos and Culture,
www.npr.org/templates/story/story.php?storyId=126504492.



Carroll, S. (2010a). The moral equivalent of the parallel postulate. Cosmic
Variance, (March 24)





























.com/cosmicvariance/2010/03/24/the-moral-equivalent-of-the-parallel-postulate/.



Carson, A. J., MacHale, S., Allen, K., Lawrie, S. M., Dennis, M., House, A., et
al. (2000). Depression after stroke and lesion location: a systematic review.
Lancet, 356 (9224), 122–126.



Carter, C. S., Braver, T. S., Barch, D. M., Botvinick, M. M., Noll, D., &
Cohen, J. D. (1998). Anterior cingulate cortex, error detection, and the online
monitoring of performance. Science, 280 (5364), 747–749.



Casebeer, W. D. (2003). Natural ethical facts: Evolution, connectionism, and
moral cognition. Cambridge, MA: MIT Press.



Chalmers, D. J. (1995). The puzzle of conscious experience. Sci Am, 273 (6),
80–86.



Chalmers, D. J. (1996). The conscious mind: In search of a fundamental theory.
New York: Oxford University Press.



Chalmers, D. J. (1997). Moving forward on the problem of consciousness. Journal
of Consciousness Studies, 4 (1), 3–46.



Choi, J. K., & Bowles, S. (2007). The coevolution of parochial altruism and
war. Science, 318 (5850), 636–640.



Christoff, K., Gordon, A. M., Smallwood, J., Smith, R., & Schooler, J. W.
(2009). Experience sampling during fMRI reveals default network and executive
system contributions to mind wandering. Proc Natl Acad Sci USA (May 26) 106
(21), 8719–24.



Church, R. M. (1959). Emotional reactions of rats to the pain of others. J Comp
Physiol Psychol, 52 (2), 132–134.



Churchland, P. M. (1979). Scientific realism and the plasticity of mind.
Cambridge, UK: Cambridge University Press.



Churchland, P. M. (1988). Matter and consciousness. Cambridge, MA: MIT Press.



Churchland, P. M. (1995). The engine of reason, the seat of the soul: A
philosophical journey into the brain. Cambridge, MA: MIT Press.



Churchland, P. M. (1997). Knowing qualia: A reply to Jackson. In N. Block, O.
Flanagan, & G. Güzeldere (Eds.), The nature of consciousness: Philosophical
debates (pp. 571–578). Cambridge, MA: MIT Press.



Churchland, P. S. (2008b). Morality & the social brain. Unpublished manuscript.



Churchland, P. S. (2009). Inference to the best decision. In J. Bickle (Ed.),
Oxford Handbook of philosophy and neuroscience. Oxford: Oxford University
Press, 419–430.



Cleckley, H. M. ([1941] 1982). The mask of sanity (Rev. ed.). New York: New
American Library.



Coghill, R. C., McHaffie, J. G., & Yen, Y. F. (2003). Neural correlates of
inter-individual differences in the subjective experience of pain. Proc Natl
Acad Sci USA, 100 (14), 8538–8542.



Cohen, J. D., & Blum, K. I. (2002). Reward and decision. Neuron, 36 (2),
193–198.



Cohen, J. D., & Tong, F. (2001). Neuroscience. The face of controversy.
Science, 293 (5539), 2405–2407.



Cohen, M. (1996). Functional MRI: a phrenology for the 1990’s? J Magn Reson
Imaging, 6 (2), 273–274.



Cohen, M. S. (1999). Echo-planar imaging and functional MRI. In C. Moonen & P.
Bandettini (Eds.), Functional MRI (pp. 137–148). Berlin: Springer-Verlag.



Cohen, M. S. (2001). Practical aspects in the design of mind reading
instruments. American Journal of Neuroradiology.



Cohen, M. S. (2001). Real-time functional magnetic resonance imaging. Methods,
25 (2), 201–220.



Collins, F. S. (2006). The language of God: A scientist presents evidence for
belief. New York: Free Press.



Comings, D. E., Gonzales, N., Saucier, G., Johnson, J. P., & MacMurray, J. P.
(2000). The DRD4 gene and the spiritual transcendence scale of the character
temperament index. Psychiatr Genet, 10 (4), 185–189.



Cooney, J. W., & Gazzaniga, M. S. (2003). Neurological disorders and the
structure of human consciousness. Trends Cogn Sci, 7 (4), 161–165.



Corballis, M. C. (1998). Sperry and the age of Aquarius: Science, values and
the split brain. Neuropsychologia, 36 (10), 1083–1087.



Cox, D. D., & Savoy, R. L. (2003). Functional magnetic resonance imaging (fMRI)
“brain reading”: Detecting and classifying distributed patterns of fMRI
activity in human visual cortex. Neuroimage, 19 (2 Pt. 1), 261–270.



Craig, A. D. (2002). How do you feel? Interoception: the sense of the
physiological condition of the body. Nat Rev Neurosci, 3 (8), 655–666.



Craig, A. D. (2009). How do you feel—now? The anterior insula and human
awareness. Nat Rev Neurosci, 10 (1), 59–70.



Craig, M. C., Catani, M., Deeley, Q., Latham, R., Daly, E., Kanaan, R., et al.
(2009). Altered connections on the road to psychopathy. Mol Psychiatry, 14
(10), 946–953.



Craik, K. (1943). Hypothesis on the nature of thought. The nature of
explanation. Cambridge, UK: Cambridge University Press.



Crick, F. (1994). The astonishing hypothesis: The scientific search for the
soul. New York: Charles Scribner’s Sons.



Crick, F., & Koch, C. (1998). Consciousness and neuroscience. Cereb. Cortex, 8,
97–107.



Crick, F., & Koch, C. (1999). The unconscious homunculus. In T. Metzinger
(Ed.), The neural correlates of consciousness (pp. 103–110). Cambridge, MA: MIT
Press.



Crick, F., & Koch, C. (2003). A framework for consciousness. Nat Neurosci, 6
(2), 119–126.



Culotta, E. (2009). Origins. On the origin of religion. Science, 326 (5954),
784–787.



D’Argembeau, A., Feyers, D., Majerus, S., Collette, F., Van der Linden, M.,
Maquet, P., et al. (2008). Self-reflection across time: Cortical midline
structures differentiate between present and past selves. Soc Cogn Affect
Neurosci, 3 (3), 244–252.



D’Onofrio, B. M., Eaves, L. J., Murrelle, L., Maes, H. H., & Spilka, B. (1999).
Understanding biological and social influences on religious affiliation,
attitudes, and behaviors: A behavior genetic perspective. J Pers, 67 (6),
953–984.



Damasio, A. (1999). The feeling of what happens: Body and emotion in the making
of consciousness. New York: Harcourt Brace.



Damasio, A. R. (1999). Thinking about belief: Concluding remarks. In D. L.
Schacter & E. Scarry (Eds.), Memory, brain, and belief (pp. 325–333).
Cambridge, MA: Harvard University Press.



Davidson, D. (1987). Knowing one’s own mind. Proceedings and addresses of the
American Philosophical Association, 61, 441–458.



Dawkins, R. (1994). Burying the vehicle. Behavioural and Brain Sciences, 17
(4), 616–617.



Dawkins, R. (1996). Climbing mount improbable. New York: Norton.



Dawkins, R. (2006). The God delusion. New York: Houghton Mifflin.



Dawkins, R. ([1976] 2006). The selfish gene. Oxford, UK: New York: Oxford
University Press.



Dawkins, R. (2010a, March 28). Ratzinger is the perfect pope. Washington Post:
On Faith.



Dawkins, R. (2010b, April 13). The pope should stand trial. The Guardian.



De Grey, A. D. N. J., & Rae, M. (2007). Ending aging: The rejuvenation
breakthroughs that could reverse human aging in our lifetime. New York: St.
Martin’s Press.



De Neys, W., Vartanian, O., & Goel, V. (2008). Smarter than we think: When our
brains detect that we are biased. Psychol Sci, 19 (5), 483–489.



de Oliveira-Souza, R., Hare, R. D., Bramati, I. E., Garrido, G. J., Azevedo
Ignacio, F., Tovar-Moll, F., et al. (2008). Psychopathy as a disorder of the
moral brain: Fronto-temporo-limbic grey matter reductions demonstrated by
voxel-based morphometry. Neuroimage, 40 (3), 1202–1213.



Deaner, R. O., Isler, K., Burkart, J., & van Schaik, C. (2007). Overall brain
size, and not encephalization quotient, best predicts cognitive ability across
non-human primates. Brain Behav Evol, 70 (2), 115–124.



Delacour, J. (1995). An introduction to the biology of consciousness.
Neuropsychologia, 33 (9), 1061–1074.



Delgado, M. R., Frank, R. H., & Phelps, E. A. (2005). Perceptions of moral
character modulate the neural systems of reward during the trust game. Nat
Neurosci, 8 (11), 1611–1618.



Dennett, D. (1990). Quining qualia. In W. Lycan (Ed.), Mind and cognition: A
reader (pp. 519–547). Oxford: Blackwell.



Dennett, D. (1994). E pluribus unum? Commentary on Wilson & Sober: Group
selection. Behavioural and Brain Sciences, 17 (4), 617–618.



Dennett, D. (1996). Facing backwards on the problem of consciousness. Journal
of Consciousness Studies, 3 (1), 4–6.



Dennett, D. C. (1987). The intentional stance. Cambridge, Mass.: MIT Press.



Dennett, D. C. (1991). Consciousness explained (1st Ed.). Boston: Little, Brown
& Co.



Dennett, D. C. (1995). Darwin’s dangerous idea: Evolution and the meanings of
life (1st ed.). New York: Simon & Schuster.



Dennett, D. C. (2003). Freedom evolves. New York: Viking.



Dennett, D. C. (2006). Breaking the spell: Religion as a natural phenomenon.
London: Allen Lane.



Desimone, R., & Duncan, J. (1995). Neural mechanisms of selective visual
attention. Annu Rev Neurosci, 18, 193–222.



Diamond, J. (2008, April 21). Vengeance is ours. New Yorker, 74–87.



Diamond, J. M. (1997). Guns, germs, and steel: The fates of human societies
(1st ed.). New York: W.W. Norton & Co.



Diamond, J. M. (2005). Collapse: How societies choose to fail or succeed. New
York: Viking.



Diana, R. A., Yonelinas, A. P., & Ranganath, C. (2007). Imaging recollection
and familiarity in the medial temporal lobe: a three-component model. Trends
Cogn Sci, 11 (9), 379–386.



Diener, E., Oishi, S., & Lucas, R. E. (2003). Personality, culture, and
subjective well-being: Emotional and cognitive evaluations of life. Annu Rev
Psychol, 54, 403–425.



Ding, Y. C., Chi, H. C., Grady, D. L., Morishima, A., Kidd, J. R., Kidd, K. K.,
et al. (2002). Evidence of positive selection acting at the human dopamine
receptor D4 gene locus. Proc Natl Acad Sci USA, 99 (1), 309–314.



Dolan, M., & Fullam, R. (2004). Theory of mind and mentalizing ability in
antisocial personality disorders with and without psychopathy. Psychol Med, 34
(6), 1093–1102.



Dolan, M., & Fullam, R. (2006). Face affect recognition deficits in
personality-disordered offenders: Association with psychopathy. Psychol Med, 36
(11), 1563–1569.



Donadio, R. (2010a, March 26). Pope may be at crossroads on abuse, forced to
reconcile policy and words. New York Times.



Donadio, R. (2010b, April 29). In abuse crisis, a church is pitted against
society and itself. New York Times.



Doty, R. W. (1998). The five mysteries of the mind, and their consequences.
Neuropsychologia, 36 (10), 1069–1076.



Douglas, P. K., Harris, S., & Cohen, M. S. (2009). Naïve Bayes classification
of belief versus disbelief using event related neuroimaging data. Paper
presented at the Organization for Human Brain Mapping 2009 (July) Annual
Meeting.



Douglas, R. J., & Martin, K. A. (2007). Recurrent neuronal circuits in the
neocortex. Curr Biol, 17 (13), R496–500.



Doumas, L. A. A., & Hummel, J. E. (2005). Approaches to modeling human mental
representations: What works, what doesn’t, and why. In K. J. Holyoak & R. G.
Morrison (Eds.), The Cambridge handbook of thinking and reasoning (pp. 73–91).
New York: Cambridge University Press.



Dressing, H., Sartorius, A., & Meyer-Lindenberg, A. (2008). Implications of
fMRI and genetics for the law and the routine practice of forensic psychiatry.
Neurocase, 14 (1), 7–14.



Dronkers, N. F. (1996). A new brain region for coordinating speech
articulation. Nature, 384 (6605), 159–161.



Dunbar, R. (1998). The social brain hypothesis. Evolutionary Anthropology, 6,
178–190.



Dunbar, R. (2003). Psychology. Evolution of the social brain. Science, 302
(5648), 1160–1161.



Dunbar, R. (2006). We believe. New Scientist, 189 (2536), 30–33.



Duncan, J., & Owen, A. M. (2000). Common regions of the human frontal lobe
recruited by diverse cognitive demands. Trends Neurosci, 23 (10), 475–483.



Durkheim, E. (2001 [1912]). The elementary forms of religious life. (C. Cosmen,
Trans.) Oxford, UK; New York: Oxford University Press.



Dyson, F. (2002). The conscience of physics. Nature, 420 (12 December),
607–608.



Eddington, A. S. (1928). The nature of the physical world. Cambridge, UK:
Cambridge University Press.



Edelman, G. M. (1989). The remembered present: A biological theory of
consciousness. New York: Basic Books.



Edelman, G. M. (2004). Wider than the sky: The phenomenal gift of
consciousness. New Haven: Yale University Press.



Edelman, G. M. (2006). Second nature: Brain science and human knowledge. New
Haven: Yale University Press.



Edelman, G. M., & Tononi, G. (2000). A universe of consciousness: How matter
becomes imagination (1st ed.). New York, NY: Basic Books.



Edgell, P., Geteis, J., & Hartmann, D. (2006). Atheists as “other”: Moral
boundaries and cultural membership in American society. American Sociological
Review, 71 (April), 211–234.



Edgerton, R. B. (1992). Sick societies: Challenging the myth of primitive
harmony. New York: Free Press.



Editorial, N. (2006a). Neuroethics needed. Nature, 441 (7096), 907.



Editorial, N. (2006b). Building bridges. Nature, 442 (7099), 110.



Editorial, N. (2007). Evolution and the brain. Nature, 447 (7146), 753.



Editorial, N. (2008). Templeton’s legacy. Nature, 454 (7202), 253–254.



Egnor, S. E. (2001). Effects of binaural decorrelation on neural and behavioral
processing of interaural level differences in the barn owl (Tyto alba). J Comp
Physiol [A], 187 (8), 589–595.



Ehrlinger, J., Johnson, K., Banner, M., Dunning, D., & Kruger, J. (2008). Why
the unskilled are unaware: Further explorations of (absent) self-insight among
the incompetent. Organ Behav Hum Decis Process, 105 (1), 98–121.



Ehrman, B. D. (2005). Misquoting Jesus: The Story Behind Who Changed the Bible
and Why (1st ed.). New York: HarperSanFrancisco.



Ehrsson, H. H., Spence, C., & Passingham, R. E. (2004). That’s my hand!
Activity in premotor cortex reflects feeling of ownership of a limb. Science,
305 (5685), 875–877.



Einstein, A. (1954). Ideas and opinions. Based on Mein Weltbild. New York:
Crown Publishers.



Eisenberger, N. I., Lieberman, M. D., & Satpute, A. B. (2005). Personality from
a controlled processing perspective: An fMRI study of neuroticism,
extraversion, and self-consciousness. Cogn Affect Behav Neurosci, 5 (2),
169–181.



Elliott, R., Frith, C. D., & Dolan, R. J. (1997). Differential neural response
to positive and negative feedback in planning and guessing tasks.
Neuropsychologia, 35 (10), 1395–1404.



Enard, W., Gehre, S., Hammerschmidt, K., Holter, S. M., Blass, T., Somel, M.,
et al. (2009). A humanized version of FOXP2, affects cortico-basal ganglia
circuits in mice. Cell, 137 (5), 961–971.



Enard, W., Przeworski, M., Fisher, S. E., Lai, C. S., Wiebe, V., Kitano, T., et
al. (2002). Molecular evolution of FOXP2, a gene involved in speech and
language. Nature, 418 (6900), 869–872.



Esposito, J. L. (2008). Who speaks for Islam?: What a billion Muslims really
think. New York, NY: Gallup Press.



Evans, E. M. (2001). Cognitive and contextual factors in the emergence of
diverse belief systems: Creation versus evolution. Cogn Psychol, 42 (3),
217–266.



Evans, J. S. B. T. (2005). Deductive reasoning. In K. J. Holyoak & R. G.
Morrison (Eds.), The Cambridge handbook of thinking and reasoning (pp.
169–184). New York: Cambridge University Press.



Evans, P. D., Gilbert, S. L., Mekel-Bobrov, N., Vallender, E. J., Anderson, J.
R., Vaez-Azizi, L. M., et al. (2005). Microcephalin, a gene regulating brain
size, continues to evolve adaptively in humans. Science, 309 (5741), 1717–1720.



Evers, K. (2005). Neuroethics: A philosophical challenge. Am J Bioeth, 5 (2),
31–33; discussion W33–34.



Faison, S. (1996, December 20). The death of the last emperor’s last eunuch.
New York Times.



Farah, M. J. (2005). Neuroethics: the practical and the philosophical. Trends
Cogn Sci, 9 (1), 34–40.



Farah, M. J. (2007). Social, legal, and ethical implications of cognitive
neuroscience: “Neuroethics” for short. J Cogn Neurosci, 19 (3), 363–364.



Farah, M. J., Illes, J., Cook-Deegan, R., Gardner, H., Kandel, E., King, P., et
al. (2004). Neurocognitive enhancement: What can we do and what should we do?
Nat Rev Neurosci, 5 (5), 421–425.



Farah, M. J., & Murphy, N. (2009). Neuroscience and the soul. Science, 323
(5918), 1168.



Farrer, C., & Frith, C. D. (2002). Experiencing oneself vs. another person as
being the cause of an action: the neural correlates of the experience of
agency. Neuroimage, 15 (3), 596–603.



Farwell, L. A., & Donchin, E. (1991). The truth will out: Interrogative
polygraphy (“lie detection”) with event-related brain potentials.
Psychophysiology, 28 (5), 531–547.



Faurion, A., Cerf, B., Le Bihan, D., & Pillias, A. M. (1998). fMRI study of
taste cortical areas in humans. Ann NY Acad Sci, 855, 535–545.



Feigl, H. (1967). The “mental” and the “physical”: The essay and a postcript.
Minneapolis, MN.: University of Minnesota Press.



Festinger, L., Riecken, H. W., & Schachter, S. ([1956] 2008). When prophecy
fails. Minneapolis, MN: University of Minnesota Press.



Filkins, D. (2010, February 7). On Afghan road, scenes of beauty and death. New
York Times.



Fincher, C. L., Thornhill, R., Murray, D. R., & Schaller, M. (2008). Pathogen
prevalence predicts human cross-cultural variability in
individualism/collectivism. Proc Biol Sci, 275 (1640), 1279–1285.



Finkbeiner, M., & Forster, K. I. (2008). Attention, intention and
domain-specific processing. Trends Cogn Sci, 12 (2), 59–64.



Finke, R., & Stark, R. (1998). Religious choice and competition. American
Sociological Review, 63 (5), 761–766.



Fins, J. J., & Shapiro, Z. E. (2007). Neuroimaging and neuroethics: Clinical
and policy considerations. Curr Opin Neurol, 20 (6), 650–654.



Fisher, C. M. (2001). If there were no free will. Med Hypotheses, 56 (3),
364–366.



Fitch, W. T., Hauser, M. D., & Chomsky, N. (2005). The evolution of the
language faculty: Clarifications and implications. Cognition, 97 (2), 179–210;
discussion 211–225.



Flanagan, O. J. (2002). The problem of the soul: Two visions of mind and how to
reconcile them. New York: Basic Books.



Flanagan, O. J. (2007). The really hard problem: Meaning in a material world.
Cambridge, MA: MIT Press.



Fletcher, P. C., Happé, F., Frith, U., Baker, S. C., Dolan, R. J., Frackowiak,
R. S., et al. (1995). Other minds in the brain: A functional imaging study of
“theory of mind” in story comprehension. Cognition, 57 (2), 109–128.



Fodor, J. (2000). The mind doesn’t work that way. Cambridge, MA: MIT Press.



Fodor, J. (2007, October 18). Why pigs don’t have wings. London Review of
Books.



Fong, G. T., Krantz, D. H., & Nisbett, R. E. (1986/07). The effects of
statistical training on thinking about everyday problems. Cognitive Psychology,
18 (3), 253–292.



Foot, P. (1967). The problem of abortion and the doctrine of double effect.
Oxford Review, 5, 5–15.



Foster, K. R., & Kokko, H. (2009). The evolution of superstitious and
superstition-like behavior. Proc Biol Sci276(1654), 31–37.



Frank, M. J., D’Lauro, C., & Curran, T. (2007). Cross-task individual
differences in error processing: Neural, electrophysiological, and genetic
components. Cogn Affect Behav Neurosci, 7 (4), 297–308.



Frederico Marques, J., Canessa, N., & Cappa, S. (2009). Neural differences in
the processing of true and false sentences: Insights into the nature of ‘truth’
in language comprehension. Cortex, 45(6), 759–68.



Freeman, W. J. (1997). Three centuries of category errors in studies of the
neural basis of consciousness and intentionality. Neural Networks, 10 (7),
1175–1183.



Freud, S. ([1930] 2005). Civilization and its discontents. New York: W. W.
Norton.



Freud, S., & Strachey, J. ([1927] 1975). The future of an illusion. New York:
Norton.



Friedman, T. L. (2007, September 5). Letter from Baghdad. New York Times.



Fries, A. B., Ziegler, T. E., Kurian, J. R., Jacoris, S., & Pollak, S. D.
(2005). Early experience in humans is associated with changes in neuropeptides
critical for regulating social behavior. Proc Natl Acad Sci USA, 102 (47),
17237–17240.



Friston, K. J., Price, C. J., Fletcher, P., Moore, C., Frackowiak, R. S., &
Dolan, R. J. (1996). The trouble with cognitive subtraction. Neuroimage, 4 (2),
97–104.



Frith, C. (2008). No one really uses reason. New Scientist, (2666) (July 26),
45.



Frith, C. D., & Frith, U. (2006). The neural basis of mentalizing. Neuron, 50
(4), 531–534.



Frith, U., Morton, J., & Leslie, A. M. (1991). The cognitive basis of a
biological disorder: Autism. Trends Neurosci, 14 (10), 433–438.



Fromm, E. (1973). The anatomy of human destructiveness (1st ed.). New York:
Holt.



Fuchs, T. (2006). Ethical issues in neuroscience. Curr Opin Psychiatry, 19 (6),
600–607.



Fuster, J. M. (2003). Cortex and mind: Unifying cognition. Oxford, UK: New
York: Oxford University Press.



Gallea, C., Graaf, J. B., Pailhous, J., & Bonnard, M. (2008). Error processing
during online motor control depends on the response accuracy. Behav Brain Res,
193(1), 117–125.



Garavan, H., Ross, T. J., Murphy, K., Roche, R. A., & Stein, E. A. (2002).
Dissociable executive functions in the dynamic control of behavior: Inhibition,
error detection, and correction. Neuroimage, 17 (4), 1820–1829.



Gazzaniga, M. S. (1998). The split brain revisited. Sci Am, 279 (1), 50–55.



Gazzaniga, M. S. (2005). Forty-five years of split-brain research and still
going strong. Nat Rev Neurosci, 6 (8), 653–659.



Gazzaniga, M. S. (2005). The ethical brain. New York: Dana Press.



Gazzaniga, M. S. (2008). Human: The science behind what makes us unique. New
York: Ecco.



Gazzaniga, M. S., Bogen, J. E., & Sperry, R. W. (1962). Some functional effects
of sectioning the cerebral commissures in man. Proc Natl Acad Sci USA, 48,
1765–1769.



Gazzaniga, M. S., Bogen, J. E., & Sperry, R. W. (1965). Observations on visual
perception after disconnexion of the cerebral hemispheres in man. Brain, 88
(2), 221–236.



Gazzaniga, M. S., Ivry, R. B. and Mangun, G. R. (1998). Cognitive neuroscience:
The biology of the mind. New York: W. W. Norton.



Gehring, W. J., & Fencsik, D. E. (2001). Functions of the medial frontal cortex
in the processing of conflict and errors. J Neurosci, 21 (23), 9430–9437.



Geschwind, D. H., Iacoboni, M., Mega, M. S., Zaidel, D. W., Cloughesy, T., &
Zaidel, E. (1995). Alien hand syndrome: Interhemispheric motor disconnection
due to a lesion in the midbody of the corpus callosum. Neurology, 45 (4),
802–808.



Gettleman, J. (2008, June 8). Albinos, long shunned, face threat in Tanzania.
New York Times.



Ghazanfar, A. A. (2008). Language evolution: Neural differences that make a
difference. Nat Neurosci, 11 (4), 382–384.



Gilbert, D. T. (1991). How mental systems believe. American Psychologist, 46
(2), 107–119.



Gilbert, D. T. (2006). Stumbling on happiness (1st ed.). New York: A. A. Knopf.



Gilbert, D. T., Brown, R. P., Pinel, E. C., & Wilson, T. D. (2000). The
illusion of external agency. J Pers Soc Psychol, 79 (5), 690–700.



Gilbert, D. T., Lieberman, M. D., Morewedge, C. K., & Wilson, T. D. (2004). The
peculiar longevity of things not so bad. Psychol Sci, 15 (1), 14–19.



Gilbert, D. T., Morewedge, C. K., Risen, J. L., & Wilson, T. D. (2004). Looking
forward to looking backward: The misprediction of regret. Psychol Sci, 15 (5),
346–350.



Gilbert, D. T., Krull, D. S., Malone, S. (1990). Unbelieving the unbelievable:
Some problems in the rejection of false information. Journal of Personality and
Social Psychology, 59 (4), 601–613.



Glannon, W. (2006). Neuroethics. Bioethics, 20 (1), 37–52.



Glenn, A. L., Raine, A., & Schug, R. A. (2009). The neural correlates of moral
decision-making in psychopathy. Mol Psychiatry, 14 (1), 5–6.



Glenn, A. L., Raine, A., Schug, R. A., Young, L., & Hauser, M. (2009).
Increased DLPFC activity during moral decision-making in psychopathy. Mol
Psychiatry, 14 (10), 909–911.



Glimcher, P. (2002). Decisions, decisions, decisions: Choosing a biological
science of choice. Neuron, 36 (2), 323–332.



Goel, V., & Dolan, R. J. (2003a). Explaining modulation of reasoning by belief.
Cognition, 87 (1), B11–22.



Goel, V., & Dolan, R. J. (2003b). Reciprocal neural response within lateral and
ventral medial prefrontal cortex during hot and cold reasoning. Neuroimage, 20
(4), 2314–2321.



Goel, V., Gold, B., Kapur, S., & Houle, S. (1997). The seats of reason? An
imaging study of deductive and inductive reasoning. Neuroreport, 8 (5),
1305–1310.



Goffman, E. (1967). Interaction ritual: Essays on face-to-face behavior. New
York: Pantheon Books.



Gold, J. I., & Shadlen, M. N. (2000). Representation of a perceptual decision
in developing oculomotor commands. Nature, 404 (6776), 390–394.



Gold, J. I., & Shadlen, M. N. (2002). Banburismus and the brain: Decoding the
relationship between sensory stimuli, decisions, and reward. Neuron, 36 (2),
299–308.



Gold, J. I., & Shadlen, M. N. (2007). The neural basis of decision making. Annu
Rev Neurosci, 30, 535–574.



Goldberg, E. (2001). The executive brain: Frontal lobes and the civilized mind.
Oxford, UK; New York: Oxford University Press.



Goldberg, I., Ullman, S., & Malach, R. (2008). Neuronal correlates of “free
will” are associated with regional specialization in the human
intrinsic/default network. Conscious Cogn, 17 (3), 587–601.



Gomes, G. (2007). Free will, the self, and the brain. Behav Sci Law, 25 (2),
221–234.



Goodstein, L. (2010a, March 24). Vatican declined to defrock U.S. priest who
abused boys. New York Times.



Goodstein, L. (2010b, April 21). Invitation to cardinal is withdrawn. New York
Times.



Goodstein, L., & Callender, D. (2010, March 26). For years, deaf boys tried to
tell of priest’s abuse. New York Times.



Gould, S. J. (1997). Nonoverlapping magisteria. Natural History, 106 (March),
16–22.



Graham Holm, N. (2010, January 4). Prejudiced Danes provoke fanaticism. The
Guardian.



Grann, D. (2009, September 7). Trial by Fire. New Yorker.



Gray, J. M., Young, A. W., Barker, W. A., Curtis, A., & Gibson, D. (1997).
Impaired recognition of disgust in Huntington’s disease gene carriers. Brain,
120 (Pt. 11), 2029–2038.



Gray, J. R., Burgess, G. C., Schaefer, A., Yarkoni, T., Larsen, R. J., &
Braver, T. S. (2005). Affective personality differences in neural processing
efficiency confirmed using fMRI. Cogn Affect Behav Neurosci, 5 (2), 182–190.



Greely, H. (2007). On neuroethics. Science, 318 (5850), 533.



Greene, J., & Cohen, J. (2004). For the law, neuroscience changes nothing and
everything. Philos Trans R Soc Lond B Biol Sci, 359 (1451), 1775–1785.



Greene, J. D. (2002). The terrible, horrible, no good, very bad truth about
morality and what to do about it. Princeton, NJ: Princeton University.



Greene, J. D. (2007). Why are VMPFC patients more utilitarian? A dual-process
theory of moral judgment explains. Trends Cogn Sci, 11 (8), 322–323; author
reply 323–324.



Greene, J. D., Nystrom, L. E., Engell, A. D., Darley, J. M., & Cohen, J. D.
(2004). The neural bases of cognitive conflict and control in moral judgment.
Neuron, 44 (2), 389–400.



Greene, J. D., Sommerville, R. B., Nystrom, L. E., Darley, J. M., & Cohen, J.
D. (2001). An fMRI investigation of emotional engagement in moral judgment.
Science, 293 (5537), 2105–2108.



Gregory, R. L. (1987). The Oxford companion to the mind. Oxford, UK: Oxford
University Press.



Grim, P. (2007). Free will in context: A contemporary philosophical
perspective. Behav Sci Law, 25 (2), 183–201.



Gross, P. R. (1991). On the “gendering” of science. Academic Questions, 5 (2),
10–23.



Gross, P. R., & Levitt, N. (1994). Higher superstition: The academic left and
its quarrels with science. Baltimore: Johns Hopkins University Press.



Gusnard, D. A., Akbudak, E., Shulman, G. L., & Raichle, M. E. (2001). Medial
prefrontal cortex and self-referential mental activity: Relation to a default
mode of brain function. Proc Natl Acad Sci USA, 98 (7), 4259–4264.



Gutchess, A. H., Welsh, R. C., Boduroglu, A., & Park, D. C. (2006). Cultural
differences in neural function associated with object processing. Cogn Affect
Behav Neurosci, 6 (2), 102–109.



Guttenplan, S. (1994). A companion to the philosophy of mind. Oxford, UK:
Blackwell.



Haber, S. N., Kunishio, K., Mizobuchi, M., & Lynd-Balta, E. (1995). The orbital
and medial prefrontal circuit through the primate basal ganglia. J Neurosci, 15
(7 Pt. 1), 4851–4867.



Haggard, P. (2001). The psychology of action. Br J Psychol, 92 (Pt. 1),
113–128.



Haggard, P., Clark, S., & Kalogeras, J. (2002). Voluntary action and conscious
awareness. Nat Neurosci, 5 (4), 382–385.



Haggard, P., & Eimer, M. (1999). On the relation between brain potentials and
the awareness of voluntary movements. Exp Brain Res, 126 (1), 128–133.



Haggard, P., & Magno, E. (1999). Localising awareness of action with
transcranial magnetic stimulation. Exp Brain Res, 127 (1), 102–107.



Haidt, J. (2001). The emotional dog and its rational tail: A social
intuitionist approach to moral judgment. Psychol Rev, 108 (4), 814–834.



Haidt, J. (2003). The emotional dog does learn new tricks: A reply to Pizarro
and Bloom (2003). Psychol Rev, 110 (1), 197–198.



Haidt, J. (2007). The new synthesis in moral psychology. Science, 316 (5827),
998–1002.



Haidt, J. (2008). What makes people vote Republican? Retrieved from
www.edge.org/3rd_culture/haidt08/haidt08_index.html.



Haidt, J. (2009). Faster evolution means more ethnic differences. The Edge
Annual Question 2009. Retrieved from www.edge.org/q2009/q09_4.html#haidt.



Hajcak, G., & Simons, R. F. (2008). Oops!… I did it again: An ERP and
behavioral study of double-errors. Brain Cogn, 68 (1), 15–21.



Hall, D. L., Matz, D. C., & Wood, W. (2010). Why don’t we practice what we
preach? A meta-analytic review of religious racism. Personality and Social
Psychology Review, 14 (1), 126–139.



Halligan, P. W. (1998). Inability to recognise disgust in Huntington’s disease.
Lancet, 351 (9101), 464.



Hameroff, S., Kaszniak, A. W., and Scott, A. C. (1996). Toward a science of
consciousness: The first Tucson discussions and debates. Cambridge, MA: MIT
Press.



Hamilton, W. D. (1964a). The genetical evolution of social behaviour. Pt. I. J
Theor Biol, 7 (1), 1–16.



Hamilton, W. D. (1964b). The genetical evolution of social behaviour. Pt. II. J
Theor Biol, 7 (1), 17–52.



Han, S., Mao, L., Gu, X., Zhu, Y., Ge, J., & Ma, Y. (2008). Neural consequences
of religious belief on self-referential processing. Soc Neurosci, 3 (1), 1–15.



Hanson, S. J., Matsuka, T., & Haxby, J. V. (2004). Combinatorial codes in
ventral temporal lobe for object recognition: Haxby (2001) revisited: Is there
a “face” area? Neuroimage, 23 (1), 156–166.



Happé, F. (2003). Theory of mind and the self. Ann NY Acad Sci, 1001, 134–144.



Hardcastle, V. G. (1993). The naturalists versus the skeptics: The debate over
a scientific understanding of consciousness. J Mind Behav, 14 (1), 27–50.



Hardcastle, V. G., & Flanagan, O. (1999). Multiplex vs. multiple selves:
Distinguishing dissociative disorders. The Monist, 82 (4), 645–657.



Harding, S. (2001). Gender, democracy, and philosophy of science. Paper
presented at the Science, Engineering and Global Responsibility lectures,
Stockholm (June 14–18, 2000).



Hare, R. D. (1999). Without conscience: The disturbing world of the psychopaths
among us. New York: Guilford Press.



Hare, T. A., Tottenham, N., Galvan, A., Voss, H. U., Glover, G. H., & Casey, B.
J. (2008). Biological substrates of emotional reactivity and regulation in
adolescence during an emotional go-nogo task. Biol Psychiatry, 63 (10),
927–934.



Harris, D., & Karamehmedovic, A. (2009, March 2). Child witches: Accused in the
name of Jesus. Nightline: ABC News.



Harris, S. (2004). The end of faith: Religion, terror, and the future of reason
(1st ed.). New York: W. W. Norton.



Harris, S. (2006a). Letter to a Christian nation. New York: Knopf.



Harris, S. (2006b). Science must destroy religion. In J. Brockman (Ed.), What
is your dangerous idea? New York: Simon & Schuster.



Harris, S. (2006c). Reply to Scott Atran. An Edge discussion of BEYOND BELIEF:
Science, religion, reason and survival, from www.edge.org/discourse/bb.html.



Harris, S. (2006d). Do we really need bad reasons to be good? Boston Globe,
Oct. 22.



Harris, S. (2007b). Response to Jonathan Haidt. Edge.org, from
www.edge.org/discourse/moral_religion.html.



Harris, S. (2007a). Scientists should unite against threat from religion.
Nature, 448 (7156), 864.



Harris, S. (2009, July 27). Science is in the details. New York Times.



Harris, S., & Ball, P. (2009, June 26). What should science do? Sam Harris v.
Philip Ball, from





roject-reason.org/archive/item/what_should_science_dosam_harris_v_philip_ball/.



Harris, S., Kaplan, J. T., Curiel, A., Bookheimer, S. Y., Iacoboni, M., &
Cohen, M. S. (2009). The neural correlates of religious and nonreligious
belief. PLoS ONE, 4 (10), e7272.



Harris, S., Sheth, S. A., & Cohen, M. S. (2008). Functional neuroimaging of
belief, disbelief, and uncertainty. Ann Neurol, 63 (2), 141–147.



Hauser, M. D. (2000). Wild minds: What animals really think (1st ed.). New
York: Henry Holt.



Hauser, M. D. (2006). Moral minds: How nature designed our universal sense of
right and wrong (1st ed.). New York: Ecco.



Hauser, M. D., Chomsky, N., & Fitch, W. T. (2002). The faculty of language:
What is it, who has it, and how did it evolve? Science, 298 (5598), 1569–1579.



Hayes, C. J., Stevenson, R. J., & Coltheart, M. (2007). Disgust and
Huntington’s disease. Neuropsychologia, 45 (6), 1135–1151.



Haynes, J. D. (2009). Decoding visual consciousness from human brain signals.
Trends Cogn Sci, 13(5), 194–202.



Haynes, J. D., & Rees, G. (2006). Decoding mental states from brain activity in
humans. Nat Rev Neurosci, 7 (7), 523–534.



Heisenberg, M. (2009). Is free will an illusion? Nature, 459 (7244), 164–165.



Heisenberg, W. (1958). The representation of Nature in contemporary physics.
Daedalus, 87 (Summer), 95–108.



Henley, S. M., Wild, E. J., Hobbs, N. Z., Warren, J. D., Frost, C., Scahill, R.
I., et al. (2008). Defective emotion recognition in early HD is
neuropsychologically and anatomically generic. Neuropsychologia, 46 (8),
2152–2160.



Hennenlotter, A., Schroeder, U., Erhard, P., Haslinger, B., Stahl, R., Weindl,
A., et al. (2004). Neural correlates associated with impaired disgust
processing in pre-symptomatic Huntington’s disease. Brain, 127 (Pt. 6),
1446–1453.



Henson, R. (2005). What can functional neuroimaging tell the experimental
psychologist? Q J Exp Psychol A, 58 (2), 193–233.



Hirsi Ali, A. (2006). The caged virgin: An emancipation proclamation for women
and Islam (1st Free Press ed.). New York: Free Press.



Hirsi Ali, A. (2007). Infidel. New York: Free Press.



Hirsi Ali, A. (2010). Nomad. New York: Free Press.



Hitchens, C. (2007). God is not great: How religion poisons everything. New
York: Twelve.



Hitchens, C. (2010, March 15). The great Catholic cover-up. Slate.



Hitchens, C. (2010, March 22). Tear down that wall. Slate.



Hitchens, C. (2010, March 29). The pope is not above the law. Slate.



Hitchens, C. (2010, May 3). Bring the pope to justice. Newsweek.



Holden, C. (2001). Polygraph screening. Panel seeks truth in lie detector
debate. Science, 291 (5506), 967.



Holyoak, K. J. (2005). Analogy. In K. J. Holyoak & R. G. Morrison (Eds.), The
Cambridge handbook of thinking of reasoning (pp. 117–142). New York: Cambridge
University Press.



Holyoak, K. J., & Morrison, R. G. (2005). The Cambridge handbook of thinking
and reasoning. New York: Cambridge University Press.



Hood, B. M. (2009). Supersense: Why we believe in the unbelievable. New York:
HarperOne.



Hornak, J., O’Doherty, J., Bramham, J., Rolls, E. T., Morris, R. G., Bullock,
P. R., et al. (2004). Reward-related reversal learning after surgical excisions
in orbito-frontal or dorsolateral prefrontal cortex in humans. J Cogn Neurosci,
16 (3), 463–478.



Houreld, K. (2009, October 20). Church burns “witchcraft” children. Daily
Telegraph.



Hsu, M., Bhatt, M., Adolphs, R., Tranel, D., & Camerer, C. F. (2005). Neural
systems responding to degrees of uncertainty in human decision-making. Science,
310 (5754), 1680–1683.



Hume, D. (1996). The philosophical works of David Hume. Bristol, U.K.: Thoemmes
Press.



Hunte-Grubbe, C. (2007, October 14). The elementary DNA of Dr. Watson. Sunday
Times.



Hutchison, W. D., Davis, K. D., Lozano, A. M., Tasker, R. R., & Dostrovsky, J.
O. (1999). Pain-related neurons in the human cingulate cortex. Nat Neurosci, 2
(5), 403–405.



Iacoboni, M. (2008). Mirroring people: The new science of how we connect with
others (1st ed.). New York: Farrar, Straus and Giroux.



Iacoboni, M., & Dapretto, M. (2006). The mirror neuron system and the
consequences of its dysfunction. Nat Rev Neurosci, 7 (12), 942–951.



Iacoboni, M., & Mazziotta, J. C. (2007). Mirror neuron system: Basic findings
and clinical applications. Ann Neurol, 62 (3), 213–218.



Iacoboni, M., Rayman, J., & Zaidel, E. (1996). Left brain says yes, right brain
says no: Normative duality in the split brain. In S. Hameroff, A. W. Kaszniak,
& A. C. Scott (Eds.), Toward a science of consciousness: The first Tucson
discussions and debates (pp. 197–202). Cambridge, MA: MIT Press.



Ibrahim, R. (Ed.)(2007). The Al Qaeda reader (1st pbk. ed.). New York: Broadway
Books.



Illes, J. (2003). Neuroethics in a new era of neuroimaging. AJNR Am J
Neuroradiol, 24 (9), 1739–1741.



Illes, J. (2004). Medical imaging: A hub for the new field of neuroethics. Acad
Radiol, 11 (7), 721–723.



Illes, J. (2007). Empirical neuroethics. Can brain imaging visualize human
thought? Why is neuroethics interested in such a possibility? EMBO Rep. 8 Spec
No. S57–60.



Illes, J., & Bird, S. J. (2006). Neuroethics: A modern context for ethics in
neuroscience. Trends Neurosci, 29 (9), 511–517.



Illes, J., Blakemore, C., Hansson, M. G., Hensch, T. K., Leshner, A., Maestre,
G., et al. (2005). International perspectives on engaging the public in
neuroethics. Nat Rev Neurosci, 6 (12), 977–982.



Illes, J., Kirschen, M. P., & Gabrieli, J. D. (2003). From neuroimaging to
neuroethics. Nat Neurosci, 6 (3), 205.



Illes, J., & Racine, E. (2005). Imaging or imagining? A neuroethics challenge
informed by genetics. Am J Bioeth, 5 (2), 5–18.



Illes, J., & Raffin, T. A. (2002). Neuroethics: An emerging new discipline in
the study of brain and cognition. Brain Cogn, 50 (3), 341–344.



Inbar, Y., Pizarro, D. A., Knobe, J., & Bloom, P. (2009). Disgust sensitivity
predicts intuitive disapproval of gays. Emotion, 9 (3), 435–439.



Inglehart, R., Foa, R., Peterson, C., & Welzel, C. (2008). Development,
freedom, and rising happiness. Perspectives on Psychological Science, 3 (4),
264–285.



Inzlicht, M., McGregor, I., Hirsh, J. B., & Nash, K. (2009). Neural markers of
religious conviction. Psychol Sci, 20 (3), 385–392.



Izuma, K., Saito, D. N., & Sadato, N. (2008). Processing of social and monetary
rewards in the human striatum. Neuron, 58 (2), 284–294.



James, W. ([1890] 1950). The principles of psychology (Authorized ed.).
Mineola, NY: Dover Publications.



James, W. ([1912] 1996). Essays in radical empiricism. Lincoln, NE: University
of Nebraska Press.



Jeannerod, M. (1999). The 25th Bartlett Lecture. To act or not to act:
Perspectives on the representation of actions. Q J Exp Psychol A, 52 (1), 1–29.



Jeannerod, M. (2001). Neural simulation of action: A unifying mechanism for
motor cognition. Neuroimage, 14 (1 Pt. 2), S103–109.



Jeannerod, M. (2003). The mechanism of self-recognition in humans. Behav Brain
Res, 142 (1–2), 1–15.



Jeans, J. (1930). The mysterious universe. Cambridge, UK: Cambridge University
Press.



Jedlicka, P. (2005). Neuroethics, reductionism and dualism. Trends Cogn Sci, 9
(4), 172; author reply, 173.



Jenkinson, M., Bannister, P., Brady, M., & Smith, S. (2002). Improved
optimization for the robust and accurate linear registration and motion
correction of brain images. Neuroimage, 17 (2), 825–841.



Jenkinson, M., & Smith, S. (2001). A global optimisation method for robust
affine registration of brain images. Med Image Anal, 5 (2), 143–156.



Jensen, K., Call, J., & Tomasello, M. (2007). Chimpanzees are rational
maximizers in an ultimatum game. Science, 318 (5847), 107–109.



Jensen, K., Hare, B., Call, J., & Tomasello, M. (2006). What’s in it for me?
Self-regard precludes altruism and spite in chimpanzees. Proc Biol Sci, 273
(1589), 1013–1021.



Johnson, S. A., Stout, J. C., Solomon, A. C., Langbehn, D. R., Aylward, E. H.,
Cruce, C. B., et al. (2007). Beyond disgust: Impaired recognition of negative
emotions prior to diagnosis in Huntington’s disease. Brain, 130 (Pt. 7),
1732–1744.



Jones, D. (2008). Human behaviour: killer instincts. Nature, 451 (7178),
512–515.



Joseph, O. (2009). Horror of Kenya’s “witch,” lynchings. Retrieved June 27,
2009, from http://news.bbc.co.uk/2/hi/africa/8119201.stm.



Joseph, R. (1999). Frontal lobe psychopathology: Mania, depression,
confabulation, catatonia, perseveration, obsessive compulsions, and
schizophrenia. Psychiatry, 62 (2), 138–172.



Jost, J. T., Glaser, J., Kruglanski, A. W., & Sulloway, F. J. (2003). Political
conservatism as motivated social cognition. Psychol Bull, 129 (3), 339–375.



Joyce, R. (2006). Metaethics and the empirical sciences. Philosophical
Explorations, 9 (Special issue: Empirical research and the nature of moral
judgment), 133–148.



Judson, O. (2008, December 2). Back to reality. New York Times.



Justo, L., & Erazun, F. (2007). Neuroethics and human rights. Am J Bioeth, 7
(5), 16–18.



Kahane, G., & Shackel, N. (2008). Do abnormal responses show utilitarian bias?
Nature, 452 (7185), E5; author reply E5–6.



Kahneman, D. (2003a). Experiences of collaborative research. Am Psychol, 58
(9), 723–730.



Kahneman, D. (2003b). A perspective on judgment and choice: Mapping bounded
rationality. Am Psychol, 58 (9), 697–720.



Kahneman, D., & Frederick, S. (2005). A model of heuristic judgment. In K. J.
Holyoak & R. G. Morrison (Eds.), The Cambridge handbook of thinking and
reasoning (pp. 267–293). New York: Cambridge University Press.



Kahneman, D., Krueger, A. B., Schkade, D., Schwarz, N., & Stone, A. A. (2006).
Would you be happier if you were richer? A focusing illusion. Science, 312
(5782), 1908–1910.



Kahneman, D., Slovic, P., & Tversky, A. (1982). Judgment under uncertainty:
Heuristics and biases. New York: Cambridge University Press.



Kahneman, D., & Tversky, A. (1979). Prospect theory: An analysis of decision
under risk. Econometrica, 47 (2), 263–292.



Kahneman, D., & Tversky, A. (1996). On the reality of cognitive illusions.
Psychol Rev, 103 (3), 582–591; discussion 592–586.



Kandel, E. R. (2008). Interview with Eric R. Kandel: From memory, free will,
and the problem with Freud to fortunate decisions. J Vis Exp (15), April 24, p.
762.



Kant, I. ([1785] 1995). Ethical philosophy: Grounding for the metaphysics of
morals and metaphysical principles of virtue (J. W. Ellington, Trans.).
Indianapolis, IN: Hackett Publishing.



Kanwisher, N., McDermott, J., & Chun, M. M. (1997). The fusiform face area: A
module in human extrastriate cortex specialized for face perception. J
Neurosci, 17 (11), 4302–4311.



Kaplan, J. T., Freedman, J., & Iacoboni, M. (2007). Us versus them: Political
attitudes and party affiliation influence neural response to faces of
presidential candidates. Neuropsychologia, 45 (1), 55–64.



Kaplan, J. T., & Iacoboni, M. (2006). Getting a grip on other minds: Mirror
neurons, intention understanding, and cognitive empathy. Soc Neurosci, 1 (3–4),
175–183.



Kapogiannis, D., Barbey, A. K., Su, M., Zamboni, G., Krueger, F., & Grafman, J.
(2009). Cognitive and neural foundations of religious belief. Proc Natl Acad
Sci USA, 106 (12), 4876–4881.



Karczmar, A. G. (2001). Sir John Eccles, 1903–1997. Pt. 2. The brain as a
machine or as a site of free will? Perspect Biol Med, 44 (2), 250–262.



Keane, M. M., Gabrieli, J. D., Monti, L. A., Fleischman, D. A., Cantor, J. M.,
& Noland, J. S. (1997). Intact and impaired conceptual memory processes in
amnesia. Neuropsychology, 11 (1), 59–69.



Kelley, W. M., Macrae, C. N., Wyland, C. L., Caglar, S., Inati, S., &
Heatherton, T. F. (2002). Finding the self? An event-related fMRI study. J Cogn
Neurosci, 14 (5), 785–794.



Kennedy, D. (2004). Neuroscience and neuroethics. Science, 306 (5695), 373.



Kertesz, A. (2000). Alien hand, free will and Arnold Pick. Can J Neurol Sci, 27
(3), 183.



Keverne, E. B., & Curley, J. P. (2004). Vasopressin, oxytocin and social
behaviour. Curr Opin Neurobiol, 14 (6), 777–783.



Kiehl, K. A. (2006). A cognitive neuroscience perspective on psychopathy:
Evidence for paralimbic system dysfunction. Psychiatry Res, 142 (2–3), 107–128.



Kiehl, K. A., Smith, A. M., Hare, R. D., Mendrek, A., Forster, B. B., Brink,
J., et al. (2001). Limbic abnormalities in affective processing by criminal
psychopaths as revealed by functional magnetic resonance imaging. Biol
Psychiatry, 50 (9), 677–684.



Kihlstrom, J. F. (1996). Unconscious processes in social interaction. In S.
Hameroff, A. W. Kaszniak, & A. C. Scott (Eds.), Toward a science of
consciousness: The first Tucson discussions and debates (pp. 93–104).
Cambridge, MA: MIT Press.



Kim, J. ([1984] 1991). Epiphenomenal and supervenient causation. In D.
Rosenthal (Ed.), The nature of mind (pp. 257–265). Oxford: Oxford University
Press.



Kim, J. (1993). The myth of nonreductive materialism. In Supervenience and mind
(pp. 265–283). Cambridge, UK: Cambridge University Press.



King-Casas, B., Tomlin, D., Anen, C., Camerer, C. F., Quartz, S. R., &
Montague, P. R. (2005). Getting to know you: Reputation and trust in a
two-person economic exchange. Science, 308 (5718), 78–83.



Kipps, C. M., Duggins, A. J., McCusker, E. A., & Calder, A. J. (2007). Disgust
and happiness recognition correlate with anteroventral insula and amygdala
volume respectively in preclinical Huntington’s disease. J Cogn Neurosci, 19
(7), 1206–1217.



Kircher, T. T., Senior, C., Phillips, M. L., Benson, P. J., Bullmore, E. T.,
Brammer, M., et al. (2000). Towards a functional neuroanatomy of self
processing: Effects of faces and words. Brain Res Cogn Brain Res, 10 (1–2),
133–144.



Kircher, T. T., Senior, C., Phillips, M. L., Rabe-Hesketh, S., Benson, P. J.,
Bullmore, E. T., et al. (2001). Recognizing one’s own face. Cognition, 78 (1),
B1–B15.



Kirsch, I. (2000). Are drug and placebo effects in depression additive? Biol
Psychiatry, 47 (8), 733–735.



Klayman, J., & Ha, Y. W. (1987). Confirmation, disconfirmation, and information
in hypothesis testing. Psychological Review, 94 (2), 211–228.



Koenig, L. B., McGue, M., Krueger, R. F., & Bouchard, T. J., Jr. (2005).
Genetic and environmental influences on religiousness: Findings for
retrospective and current religiousness ratings. J Pers, 73 (2), 471–488.



Koenig, L. B., McGue, M., Krueger, R. F., & Bouchard, T. J., Jr. (2007).
Religiousness, antisocial behavior, and altruism: Genetic and environmental
mediation. J Pers, 75 (2), 265–290.



Koenigs, M., Young, L., Adolphs, R., Tranel, D., Cushman, F., Hauser, M., et
al. (2007). Damage to the prefrontal cortex increases utilitarian moral
judgements. Nature, 446 (7138), 908–911.



Kolb, B., & Whishaw, I. Q. (2008). Fundamentals of human neuropsychology (6th
ed.). New York: Worth Publishers.



Kosik, K. S. (2006). Neuroscience gears up for duel on the issue of brain
versus deity. Nature, 439 (7073), 138.



Krause, J., Lalueza-Fox, C., Orlando, L., Enard, W., Green, R. E., Burbano, H.
A., et al. (2007). The derived FOXP2 variant of modern humans was shared with
Neandertals. Curr Biol, 17 (21), 1908–1912.



Kripke, S. ([1970] 1991). From naming and necessity. In D. Rosenthal (Ed.), The
nature of mind (pp. 236–246). UK: Oxford University Press.



Kruger, J., & Dunning, D. (1999). Unskilled and unaware of it: How difficulties
in recognizing one’s own incompetence lead to inflated self-assessments. J Pers
Soc Psychol, 77 (6), 1121–1134.



Kruglanski, A. W. (1999). Motivation, cognition, and reality: Three memos for
the next generation of research. Psychological Inquiry, 10 (1), pp. 54–58.



Kuhnen, C. M., & Knutson, B. (2005). The neural basis of financial risk taking.
Neuron, 47 (5), 763–770.



LaBoeuf, R. A., & Shafir, E. B. (2005). Decision making. In K. J. Holyoak & R.
G. Morrison (Eds.), The Cambridge handbook of thinking and reasoning (pp.
243–266). New York: Cambridge University Press.



LaFraniere, S. (2007, November 15). African crucible: Cast as witches, then
cast out. New York Times.



Lahav, R. (1997). The conscious and the non-conscious: Philosophical
implications of neuropsychology. In M. Carrier & P. K. Machamer (Eds.),
Mindscapes: Philosophy, science, and the mind. Pittsburgh, PA: University of
Pittsburgh Press.



Lai, C. S., Fisher, S. E., Hurst, J. A., Vargha-Khadem, F., & Monaco, A. P.
(2001). A forkhead-domain gene is mutated in a severe speech and language
disorder. Nature, 413 (6855), 519–523.



Langford, D. J., Crager, S. E., Shehzad, Z., Smith, S. B., Sotocinal, S. G.,
Levenstadt, J. S., et al. (2006). Social modulation of pain as evidence for
empathy in mice. Science, 312 (5782), 1967–1970.



Langleben, D. D., Loughead, J. W., Bilker, W. B., Ruparel, K., Childress, A.
R., Busch, S. I., et al. (2005). Telling truth from lie in individual subjects
with fast event-related fMRI. Hum Brain Mapp, 26 (4), 262–272.



Langleben, D. D., Schroeder, L., Maldjian, J. A., Gur, R. C., McDonald, S.,
Ragland, J. D., et al. (2002). Brain activity during simulated deception: An
event-related functional magnetic resonance study. Neuroimage, 15 (3), 727–732.



Larson, E. J., & Witham, L. (1998). Leading scientists still reject God.
Nature, 394 (6691), 313.



LeDoux, J. E. (2002). Synaptic self: How our brains become who we are. New
York: Viking.



Lee, T. M., Liu, H. L., Chan, C. C., Ng, Y. B., Fox, P. T., & Gao, J. H.
(2005). Neural correlates of feigned memory impairment. Neuroimage, 28 (2),
305–313.



Leher, J. (2010, February 28). Depression’s upside. New York Times Magazine.



Levine, J. (1983). Materialism and qualia: The explanatory gap. Pacific
Philosophical Quarterly, 64, 354–361.



Levine, J. (1997). On leaving out what it’s like. In N. Block, O. Flanagan, &
G. Güzeldere (Eds.), The nature of consciousness: Philosophical debates (pp.
543–555). Cambridge, MA: MIT Press.



Levy, N. (2007). Rethinking neuroethics in the light of the extended mind
thesis. Am J Bioeth, 7 (9), 3–11.



Levy, N. (2007). Neuroethics. New York: Cambridge University Press.



Libet, B. (1999). Do we have free will? Journal of Consciousness Studies, 6
(8–9), 47–57.



Libet, B. (2001). Consciousness, free action and the brain: Commentary on John
Searle’s article. Journal of Consciousness Studies, 8 (8), 59–65.



Libet, B. (2003). Can conscious experience affect brain activity? Journal of
Consciousness Studies, 10 (12), 24–28.



Libet, B., Gleason, C. A., Wright, E. W., & Pearl, D. K. (1983). Time of
conscious intention to act in relation to onset of cerebral activity
(readiness-potential). The unconscious initiation of a freely voluntary act.
Brain, 106 (Pt. 3), 623–642.



Lieberman, M. D., Jarcho, J. M., Berman, S., Naliboff, B. D., Suyenobu, B. Y.,
Mandelkern, M., et al. (2004). The neural correlates of placebo effects: a
disruption account. Neuroimage, 22 (1), 447–455.



Litman, L., & Reber, A. S. (2005). Implicit cognition and thought. In K. J.
Holyoak & R. G. Morrison (Eds.), The Cambridge handbook of thinking and
reasoning (pp. 431–453). New York: Cambridge University Press.



Livingston, K. R. (2005). Religious practice, brain, and belief. Journal of
Cognition and Culture, 5 (1–2), 75–117.



Llinás, R. (2001). I of the vortex: From neurons to self. Cambridge, MA: MIT
Press.



Llinás, R., Ribary, U., Contreras, D., & Pedroarena, C. (1998). The neuronal
basis for consciousness. Philos Trans R Soc Lond B Biol Sci, 353 (1377),
1841–1849.



Logothetis, N. K. (1999). Vision: A window on consciousness. Sci Am, 281 (5),
69–75.



Logothetis, N. K. (2008). What we can do and what we cannot do with fMRI.
Nature, 453 (7197), 869–878.



Logothetis, N. K., Pauls, J., Augath, M., Trinath, T., & Oeltermann, A. (2001).
Neurophysiological investigation of the basis of the fMRI signal. Nature, 412
(6843), 150–157.



Logothetis, N. K., & Pfeuffer, J. (2004). On the nature of the BOLD fMRI
contrast mechanism. Magn Reson Imaging, 22 (10), 1517–1531.



Lou, H. C., Luber, B., Crupain, M., Keenan, J. P., Nowak, M., Kjaer, T. W., et
al. (2004). Parietal cortex and representation of the mental self. Proc Natl
Acad Sci USA, 101 (17), 6827–6832.



Lou, H. C., Nowak, M., & Kjaer, T. W. (2005). The mental self. Prog Brain Res,
150, 197–204.



Lugo, L. D. (2008). U.S. Religious Landscape Survey, Pew Research Center.



Lutz, A., Brefczynski-Lewis, J., Johnstone, T., & Davidson, R. J. (2008).
Regulation of the neural circuitry of emotion by compassion meditation: effects
of meditative expertise. PLoS ONE, 3 (3), e1897.



Lutz, A., Greischar, L. L., Rawlings, N. B., Ricard, M., & Davidson, R. J.
(2004). Long-term meditators self-induce high-amplitude gamma synchrony during
mental practice. Proc Natl Acad Sci USA, 101 (46), 16369–16373.



Lutz, A., Slagter, H. A., Dunne, J. D., & Davidson, R. J. (2008). Attention
regulation and monitoring in meditation. Trends Cogn Sci, 12 (4), 163–169.



Lykken, D. T., & Tellegen, A. (1996). Happiness is a stochastic phenomenon.
Psychological Science, 7 (3), 186–189.



Mackie, J. L. (1977). Ethics: Inventing right and wrong. London: Penguin.



Macrae, C. N., Moran, J. M., Heatherton, T. F., Banfield, J. F., & Kelley, W.
M. (2004). Medial prefrontal activity predicts memory for self. Cereb Cortex,
14 (6), 647–654.



Maddox, J. (1981). A book for burning? Nature, 293 (September 24), 245–246.



Maddox, J. (1995). The prevalent distrust of science. Nature, 378 (6556),
435–437.



Maguire, E. A., Frith, C. D., & Morris, R. G. (1999). The functional
neuroanatomy of comprehension and memory: The importance of prior knowledge.
Brain, 122 (Pt. 10), 1839–1850.



Mark, V. (1996). Conflicting communicative behavior in a split-brain patient:
Support for dual consciousness. In S. Hameroff, A. W. Kaszniak, & A. C. Scott
(Eds.), Toward a science of consciousness: The first Tucson discussions and
debates (pp. 189–196). Cambridge, MA: MIT Press.



Marks, C. E. (1980). Commissurotomy, consciousness, and the unity of mind.
Montgomery, VT: Bradford Books.



Marr, D. (1982). Vision: A computational investigation into the human
representation and processing of visual information. San Francisco: W. H.
Freeman.



Marx, K. ([1843] 1971). Critique of Hegel’s philosophy of right (A. J.
O’Malley, Trans.). Cambridge, UK: Cambridge University Press.



Mason, M. F., Norton, M. I., Van Horn, J. D., Wegner, D. M., Grafton, S. T., &
Macrae, C. N. (2007). Wandering minds: The default network and
stimulus-independent thought. Science, 315 (5810), 393–395.



Masserman, J. H., Wechkin, S., & Terris, W. (1964). “Altruistic” behavior in
rhesus monkeys. Am J Psychiatry, 121, 584–585.



Matsumoto, K., & Tanaka, K. (2004). The role of the medial prefrontal cortex in
achieving goals. Curr Opin Neurobiol, 14 (2), 178–185.



McCloskey, M. S., Phan, K. L., & Coccaro, E. F. (2005). Neuroimaging and
personality disorders. Curr Psychiatry Rep, 7 (1), 65–72.



McClure, S. M., Li, J., Tomlin, D., Cypert, K. S., Montague, L. M., & Montague,
P. R. (2004). Neural correlates of behavioral preference for culturally
familiar drinks. Neuron, 44 (2), 379–387.



McCrone, J. (2003). Free will. Lancet Neurol, 2 (1), 66.



McElreath, R., & Boyd, R. (2007). Mathematical models of social evolution: A
guide for the perplexed. Chicago; London: University of Chicago Press.



McGinn, C. (1989). Can we solve the mind-body problem? Mind, 98, 349–366.



McGinn, C. (1999). The mysterious flame: Conscious minds in a material world.
New York: Basic Books.



McGuire, P. K., Bench, C. J., Frith, C. D., Marks, I. M., Frackowiak, R. S., &
Dolan, R. J. (1994). Functional anatomy of obsessive-compulsive phenomena. Br J
Psychiatry, 164 (4), 459–468.



McKiernan, K. A., Kaufman, J. N., Kucera-Thompson, J., & Binder, J. R. (2003).
A parametric manipulation of factors affecting task-induced deactivation in
functional neuroimaging. J Cogn Neurosci, 15 (3), 394–408.



McNeil, B. J., Pauker, S. G., Sox, H. C., Jr., & Tversky, A. (1982). On the
elicitation of preferences for alternative therapies. N Engl J Med, 306 (21),
1259–1262.



Mekel-Bobrov, N., Gilbert, S. L., Evans, P. D., Vallender, E. J., Anderson, J.
R., Hudson, R. R., et al. (2005). Ongoing adaptive evolution of ASPM, a brain
size determinant in Homo sapiens. Science, 309 (5741), 1720–1722.



Meriau, K., Wartenburger, I., Kazzer, P., Prehn, K., Lammers, C. H., van der
Meer, E., et al. (2006). A neural network reflecting individual differences in
cognitive processing of emotions during perceptual decision making. Neuroimage,
33 (3), 1016–1027.



Merleau-Ponty, M. (1964). The primacy of perception, and other essays on
phenomenological psychology, the philosophy of art, history, and politics.
Evanston, IL: Northwestern University Press.



Mesoudi, A., Whiten, A., & Dunbar, R. (2006). A bias for social information in
human cultural transmission. Br J Psychol, 97 (Pt. 3), 405–423.



Mill, J. S. (1863). Utilitarianism. London: Parker, Son, and Bourn.



Miller, E. K., & Cohen, J. D. (2001). An integrative theory of prefrontal
cortex function. Annu Rev Neurosci, 24, 167–202.



Miller, G. (2008). Investigating the psychopathic mind. Science, 321 (5894),
1284–1286.



Miller, G. (2008). Neuroimaging. Growing pains for fMRI. Science, 320 (5882),
1412–1414.



Miller, G. F. (2007). Sexual selection for moral virtues. Q Rev Biol, 82 (2),
97–125.



Miller, K. R. (1999). Finding Darwin’s God: A scientist’s search for common
ground between God and evolution (1st ed.). New York: Cliff Street Books.



Miller, W. I. (1993). Humiliation: And other essays on honor, social
discomfort, and violence. Ithaca, NY: Cornell University Press.



Miller, W. I. (1997). The anatomy of disgust. Cambridge, MA: Harvard University
Press.



Miller, W. I. (2003). Faking it. Cambridge, UK; New York: Cambridge University
Press.



Miller, W. I. (2006). Eye for an eye. Cambridge, UK; New York: Cambridge
University Press.



Mink, J. W. (1996). The basal ganglia: focused selection and inhibition of
competing motor programs. Prog Neurobiol, 50 (4), 381–425.



Mitchell, I. J., Heims, H., Neville, E. A., & Rickards, H. (2005). Huntington’s
disease patients show impaired perception of disgust in the gustatory and
olfactory modalities. J Neuropsychiatry Clin Neurosci, 17 (1), 119–121.



Mitchell, J. P., Dodson, C. S., & Schacter, D. L. (2005). fMRI evidence for the
role of recollection in suppressing misattribution errors: The illusory truth
effect. J Cogn Neurosci, 17 (5), 800–810.



Mitchell, J. P., Macrae, C. N., & Banaji, M. R. (2006). Dissociable medial
prefrontal contributions to judgments of similar and dissimilar others. Neuron,
50 (4), 655–663.



Mlodinow, L. (2008). The drunkard’s walk: How randomness rules our lives. New
York: Pantheon.



Moll, J., & de Oliveira-Souza, R. (2007). Moral judgments, emotions and the
utilitarian brain. Trends Cogn Sci, 11 (8), 319–321.



Moll, J., de Oliveira-Souza, R., Garrido, G. J., Bramati, I. E.,
Caparelli-Daquer, E. M., Paiva, M. L., et al. (2007). The self as a moral
agent: Linking the neural bases of social agency and moral sensitivity. Soc
Neurosci, 2 (3–4), 336–352.



Moll, J., de Oliveira-Souza, R., Moll, F. T., Ignacio, F. A., Bramati, I. E.,
Caparelli-Daquer, E. M., et al. (2005). The moral affiliations of disgust: A
functional MRI study. Cogn Behav Neurol, 18 (1), 68–78.



Moll, J., de Oliveira-Souza, R., & Zahn, R. (2008). The neural basis of moral
cognition: sentiments, concepts, and values. Ann NY Acad Sci, 1124, 161–180.



Moll, J., Zahn, R., de Oliveira-Souza, R., Krueger, F., & Grafman, J. (2005).
Opinion: The neural basis of human moral cognition. Nat Rev Neurosci, 6 (10),
799–809.



Monchi, O., Petrides, M., Strafella, A. P., Worsley, K. J., & Doyon, J. (2006).
Functional role of the basal ganglia in the planning and execution of actions.
Ann Neurol, 59 (2), 257–264.



Mooney, C. (2005). The Republican war on science. New York: Basic Books.



Mooney, C., & Kirshenbaum, S. (2009). Unscientific America: How scientific
illiteracy threatens our future. New York: Basic Books.



Moore, G. E. ([1903] 2004). Principia ethica. Mineola, NY: Dover Publications.



Moran, J. M., Macrae, C. N., Heatherton, T. F., Wyland, C. L., & Kelley, W. M.
(2006). Neuroanatomical evidence for distinct cognitive and affective
components of self. J Cogn Neurosci, 18 (9), 1586–1594.



Moreno, J. D. (2003). Neuroethics: An agenda for neuroscience and society. Nat
Rev Neurosci, 4 (2), 149–153.



Morse, D. (2009, March 31). Plea deal includes resurrection clause. Washington
Post, B02.



Mortimer, M., & Toader, A. (2005). Blood feuds blight Albanian lives. September
23. Retrieved July 7, 2009, from http://news.bbc.co.uk/2/hi/europe/4273020.stm.



Muller, J. L., Ganssbauer, S., Sommer, M., Dohnel, K., Weber, T.,
Schmidt-Wilcke, T., et al. (2008). Gray matter changes in right superior
temporal gyrus in criminal psychopaths. Evidence from voxel-based morphometry.
Psychiatry Res, 163 (3), 213–222.



Nagel, T. (1974). What is it like to be a bat? Philosophical Review, 83,
435–456.



Nagel, T. (1979). Brain bisection and the unity of consciousness. In Mortal
questions. Cambridge, UK: Cambridge University Press, 147–164.



Nagel, T. (1979). Mortal/Questions. Cambridge, UK: Cambridge University Press.



Nagel, T. (1986). The view from nowhere. Oxford, UK: Oxford University Press.



Nagel, T. (1995). Other minds. Oxford, UK: Oxford University Press.



Nagel, T. (1997). The last word. Oxford, UK: Oxford University Press.



Nagel, T. (1998). Conceiving the impossible and the mind body problem.
Philosophy, 73 (285), 337–352.



Narayan, V. M., Narr, K. L., Kumari, V., Woods, R. P., Thompson, P. M., Toga,
A. W., et al. (2007). Regional cortical thinning in subjects with violent
antisocial personality disorder or schizophrenia. Am J Psychiatry, 164 (9),
1418–1427.



National Academy of Sciences (U.S.). Working Group on Teaching Evolution.
(1998). Teaching about evolution and the nature of science. Washington, DC:
National Academies Press.



National Academy of Sciences (U.S.) & Institute of Medicine (U.S.) (2008).
Science, evolution, and creationism. Washington, DC: National Academies Press.



Newberg, A., Alavi, A., Baime, M., Pourdehnad, M., Santanna, J., & d’Aquili, E.
(2001). The measurement of regional cerebral blood flow during the complex
cognitive task of meditation: A preliminary SPECT study. Psychiatry Res, 106
(2), 113–122.



Newberg, A., Pourdehnad, M., Alavi, A., & d’Aquili, E. G. (2003). Cerebral
blood flow during meditative prayer: Preliminary findings and methodological
issues. Percept Mot Skills, 97 (2), 625–630.



Newberg, A. B., Wintering, N. A., Morgan, D., & Waldman, M. R. (2006). The
measurement of regional cerebral blood flow during glossolalia: A preliminary
SPECT study. Psychiatry Res, 148 (1), 67–71.



Ng, F. (2007). The interface between religion and psychosis. Australas
Psychiatry, 15 (1), 62–66.



Nørretranders, T. (1998). The user illusion: Cutting consciousness down to
size. New York: Viking.



Norris, P., & Inglehart, R. (2004). Sacred and secular: Religion and politics
worldwide. Cambridge, UK: Cambridge University Press.



Northoff, G., Heinzel, A., Bermpohl, F., Niese, R., Pfennig, A., Pascual-Leone,
A., et al. (2004). Reciprocal modulation and attenuation in the prefrontal
cortex: An fMRI study on emotional-cognitive interaction. Hum Brain Mapp, 21
(3), 202–212.



Northoff, G., Heinzel, A., de Greck, M., Bermpohl, F., Dobrowolny, H., &
Panksepp, J. (2006). Self-referential processing in our brain—a meta-analysis
of imaging studies on the self. Neuroimage, 31 (1), 440–457.



Nowak, M. A., & Sigmund, K. (2005). Evolution of indirect reciprocity. Nature,
437 (7063), 1291–1298.



Nozick, R. (1974). Anarchy, state, and utopia. New York: Basic Books.



Nunez, J. M., Casey, B. J., Egner, T., Hare, T., & Hirsch, J. (2005).
Intentional false responding shares neural substrates with response conflict
and cognitive control. Neuroimage, 25 (1), 267–277.



O’Doherty, J., Critchley, H., Deichmann, R., & Dolan, R. J. (2003).
Dissociating valence of outcome from behavioral control in human orbital and
ventral prefrontal cortices. J Neurosci, 23 (21), 7931–7939.



O’Doherty, J., Kringelbach, M. L., Rolls, E. T., Hornak, J., & Andrews, C.
(2001). Abstract reward and punishment representations in the human
orbitofrontal cortex. Nat Neurosci, 4 (1), 95–102.



O’Doherty, J., Rolls, E. T., Francis, S., Bowtell, R., & McGlone, F. (2001).
Representation of pleasant and aversive taste in the human brain. J
Neurophysiol, 85 (3), 1315–1321.



O’Doherty, J., Winston, J., Critchley, H., Perrett, D., Burt, D. M., & Dolan,
R. J. (2003). Beauty in a smile: The role of medial orbitofrontal cortex in
facial attractiveness. Neuropsychologia, 41 (2), 147–155.



Oliver, A. M., & Steinberg, P. F. (2005). The road to martyrs’ square: A
journey into the world of the suicide bomber. New York: Oxford University
Press.



Olsson, A., Ebert, J. P., Banaji, M. R., & Phelps, E. A. (2005). The role of
social groups in the persistence of learned fear. Science, 309 (5735), 785–787.



Osherson, D., Perani, D., Cappa, S., Schnur, T., Grassi, F., & Fazio, F.
(1998). Distinct brain loci in deductive versus probabilistic reasoning.
Neuropsychologia, 36 (4), 369–376.



Parens, E., & Johnston, J. (2007). Does it make sense to speak of neuroethics?
Three problems with keying ethics to hot new science and technology. EMBO Rep,
8 Spec No, S61–64.



Parfit, D. (1984). Reasons and persons. Oxford, UK: Clarendon Press.



Patterson, K., Nestor, P. J., & Rogers, T. T. (2007). Where do you know what
you know? The representation of semantic knowledge in the human brain. Nat Rev
Neurosci, 8 (12), 976–987.



Patterson, N., Richter, D. J., Gnerre, S., Lander, E. S., & Reich, D. (2006).
Genetic evidence for complex speciation of humans and chimpanzees. Nature, 441
(7097), 1103–1108.



Patterson, N., Richter, D. J., Gnerre, S., Lander, E. S., & Reich, D. (2008).
Patterson et al. reply. Nature, 452 (7184), E4.



Paul, G. (2009). The chronic dependence of popular religiosity upon
dysfunctional psychosociological conditions. Evolutionary Psychology, 7 (3),
398–441.



Pauli, W., Enz, C. P., & Meyenn, K. von ([1955] 1994). Writings on physics and
philosophy. Berlin; New York: Springer-Verlag.



Paulson, S. (2006). The believer. Retrieved July 24, 2009, from
www.salon.com/books/int/2006/08/07/collins/index.html.



Paulus, M. P., Rogalsky, C., Simmons, A., Feinstein, J. S., & Stein, M. B.
(2003). Increased activation in the right insula during risk-taking decision
making is related to harm avoidance and neuroticism. Neuroimage, 19 (4),
1439–1448.



Pavlidis, I., Eberhardt, N. L., & Levine, J. A. (2002). Seeing through the face
of deception. Nature, 415 (6867), 35.



Pedersen, C. A., Ascher, J. A., Monroe, Y. L., & Prange, A. J., Jr. (1982).
Oxytocin induces maternal behavior in virgin female rats. Science, 216 (4546),
648–650.



Pennisi, E. (1999). Are our primate cousins “conscious”? Science, 284 (5423),
2073–2076.



Penrose, R. (1994). Shadows of the mind. Oxford, UK: Oxford University Press.



Perry, J. (2001). Knowledge, possibility, and consciousness. Cambridge, MA: MIT
Press.



Persinger, M. A., & Fisher, S. D. (1990). Elevated, specific temporal lobe
signs in a population engaged in psychic studies. Percept Mot Skills, 71 (3 Pt.
1), 817–818.



Pessiglione, M., Schmidt, L., Draganski, B., Kalisch, R., Lau, H., Dolan, R.
J., et al. (2007). How the brain translates money into force: A neuroimaging
study of subliminal motivation. Science, 316 (5826), 904–906.



Pierre, J. M. (2001). Faith or delusion? At the crossroads of religion and
psychosis. J Psychiatr Pract, 7 (3), 163–172.



Pinker, S. (1997). How the mind works. New York: Norton.



Pinker, S. (2002). The blank slate: The modern denial of human nature. New
York: Viking.



Pinker, S. (2007, March 19). A history of violence. The New Republic.



Pinker, S. (2008). The stupidity of dignity. The New Republic (May 28).



Pinker, S. (2008, January 13). The moral instinct. New York Times Magazine.



Pinker, S., & Jackendoff, R. (2005). The faculty of language: What’s special
about it? Cognition, 95 (2), 201–236.



Pizarro, D. A., & Bloom, P. (2003). The intelligence of the moral intuitions:
comment on Haidt (2001). Psychol Rev, 110 (1), 193–196; discussion 197–198.



Pizarro, D. A., & Uhlmann, E. L. (2008). The motivated use of moral principles.
(Unpublished manuscript.)



Planck, M., & Murphy, J. V. (1932). Where is science going? New York: W. W.
Norton.



Poldrack, R. A. (2006). Can cognitive processes be inferred from neuroimaging
data? Trends Cogn Sci, 10 (2), 59–63.



Polkinghorne, J. C. (2003). Belief in God in an age of science. New Haven, CT:
Yale University Press.



Polkinghorne, J. C., & Beale, N. (2009). Questions of truth: Fifty-one
responses to questions about God, science, and belief (1st ed.). Louisville,
KY: Westminster John Knox Press.



Pollard Sacks, D. (2009). State actors beating children: A call for judicial
relief. U.C. Davis Law Review, 42, 1165–1229.



Popper, K. R. (2002). The open society and its enemies (5th ed.). London; New
York: Routledge.



Popper, K. R., & Eccles, J. C. ([1977] 1993). The self and its brain. London:
Routledge.



Prabhakaran, V., Rypma, B., & Gabrieli, J. D. (2001). Neural substrates of
mathematical reasoning: A functional magnetic resonance imaging study of
neocortical activation during performance of the necessary arithmetic
operations test. Neuropsychology, 15 (1), 115–127.



Prado, J., Noveck, I. A., & Van Der Henst, J. B. (2009). Overlapping and
distinct neural representations of numbers and verbal transitive series. Cereb
Cortex, 20(3), 720–729.



Premack, D., & Woodruff, G. (1978). Chimpanzee problem-solving: A test for
comprehension. Science, 202 (4367), 532–535.



Previc, F. H. (2006). The role of the extrapersonal brain systems in religious
activity. Conscious Cogn, 15 (3), 500–539.



Prinz, J. (2001). Functionalism, dualism and consciousness. In W. Bechtel, P.
Mandik, J. Mundale, & R. Stufflebeam (Eds.), Philosophy and the neurosciences.
Oxford, UK: Blackwell, 278–294.



Pryse-Phillips, W. (2003). The Oxford companion to clinical neurology. Oxford,
UK: Oxford University Press.



Puccetti, R. (1981). The case for mental duality: Evidence from split-brain
data and other considerations. Behavioral and Brain Sciences, (1981) (4),
93–123.



Puccetti, R. (1993). Dennett on the split-brain. Psycoloquy, 4 (52).



Putnam, H. (2007). The fact/value dichotomy and its critics. Paper presented at
the UCD Ulysses Medal Lecture. Retrieved from
www.youtube.com/watch?v=gTWKSb8ajXc&feature=player_embedded.



Pyysiäinen, I., & Hauser, M. (2010). The origins of religion: Evolved
adaptation or by-product? Trends Cogn Sci, 14 (3), 104–109.



Quiroga, R. Q., Reddy, L., Kreiman, G., Koch, C., & Fried, I. (2005). Invariant
visual representation by single neurons in the human brain. Nature, 435 (7045),
1102–1107.



Racine, E. (2007). Identifying challenges and conditions for the use of
neuroscience in bioethics. Am J Bioeth, 7 (1), 74–76; discussion W71–74.



Raichle, M. E., MacLeod, A. M., Snyder, A. Z., Powers, W. J., Gusnard, D. A., &
Shulman, G. L. (2001). A default mode of brain function. Proc Natl Acad Sci
USA, 98 (2), 676–682.



Raine, A., & Yaling, Y. (2006). The neuroanatomical bases of psychopathy: A
review of brain imaging findings. In C. J. Patrick (Ed.), Handbook of
psychopathy (pp. 278–295). New York: Guilford Press.



Ramachandran, V. S. (1995). Anosognosia in parietal lobe syndrome. Conscious
Cogn, 4 (1), 22–51.



Ramachandran, V. S. (2007). The neurology of self-awareness, retrieved December
5, 2008, from
www.edge.org/3rd_culture/ramachandran07/ramachandran07_index.html.



Ramachandran, V. S., & Blakeslee, S. (1998). Phantoms in the brain. New York:
William Morrow and Company.



Ramachandran, V. S., & Hirstein, W. (1997). Three laws of qualia: What
neurology tells us about the biological functions of consciousness. Journal of
Consciousness Studies, 4 (5/6), 429–457.



Range, F., Horn, L., Viranyi, Z., & Huber, L. (2009). The absence of reward
induces inequity aversion in dogs. Proc Natl Acad Sci USA, 106 (1), 340–345.



Raskin, R., & Terry, H. (1988). A principal-components analysis of the
Narcissistic Personality Inventory and further evidence of its construct
validity. J Pers Soc Psychol, 54 (5), 890–902.



Rauch, S. L., Kim, H., Makris, N., Cosgrove, G. R., Cassem, E. H., Savage, C.
R., et al. (2000). Volume reduction in the caudate nucleus following
stereotactic placement of lesions in the anterior cingulate cortex in humans: A
morphometric magnetic resonance imaging study. J Neurosurg, 93 (6), 1019–1025.



Rauch, S. L., Makris, N., Cosgrove, G. R., Kim, H., Cassem, E. H., Price, B.
H., et al. (2001). A magnetic resonance imaging study of regional cortical
volumes following stereotactic anterior cingulotomy. CNS Spectr, 6 (3),
214–222.



Rawls, J. ([1971] 1999). A theory of justice (Rev. ed.). Cambridge, MA.:
Belknap Press of Harvard University Press.



Rawls, J., & Kelly, E. (2001). Justice as fairness: A restatement. Cambridge,
MA: Harvard University Press.



Redelmeier, D. A., Katz, J., & Kahneman, D. (2003). Memories of colonoscopy: A
randomized trial. Pain, 104 (1–2), 187–194.



Resnik, D. B. (2007). Neuroethics, national security and secrecy. Am J Bioeth,
7 (5), 14–15.



Richell, R. A., Mitchell, D. G., Newman, C., Leonard, A., Baron-Cohen, S., &
Blair, R. J. (2003). Theory of mind and psychopathy: Can psychopathic
individuals read the “language of the eyes”? Neuropsychologia, 41 (5), 523–526.



Ridderinkhof, K. R., Ullsperger, M., Crone, E. A., & Nieuwenhuis, S. (2004).
The role of the medial frontal cortex in cognitive control. Science, 306
(5695), 443–447.



Rilling, J., Gutman, D., Zeh, T., Pagnoni, G., Berns, G., & Kilts, C. (2002). A
neural basis for social cooperation. Neuron, 35 (2), 395–405.



Rodriguez-Moreno, D., & Hirsch, J. (2009). The dynamics of deductive reasoning:
An fMRI investigation. Neuropsychologia, 47 (4), 949–961.



Rolls, E. T., Grabenhorst, F., & Parris, B. A. (2008). Warm pleasant feelings
in the brain. Neuroimage, 41 (4), 1504–1513.



Rosenblatt, A., Greenberg, J., Solomon, S., Pyszczynski, T., & Lyon, D. (1989).
Evidence for terror management theory: I. The effects of mortality salience on
reactions to those who violate or uphold cultural values. J Pers Soc Psychol,
57 (4), 681–690.



Rosenhan, D. L. (1973). On being sane in insane places. Science, 179 (70),
250–258.



Rosenthal, D. (1991). The nature of mind. Oxford, UK: Oxford University Press.



Roskies, A. (2002). Neuroethics for the new millennium. Neuron, 35 (1), 21–23.



Roskies, A. (2006). Neuroscientific challenges to free will and responsibility.
Trends Cogn Sci, 10 (9), 419–423.



Royet, J. P., Plailly, J., Delon-Martin, C., Kareken, D. A., & Segebarth, C.
(2003). fMRI of emotional responses to odors: Influence of hedonic valence and
judgment, handedness, and gender. Neuroimage, 20 (2), 713–728.



Rubin, A. J. (2009, August 12). How Baida wanted to die. New York Times, MM38.



Rule, R. R., Shimamura, A. P., & Knight, R. T. (2002). Orbitofrontal cortex and
dynamic filtering of emotional stimuli. Cogn Affect Behav Neurosci, 2 (3),
264–270.



Rumelhart, D. E. (1980). Schemata: The building blocks of cognition. In R. J.
Spiro, B. C. Bruce, & W. F. Brewer (Eds.), Theoretical issues in reading
comprehension (pp. 33–58). Hillsdale, NJ: Erlbaum.



Ryle, G. ([1949] 1984). The concept of mind. Chicago: University of Chicago
Press.



Sagan, C. (1995). The demon-haunted world: Science as a candle in the dark (1st
ed.). New York: Random House.



Salter, A. C. (2003). Predators: Pedophiles, rapists, and other sex offenders:
Who they are, how they operate, and how we can protect ourselves and our
children. New York: Basic Books.



Sarmiento, E. E., Sawyer, G. J., Milner, R., Deak, V., & Tattersall, I. (2007).
The last human: A guide to twenty-two species of extinct humans. New Haven, CT:
Yale University Press.



Sartre, J. P. ([1956] 1994). Being and nothingness (H. Barnes, Trans.). New
York: Gramercy Books.



Saxe, R., & Kanwisher, N. (2003). People thinking about thinking people: The
role of the temporo-parietal junction in “theory of mind.” Neuroimage, 19 (4),
1835–1842.



Schacter, D. L. (1987). Implicit expressions of memory in organic amnesia:
learning of new facts and associations. Hum Neurobiol, 6 (2), 107–118.



Schacter, D. L., & Scarry, E. (1999). Memory, brain, and belief. Cambridge, MA:
Harvard University Press.



Schall, J. D., Stuphorn, V., & Brown, J. W. (2002). Monitoring and control of
action by the frontal lobes. Neuron, 36 (2), 309–322.



Schiff, N. D., Giacino, J. T., Kalmar, K., Victor, J. D., Baker, K., Gerber,
M., et al. (2007). Behavioural improvements with thalamic stimulation after
severe traumatic brain injury. Nature, 448 (7153), 600–603.



Schiffer, F., Zaidel, E., Bogen, J., & Chasan-Taber, S. (1998). Different
psychological status in the two hemispheres of two split-brain patients.
Neuropsychiatry Neuropsychol Behav Neurol, 11 (3), 151–156.



Schjoedt, U., Stodkilde-Jorgensen, H., Geertz, A. W., & Roepstorff, A. (2008).
Rewarding prayers. Neurosci Lett, 443 (3), 165–168.



Schjoedt, U., Stodkilde-Jorgensen, H., Geertz, A. W., & Roepstorff, A. (2009).
Highly religious participants recruit areas of social cognition in personal
prayer. Soc Cogn Affect Neurosci, 4 (2), 199–207.



Schmitt, J. J., Hartje, W., & Willmes, K. (1997). Hemispheric asymmetry in the
recognition of emotional attitude conveyed by facial expression, prosody and
propositional speech. Cortex, 33 (1), 65–81.



Schneider, F., Bermpohl, F., Heinzel, A., Rotte, M., Walter, M., Tempelmann,
C., et al. (2008). The resting brain and our self: Self-relatedness modulates
resting state neural activity in cortical midline structures. Neuroscience, 157
(1), 120–131.



Schnider, A. (2001). Spontaneous confabulation, reality monitoring, and the
limbic system—a review. Brain Res Brain Res Rev, 36 (2–3), 150–160.



Schreiber, C. A., & Kahneman, D. (2000). Determinants of the remembered utility
of aversive sounds. J Exp Psychol Gen, 129 (1), 27–42.



Schrödinger, E. (1964). My view of the world (C. Hastings, Trans.). Cambridge,
UK: Cambridge University Press.



Schwartz, B. (2004). The paradox of choice: Why more is less. New York: Ecco.



Seabrook, J. (2008, November 10). Suffering souls. New Yorker, 64–73.



Searle, J. (1964). How to derive “ought” from “is”. Philosophical Review 73
(1), 43–58.



Searle, J. (2001). Free will as a problem in neurobiology. Philosophy, 76,
491–514.



Searle, J. R. (1992). The rediscovery of the mind. Cambridge, MA: MIT Press.



Searle, J. R. (1995). The construction of social reality. New York: The Free
Press.



Searle, J. R. (1997). Consciousness and the philosophers. New York Review of
Books, XLIV (4).



Searle, J. R. (1998). How to study consciousness scientifically. Philos Trans R
Soc Lond B Biol Sci, 353 (1377), 1935–1942.



Searle, J. R. (2000). Consciousness. Annu Rev Neurosci, 23, 557–578.



Searle, J. R. (2001). Further reply to Libet. Journal of Consciousness Studies,
8 (8), 63–65.



Searle, J. R. (2007). Dualism revisited. J Physiol Paris, 101 (4–6), 169–178.



Searle, J. R., Dennett, D. C., & Chalmers, D. J. (1997). The mystery of
consciousness (1st ed.). New York: New York Review of Books.



Seeley, W. W., Carlin, D. A., Allman, J. M., Macedo, M. N., Bush, C., Miller,
B. L., et al. (2006). Early frontotemporal dementia targets neurons unique to
apes and humans. Ann Neurol, 60 (6), 660–667.



Sergent, J., Ohta, S., & MacDonald, B. (1992). Functional neuroanatomy of face
and object processing: A positron emission tomography study. Brain, 115 Pt. 1,
15–36.



Seybold, K. S. (2007). Physiological mechanisms involved in
religiosity/spirituality and health. J Behav Med, 30 (4), 303–309.



Shadlen, M. N., & Kiani, R. (2007). Neurology: An awakening. Nature, 448
(7153), 539–540.



Shadlen, M. N., & Movshon, J. A. (1999). Synchrony unbound: A critical
evaluation of the temporal binding hypothesis. Neuron, 24 (1), 67–77, 111–125.



Shadlen, M. N., & Newsome, W. T. (2001). Neural basis of a perceptual decision
in the parietal cortex (area LIP) of the rhesus monkey. J Neurophysiol, 86 (4),
1916–1936.



Shamay-Tsoory, S. G., Tibi-Elhanany, Y., & Aharon-Peretz, J. (2007). The
green-eyed monster and malicious joy: The neuroanatomical bases of envy and
gloating (schadenfreude). Brain, 130 (Pt. 6), 1663–1678.



Sheldrake, R. (1981). A new science of life: The hypothesis of formative
causation. London: Blond & Briggs.



Sheline, Y. I., Barch, D. M., Price, J. L., Rundle, M. M., Vaishnavi, S. N.,
Snyder, A. Z., et al. (2009). The default mode network and self-referential
processes in depression. Proc Natl Acad Sci USA, 106 (6), 1942–1947.



Shoebat, W. (2007). Why we want to kill you: The jihadist mindset and how to
defeat it. [United States]: Top Executive Media.



Shweder, R. A. (2006, November 27). Atheists agonistes. New York Times.



Siebert, C. (2009, July 12). Watching whales watching us. New York Times.



Siefe, C. (2000). Cold numbers unmake the quantum mind. Science, 287 (5454),
791.



Silk, J. B., Brosnan, S. F., Vonk, J., Henrich, J., Povinelli, D. J.,
Richardson, A. S., et al. (2005). Chimpanzees are indifferent to the welfare of
unrelated group members. Nature, 437 (7063), 1357–1359.



Silver, L. M. (2006). Challenging nature: The clash of science and spirituality
at the new frontiers of life. New York: Ecco.



Simons, D. J., Chabris, C. F., Schnur, T., & Levin, D. T. (2002). Evidence for
preserved representations in change blindness. Conscious Cogn, 11 (1), 78–97.



Simonton, D. K. (1994). Greatness: Who makes history and why. New York:
Guilford.



Singer, P. (2009). The life you can save: Acting now to end world poverty. New
York: Random House.



Singer, T., Seymour, B., O’Doherty, J., Kaube, H., Dolan, R. J., & Frith, C. D.
(2004). Empathy for pain involves the affective but not sensory components of
pain. Science, 303 (5661), 1157–1162.



Singer, W. (1999). Striving for coherence. Nature, 397 (4 February), 391–393.



Singer, W. (1999). Neuronal synchrony: A versatile code for the definition of
relations? Neuron, 24 (1), 49–65, 111–125.



Sinnott-Armstrong, W. (2006). Consequentialism. The Stanford encyclopedia of
philosophy. Retrieved from http://plato.stanford.edu/entries/consequentialism/.



Sirigu, A., Daprati, E., Ciancia, S., Giraux, P., Nighoghossian, N., Posada,
A., et al. (2004). Altered awareness of voluntary action after damage to the
parietal cortex. Nat Neurosci, 7 (1), 80–84.



Sirotin, Y. B., & Das, A. (2009). Anticipatory haemodynamic signals in sensory
cortex not predicted by local neuronal activity. Nature, 457 (7228), 475–479.



Sloman, S. A., & Lagnado, D. A. (2005). The problem of Induction. In K. J.
Holyoak & R. G. Morrison (Eds.), The Cambridge handbook of thinking and
reasoning (pp. 95–116). New York: Cambridge University Press.



Slovic, P. (2007). “If I look at the mass I will never act”: Psychic numbing
and genocide. Judgment and Decision Making, 2 (2), 79–95.



Smeltzer, M. D., Curtis, J. T., Aragona, B. J., & Wang, Z. (2006). Dopamine,
oxytocin, and vasopressin receptor binding in the medial prefrontal cortex of
monogamous and promiscuous voles. Neurosci Lett, 394 (2), 146–151.



Smith, A., & Stewart, D. ([1759] 1853). The theory of moral sentiments (New
ed.). London: H. G. Bohn.



Snowden, J. S., Austin, N. A., Sembi, S., Thompson, J. C., Craufurd, D., &
Neary, D. (2008). Emotion recognition in Huntington’s disease and
frontotemporal dementia. Neuropsychologia, 46 (11), 2638–2649.



Snyder, S. H. (2008). Seeking God in the brain—efforts to localize higher brain
functions. N Engl J Med, 358 (1), 6–7.



Sokal, A. (1996). Transgressing the boundaries: Toward a transformative
hermeneutics of quantum gravity. Social Text (46/47), 217–252.



Sommer, M., Dohnel, K., Sodian, B., Meinhardt, J., Thoermer, C., & Hajak, G.
(2007). Neural correlates of true and false belief reasoning. Neuroimage, 35
(3), 1378–1384.



Soon, C. S., Brass, M., Heinze, H. J., & Haynes, J. D. (2008). Unconscious
determinants of free decisions in the human brain. Nat Neurosci, 11 (5),
543–545.



Sowell, E. R., Thompson, P. M., Holmes, C. J., Jernigan, T. L., & Toga, A. W.
(1999). In vivo evidence for post-adolescent brain maturation in frontal and
striatal regions. Nat Neurosci, 2 (10), 859–861.



Spence, S. A., Farrow, T. F., Herford, A. E., Wilkinson, I. D., Zheng, Y., &
Woodruff, P. W. (2001). Behavioural and functional anatomical correlates of
deception in humans. Neuroreport, 12 (13), 2849–2853.



Spence, S. A., Kaylor-Hughes, C., Farrow, T. F., & Wilkinson, I. D. (2008).
Speaking of secrets and lies: The contribution of ventrolateral prefrontal
cortex to vocal deception. Neuroimage, 40 (3), 1411–1418.



Sperry, R. W. (1961). Cerebral organization and behavior: The split brain
behaves in many respects like two separate brains, providing new research
possibilities. Science, 133 (3466), 1749–1757.



Sperry, R. W. (1968). Hemisphere deconnection and unity in conscious awareness.
Am Psychol, 23 (10), 723–733.



Sperry, R. W. (1976). Changing concepts of consciousness and free will.
Perspect Biol Med, 20 (1), 9–19.



Sperry, R. W. (1982). Some effects of disconnecting the cerebral hemispheres.
Nobel Lecture, 8 December 1981. Biosci Rep, 2 (5), 265–276.



Sperry, R. W., Zaidel, E., & Zaidel, D. (1979). Self recognition and social
awareness in the deconnected minor hemisphere. Neuropsychologia, 17 (2),
153–166.



Spinoza, B. S. F., Ed. (S. Shirley, Trans.). ([1677] 1982). The ethics and
selected letters. Indianapolis, IN: Hackett Publishing.



Spitzer, M., Fischbacher, U., Herrnberger, B., Gron, G., & Fehr, E. (2007). The
neural signature of social norm compliance. Neuron, 56 (1), 185–196.



Sprengelmeyer, R., Schroeder, U., Young, A. W., & Epplen, J. T. (2006). Disgust
in pre-clinical Huntington’s disease: A longitudinal study. Neuropsychologia,
44 (4), 518–533.



Squire, L. R., & McKee, R. (1992). Influence of prior events on cognitive
judgments in amnesia. J Exp Psychol Learn Mem Cogn, 18 (1), 106–115.



Stanovich, K. E., & West, R. F. (2000). Individual differences in reasoning:
Implications for the rationality debate? Behavioral and Brain Sciences, 23,
645–726.



Stark, R. (2001). One true God: Historical consequences of monotheism.
Princeton, NJ: Princeton University Press.



Steele, J. D., & Lawrie, S. M. (2004). Segregation of cognitive and emotional
function in the prefrontal cortex: A stereotactic meta-analysis. Neuroimage, 21
(3), 868–875.



Stenger, V. A. (2009). The new atheism: Taking a stand for science and reason.
New York: Prometheus Books.



Stewart, P. (2008, May 29). Vatican says it will excommunicate women priests.
Reuters.



Stoller, S. E., & Wolpe, P. R. (2007). Emerging neurotechnologies for lie
detection and the Fifth Amendment. American Journal of Law & Medicine, 33,
359–375.



Stone, M. H. (2009). The anatomy of evil. Amherst, NY: Prometheus Books.



Strange, B. A., Henson, R. N., Friston, K. J., & Dolan, R. J. (2001). Anterior
prefrontal cortex mediates rule learning in humans. Cereb Cortex, 11 (11),
1040–1046.



Swick, D., & Turken, A. U. (2002). Dissociation between conflict detection and
error monitoring in the human anterior cingulate cortex. Proc Natl Acad Sci
USA, 99 (25), 16354–16359.



Tabibnia, G., Satpute, A. B., & Lieberman, M. D. (2008). The sunny side of
fairness: Preference for fairness activates reward circuitry (and disregarding
unfairness activates self-control circuitry). Psychol Sci, 19 (4), 339–347.



Takahashi, H., Kato, M., Matsuura, M., Mobbs, D., Suhara, T., & Okubo, Y.
(2009). When your gain is my pain and your pain is my gain: Neural correlates
of envy and schadenfreude. Science, 323 (5916), 937–939.



Tarski, A. (1969). Truth and proof. Sci Am., 220 (6), 63–77.



Tenenbaum, J. B., Kemp, C., & Shafto, P. (2007). Theory-based Bayesian models
of inductive reasoning. In A. Feeney & E. Heit (Eds.), Inductive reasoning:
Experimental, developmental, and computational approaches (pp. 167–204).
Cambridge, UK: Cambridge University Press.



Teresi, D. (1990). The lone ranger of quantum mechanics. New York Times.



Thompson, J. J. (1976). Letting die, and the trolley problem. The Monist, 59
(2), 204–217.



Tiihonen, J., Rossi, R., Laakso, M. P., Hodgins, S., Testa, C., Perez, J., et
al. (2008). Brain anatomy of persistent violent offenders: More rather than
less. Psychiatry Res, 163 (3), 201–212.



Tom, S. M., Fox, C. R., Trepel, C., & Poldrack, R. A. (2007). The neural basis
of loss aversion in decision-making under risk. Science, 315 (5811), 515–518.



Tomasello, M. (2007, January 13). For human eyes only. New York Times.



Tomlin, D., Kayali, M. A., King-Casas, B., Anen, C., Camerer, C. F., Quartz, S.
R., et al. (2006). Agent-specific responses in the cingulate cortex during
economic exchanges. Science, 312 (5776), 1047–1050.



Tononi, G., & Edelman, G. M. (1998). Consciousness and complexity. Science, 282
(5395), 1846–1851.



Trinkaus, E. (2007). Human evolution: Neandertal gene speaks out. Curr Biol, 17
(21), R917–919.



Trivers, R. (1971). The evolution of reciprocal altruism. Quarterly Review of
Biology, 46 (Mar.), 35–57.



Trivers, R. (2002). Natural selection and social theory: Selected papers of
Robert L. Trivers. New York: Oxford University Press.



Turk, D. J., Heatherton, T. F., Kelley, W. M., Funnell, M. G., Gazzaniga, M.
S., & Macrae, C. N. (2002). Mike or me? Self-recognition in a split-brain
patient. Nat Neurosci, 5 (9), 841–842.



Tversky, A., & Kahneman, D. (1974). Judgment under uncertainty: Heuristics and
biases. Science, 185 (4157), 1124–1131.



Ullsperger, M., & von Cramon, D. Y. (2003). Error monitoring using external
feedback: Specific roles of the habenular complex, the reward system, and the
cingulate motor area revealed by functional magnetic resonance imaging. J
Neurosci, 23 (10), 4308–4314.



Valdesolo, P., & DeSteno, D. (2006). Manipulations of emotional context shape
moral judgment. Psychol Sci, 17 (6), 476–477.



Van Biema, D. (2006, July 10). Reconciling God and science. Time.



van Leijenhorst, L., Crone, E. A., & Bunge, S. A. (2006). Neural correlates of
developmental differences in risk estimation and feedback processing.
Neuropsychologia, 44 (11), 2158–2170.



van Veen, V., Holroyd, C. B., Cohen, J. D., Stenger, V. A., & Carter, C. S.
(2004). Errors without conflict: Implications for performance monitoring
theories of anterior cingulate cortex. Brain Cogn, 56 (2), 267–276.



Viding, E., Jones, A. P., Frick, P. J., Moffitt, T. E., & Plomin, R. (2008).
Heritability of antisocial behaviour at 9: Do callous-unemotional traits
matter? Dev Sci, 11 (1), 17–22.



Vocat, R., Pourtois, G., & Vuilleumier, P. (2008). Unavoidable errors: A
spatiotemporal analysis of time-course and neural sources of evoked potentials
associated with error processing in a speeded task. Neuropsychologia, 46 (10),
2545–2555.



Vogel, G. (2004). Behavioral evolution. The evolution of the golden rule.
Science, 303 (5661), 1128–1131.



Vogeley, K., Bussfeld, P., Newen, A., Herrmann, S., Happé, F., Falkai, P., et
al. (2001). Mind reading: Neural mechanisms of theory of mind and
self-perspective. Neuroimage, 14 (1 Pt. 1), 170–181.



Vogeley, K., May, M., Ritzl, A., Falkai, P., Zilles, K., & Fink, G. R. (2004).
Neural correlates of first-person perspective as one constituent of human
self-consciousness. J Cogn Neurosci, 16 (5), 817–827.



Voight, B. F., Kudaravalli, S., Wen, X., & Pritchard, J. K. (2006). A map of
recent positive selection in the human genome. PLoS Biol, 4 (3), e72.



Wade, N. (2006). Before the dawn: Recovering the lost history of our ancestors.
New York: Penguin.



Wade, N. (2010, March 1). Human culture, an evolutionary force. New York Times.



Wager, T. D., & Nichols, T. E. (2003). Optimization of experimental design in
fMRI: A general framework using a genetic algorithm. Neuroimage, 18 (2),
293–309.



Wager, T. D., Rilling, J. K., Smith, E. E., Sokolik, A., Casey, K. L.,
Davidson, R. J., et al. (2004). Placebo-induced changes in fMRI in the
anticipation and experience of pain. Science, 303 (5661), 1162–1167.



Wain, O., & Spinella, M. (2007). Executive functions in morality, religion, and
paranormal beliefs. Int J Neurosci, 117 (1), 135–146.



Wakin, D. J., & McKinley Jr., J. C. (2010, May 2). Abuse case offers a view of
the Vatican’s politics. New York Times.



Waldmann, M. R., & Dieterich, J. H. (2007). Throwing a bomb on a person versus
throwing a person on a bomb: Intervention myopia in moral intuitions. Psychol
Sci, 18 (3), 247–253.



Waldmann, M. R., Hagmayer, Y., & Blaisdell, A. P. (2006). Beyond the
information given: Causal models in learning and reasoning. Current Directions
in Psychological Science, 15 (6), 307–311.



Waters, E. (2010, January 8). The Americanization of mental illness. New York
Times Magazine.



Watson, G. (1982). Free will. Oxford, UK; New York: Oxford University Press.



Weber, M. ([1922] 1993). The sociology of religion. Boston: Beacon Press.



Wegner, D. M. (2002). The illusion of conscious will. Cambridge, MA: MIT Press.



Wegner, D. M. (2004). Precis of the illusion of conscious will. Behav Brain
Sci, 27 (5), 649–659; discussion 659–692.



Weinberg, S. (2001). Facing up: Science and its cultural adversaries.
Cambridge, MA: Harvard University Press.



Westbury, C., & Dennett, D. C. (1999). Mining the past to construct the future:
Memory and belief as forms of knowledge. In D. L. Schacter & E. Scarry (Eds.),
Memory, brain, and belief (pp. 11–32). Cambridge, MA: Harvard University Press.



Westen, D., Blagov, P. S., Harenski, K., Kilts, C., & Hamann, S. (2006). Neural
bases of motivated reasoning: An fMRI study of emotional constraints on
partisan political judgment in the 2004 U.S. presidential election. J Cogn
Neurosci, 18 (11), 1947–1958.



Wicker, B., Keysers, C., Plailly, J., Royet, J. P., Gallese, V., & Rizzolatti,
G. (2003). Both of us disgusted in my insula: The common neural basis of seeing
and feeling disgust. Neuron, 40 (3), 655–664.



Wicker, B., Ruby, P., Royet, J. P., & Fonlupt, P. (2003). A relation between
rest and the self in the brain? Brain Res Rev, 43 (2), 224–230.



Wigner, E. (1960). The unreasonable effectiveness of mathematics in the natural
sciences. Communications in Pure and Applied Mathematics, 13 (1).



Williams, B. A. O. (1985). Ethics and the limits of philosophy. Cambridge, MA:
Harvard University Press.



Wilson, D. S. (2002). Darwin’s cathedral: Evolution, religion, and the nature
of society. Chicago: University of Chicago Press.



Wilson, D. S., & Wilson, E. O. (2007). Rethinking the theoretical foundation of
sociobiology. Q Rev Biol, 82 (4), 327–348.



Wilson, E. O. (1998). Consilience: The unity of knowledge (1st ed.). New York:
Knopf.



Wilson, E. O. (2005). Kin selection as the key to altruism: Its rise and fall.
Social Research, 72 (1), 159–166.



Wilson, E. O., & Holldobler, B. (2005). Eusociality: Origin and consequences.
Proc Natl Acad Sci USA, 102 (38), 13367–13371.



Wittgenstein, L. (1969). Philosophical grammar (A. Kenny, Trans.). Berkeley,
CA: University of California Press.



Woolrich, M. W., Ripley, B. D., Brady, M., & Smith, S. M. (2001). Temporal
autocorrelation in univariate linear modeling of fMRI data. Neuroimage, 14 (6),
1370–1386.



Wright, N. T. (2003). The resurrection of the Son of God. London: SPCK.



Wright, N. T. (2008). Surprised by hope: Rethinking heaven, the resurrection,
and the mission of the church (1st ed.). New York: HarperOne.



Yang, T., & Shadlen, M. N. (2007). Probabilistic reasoning by neurons. Nature,
447 (7148), 1075–1080.



Yang, Y., Glenn, A. L., & Raine, A. (2008). Brain abnormalities in antisocial
individuals: Implications for the law. Behav Sci Law, 26 (1), 65–83.



Yang, Y., Raine, A., Colletti, P., Toga, A. W., & Narr, K. L. (2009). Abnormal
temporal and prefrontal cortical gray matter thinning in psychopaths. Mol
Psychiatry, 14 (6), 561–562.



Ye’or, B. (2005). Eurabia: The Euro-Arab Axis. Madison, NJ: Fairleigh Dickinson
University Press.



Yong, E. (2008). The evolutionary story of the “language gene.” New Scientist
(2669) Aug. 13, pp. 38–41.



Young, L. J., Lim, M. M., Gingrich, B., & Insel, T. R. (2001). Cellular
mechanisms of social attachment. Horm Behav, 40 (2), 133–138.



Young, L. J., & Wang, Z. (2004). The neurobiology of pair bonding. Nat
Neurosci, 7 (10), 1048–1054.



Yu, A. J., & Dayan, P. (2005). Uncertainty, neuromodulation, and attention.
Neuron, 46 (4), 681–692.



Zaidel, E., Iacoboni, M., Zaidel, D., & Bogen, J. E. (2003). The callosal
syndromes. In Clinical Neuropsychology (pp. 347–403). Oxford, UK: Oxford
University Press.



Zaidel, E., Zaidel, D. W., & Bogen, J. (undated). The split brain. Retrieved
from www.its.caltech.edu/~jbogen/text/ref130.htm.



Zak, P. J., Kurzban, R., & Matzner, W. T. (2005). Oxytocin is associated with
human trustworthiness. Horm Behav, 48 (5), 522–527.



Zak, P. J., Stanton, A. A., & Ahmadi, S. (2007). Oxytocin increases generosity
in humans. PLoS ONE, 2 (11), e1128.



Zhang, J. X., Leung, H. C., & Johnson, M. K. (2003). Frontal activations
associated with accessing and evaluating information in working memory: An fMRI
study. Neuroimage, 20 (3), 1531–1539.



Zhu, Y., Zhang, L., Fan, J., & Han, S. (2007). Neural basis of cultural
influence on self-representation. Neuroimage, 34 (3), 1310–1316.



Zuckerman, P. (2008). Society without God. New York: New York University Press.





INDEX





The letter n after a page number means “note”; the number following an n is the
note’s number; a double nn precedes a range of note numbers.





abortion, 5, 35, 146



acetylcholine, 226n35



Adam and Eve, 40–41



adultery, 74, 91, 97



affective forecasting, 183–84



Afghanistan, 122, 196n9, 207n17



Africa, 129, 145, 156–57



aggression, 100–101, 213n78, 215n90. See also violence



AIDS, 179, 200n14



Ainslie, George, 211n51



Albania, 1



albinos, 156–57



alien hand syndrome, 105, 216n104



altruism, 56, 57, 92, 101–2, 170



altruistic punishment, 92



ambiguity, 226n35



American Anthropological Association, 205n28



American Psychiatric Association, 157



Amodio, D. M., 227n40



animals:



aggression in chimps, 100



brain size of primates, 218–19n5



caudate in, 225n35



common ancestor of chimps and humans, 114, 159



communicative behavior of, 114, 218n1, 218n5



differential rewards for, 229n61



fairness and chimps, 170, 237n90



as food source, 210–11n50



foraging behavior of, 229n61



head movements of chimps, 57



monkeys’ aversion from producing suffering in other monkeys, 170, 214n88



moral sense and, 169–70



reward system in, 9



suffering of, 171, 199n8, 210–11n50, 214n88



visual-decision task with monkeys, 228n61



well-being of, 41–42, 198–99n8, 210–11n50



answers in practice versus answers in principle, 3, 30–31, 60, 191



anthropology, 19–20, 45, 145, 147, 151, 197n25, 205–6n28. See also specific
anthropologists



anticipated memories, 185



antidepressants, 110, 182, 230n66



antisocial behavior, 99, 213n76, 214–15n89. See also psychopathy



antisocial personality disorder (ASPD), 213n76



anxiety, 97–98



aphasia, 159



Aristotle, 195n9



Asian Disease Problem, 140–41



ASPD. See antisocial personality disorder (ASPD)



atheism, 234–35n64. See also New Atheists; secular liberals



Atran, Scott, 155–56, 205n28



“autonomous hand,” 216n104



aversive sounds, 77



Babiak, P., 214n87



Bad Life versus Good Life, 15–21, 38–42



Ball, Philip, 137–39



Barrett, Justin, 151



Bechara, A., 228n61



beehive approach to morality, 89



belief:



adoption of, for feeling better, 137–39



bias and, 122–26, 137, 226n36



brain science on, 11, 14, 116–22, 197n22



definitions of, 117



different categories of, 139–40



ethical beliefs, 14



extraneous information and/or context as influence on, 140–42



factual beliefs, 14



freedom of, 136–44



inseparability of reasoning and emotion, 126–31



internet’s influence on, 123



as intrinsically epistemic, 138



knowledge as, 115, 196–97n22



lie detection and, 133–36



meaning of, 115–18, 219–20n15



memory and, 116



mental properties of, 136–40



motivation for, 126



reasoning and, 122, 131–33



religious belief, 137–38, 148–54



science and, 144



wrong beliefs, 21



Benedict, Pope, 200n14



Benedict, Ruth, 20, 60–62



Bentham, Jeremy, 207n12



bias:



adaptive fitness versus, 226–27n38



belief and, 122–26, 137, 226n36



decisional conflict, 231n75



definition of, 132



endowment effect and, 75



factors causing, 226n36



internet’s influence on, 123



knowledge and, 123–24



of liberals, 125–26



loss aversion, 75–77, 209n35



medical decisions and, 143, 231n75



of parents, 73



of political conservatives, 124–25



in reasoning, 132, 142–43



of science, 47



sins of commission versus sins of omission, 77



truth bias, 120, 223n26



unconscious and, 122–23



Bible, 3, 34, 38, 150, 166, 236–37n82



Biblical Creationism, 34, 37, 151, 202n19



Bin Laden, Osama, 5



Bingham, Roger, 5–6, 23



BioLogos Foundation, 169



birth control. See contraception



birthday wishes, 30–31



Blackford, Russell, 204n24



Blair, James, 99, 214n87, 214n88



Bloom, Paul, 151



Boas, Franz, 20



Bohr, Niels, 179



Bowles, Samuel, 101



Boyer, Pascal, 150–51



brain science:



Bad Life versus Good Life, 17–18



on belief, 11, 14, 116–22, 197n22



on change, 8



on cooperation, 55–56, 59, 61–62



on cultural norms, 9–10



on depression, 30



on disgust, 153, 212n64, 224–25n34, 233n48



early childhood experience and, 9–10



emotional circuitry of, and moral intuitions, 89, 212n71



on envy, 222n18



evolution of, 13



on facial recognition, 223n22



fears about progress in, 110



feedback and, 225–26n35



fundamental processes of, as self-generated, 103–4



illusion of free will and, 102–5, 110



and influences on well-being, 64



information processing and, 102–3, 117–18



interconnectivity and, 119–20, 222n19



on loss aversion, 75, 209n35



maximization of well-being of self and others, 83–85



on memory and language processing, 212n58, 212n71



mind as product of physical brain, 110



modularity in brain organization, 220–22n18



on moral cognition, 91–95



on moral responsibility, 216–17n109



on motivated reasoning, 227n44



multiple functions of brain regions, 119–20, 212n64, 212n71, 220–22n18,
224–26nn34–35



on neuroethics, 206n37



on psychopaths, 97–98, 204n24, 213n78, 214–15 nn 89–90



on reasoning, 228n61



religion and, 152–54, 233nn 48–49, 234n54



reward system, 92–93, 98, 153, 212n63



on schadenfreude, 222n18



split-brain research, 212n58 See also brain structures; neuroimaging research



brain structures:



amygdala, 128



anterior cingulate cortex (ACC), 154, 222n18, 225–26n35, 227n40



anterior insula, 153, 224–25n34, 233n48



anterior temporal lobe, 234n54



basal ganglia, 225–26n35



caudate nucleus in, 225–26n35



dorsal striatum, 226



frontal lobes of, 93, 118–19, 213n78, 223n22



fusiform gyrus in, 222–23n22



“grandmother cells,” 222n20



gray matter, 214–15n89



hippocampus, 234n54



insula, 119, 233n48



lateral prefrontal cortex, 228n61



limbic system, 103, 217n109



medial prefrontal cortex (MPFC), 93–94, 107, 108, 120–22, 153, 222n18,
223–24nn27–28



medial temporal lobes, 223n22, 234n54



motor regions, 103



nucleus accumbens, 98, 212n63



parahippocampal gyrus, 234n54



paralimbic system, 215n90



posterior medial cortex, 234n54



prefrontal cortex (PFC), 91–93, 103, 107, 120, 214–15n89, 223n23, 228n61,
230n66



retrosplenial cortex, 234n54



temporal lobes, 91–92, 223n22, 234n54



ventral striatum, 153



ventromedial prefrontal cortex, 228n61



white matter, 214n89, 223n23 See also brain



Brown, Andrew, 173



Bundy, Ted, 205n24



Burton, Robert, 127–29



Bush, George W., 88, 197n28



cancer, 87, 101, 143, 202n17



capital punishment, 128, 136



Carroll, Sean, 203n20



Casebeer, William, 195–96n9



categorical imperative, 81–82, 199n10



Catholic Church, 34–35, 146, 149, 179, 199–202nn 14–15, 237n82. See also
religion



children:



callousness/unemotional trait in, 99, 213n78



care about other people’s children, 40



corporal punishment of, 3, 214n88



decision to have children, 187–88



disgust felt by, 224n34



early experience of, 9–10



hospital care of, 76–77



infants’ ability to follow a person’s gaze, 57



infants’ perception of aggressors, 206n35



in Israeli kibbutzim, 73



kindness for, 38



murder of infant by religious conservatives, 158



neglect and abuse of, 9, 35, 95–96, 107–8, 199–201n14



in orphanages, 9, 200n14



parents’ attachment to, 73



religion and, 151



self-regulation of, 223n23



sexual abuse scandal in Catholic Church, 35, 199–201n14



China, 67



Christianity. See religion



Churchland, Patricia, 68, 101–2, 196n18, 210n49



cingulotomy, 226n35



Cleckley, H. M., 214n87



Clinton, Bill, 133



cognitive bias. See bias



Cohen, Jonathan, 217–18n111



Cohen, Mark, 152, 229n62, 232n19



Collins, Francis, 160–74, 235n69, 236n77



colonoscopies, 77, 184



common sense dualists, 151



communication. See language



compatibilism, 217n111



computational theory, 220n17



conduct disorder, 213n76



confirmation bias, 223n26



consciousness, 32–33, 41–42, 62, 108–9, 158–59, 221–22n18, 235n66



consensus, 31–32, 34, 198, 198n6



consequentialism, 62, 67–73, 207n12, 208n20, 210–11n50



conservatives. See political conservatives; religious conservatives



“consilience” in science, 8



conspiracy theories, 88–89, 212n57



contraception, 35, 48, 63, 179



contractual approach to morality, 89



contractualism, 78–79



cooperation, 55–62, 92, 99–100, 189, 207n7



corporal punishment, 3, 214n88



Cotard’s delusion, 127



Cox, D. D., 229n62



Coyne, Jerry, 232n19



Creationist “science,” 34, 37, 151, 202n19, 237n97



Crick, Francis, 47



criminal justice system, 106, 109, 110–11, 135–36. See also murder; prisons



cultural norms, 9–10



cultural relativism, 20–21, 45–46



“culture wars.” See religious conservatives; secular liberals



Dahmer, Jeffrey, 18–19, 34



Damasio, Antonio, 126



Danish cartoon controversy, 74–75, 179



Darwin, Charles, 13, 56



Dawkins, Richard, 23, 174



De Grey, Aubrey, 12



De Oliveira-Souza, Ricardo, 91–92, 213n78



death, 35, 125, 143. See also murder



deception, 133–36, 229n62, 229–30n66



decision making, 228–29n61



decisional conflict, 231n75



deduction, 131–32



Delgado, M. R., 226n35



delusions, 157



Dennett, Daniel, 48, 68, 105, 174, 217n111



depression, 22, 30, 182



determinism, 105, 217–18n111



Diagnostic and Statistical Manual of Mental Disorders (DSM-IV), 157



Diamond, Jared, 100–101, 110–11



disbelief, 120–22, 225–26n35, 229n62, 233n48. See also belief; uncertainty



disgust, 153, 181, 212n64, 224–25n34, 233n48



diversity, bewildered by, 85–91



Dobu islanders, 60–62



dogmatism, 22–23, 53, 124–25. See also religion



dopamine, 128, 152, 227n51



Douglas, Pamela, 229n62



DSM-IV, 157



Edelman, G. M., 196n16



Edgerton, Robert, 20, 197n25



Einstein, Albert, 179, 202n18, 236n77



Elliot, R., 228n61



embryonic stem-cell research, 5, 23, 171–73



emotions, 89, 126–31, 210n49. See also specific emotions, such as happiness



empathy, 99, 177



endowment effect, 75



envy, 222n18



ethics. See morality; values; and headings beginning with moral



Europe, 5, 145–46



Evans, Margaret, 151



evil, 27, 64–66, 100–102, 108, 109, 189–90. See also psychopathy



evolution, 11, 13–14, 36, 48–53, 56–57, 147–52, 161, 175, 207–8n19, 216n101,
237–38n99



experiencing self, 184–87



extension neglect, 208n25



facts, 4, 5–6, 10–14, 24–25, 122, 143–44. See also knowledge; science



fairness, 77–82, 89–90, 170, 209n42, 209n45, 237n90



faith. See belief; religion



fatalism versus determinism, 105



feedback, 225–26n35



feminist epistemology, 47–48



fetus in fetu, 171–72



Fifth Amendment, 135



Flanagan, Owen, 195–96n9



fMRI. See neuroimaging research



Fodor, Jerry, 11



food, 7–8, 82–83, 113–14, 197n25, 210–11n50



Foot, P., 212n67



Fox, C. R., 209n35



Franklin, Rosalind, 47



Frederick, S., 208n25



free will, 102–6, 110–12, 206n37, 215n97, 216n102, 217–18n111



freedom of belief, 136–44



Freud, Sigmund, 145



Friedman, Thomas, 202n19



Frith, Chris, 127, 128



functional magnetic resonance imaging (fMRI). See neuroimaging research



gay marriage, 5, 53, 86, 191



Gazzaniga, Michael, 216–17n109



Geertz, Clifford, 205n28



genital mutilation of females, 27, 42, 46



genocide, 133, 191, 219n7



genocide neglect, 69



Gilbert, Daniel, 183



God. See religion



Gold, J. I., 228n61



good/goodness:



Bad Life versus Good Life, 15–21, 38–42, 195–96n9



bewildered by diversity and, 85–91



cooperation and, 55–62, 92, 99–100, 189, 207n7



definition of, 12



difficulty of being good, 82–85



fairness and hierarchy, 77–82, 209n42



Greene on, 64–66, 208n20



Kahneman on, 75



Moore on open question argument, 10, 12



moral brain and, 91–95



moral paradox and, 67–77



moral responsibility and, 106–12, 216–17n109



Plato on, 30



pleasure and, 196n20



Rawls on, 210n46



of suffering, 21–22 See also happiness; well-being; and headings beginning with
moral



Gould, Stephen J., 6



Greene, Joshua, 64–66, 86, 94, 208n20, 212n71, 217–18n111



Haidt, Jonathan, 50, 85–91, 180–81, 238n3



Haiti earthquake, 68



Haldane, J. B. S., 56



Hamilton, William, 56



happiness:



Bad Life versus Good Life, 15–21, 38–42



care about others’ happiness, 57–59



difficulties in study of, 182–83



future of, 177–91



inaccurate intuitions about, 183



kindness versus cruelty for, 8, 80



maximization of, for self and others, 83–85



of parents, 73, 187–88



positive psychology on, 181–84



religion’s contribution to, 231–32n15



in secular societies, 231–32n15 See also good/goodness; well-being



Harding, Sandra, 47



Hare, Robert, 97, 214n87



harm, 89–90, 181, 238n3. See also evil; psychopathy



Hawking, Stephen, 236n77



health, 7–8, 11–12, 21, 22, 35–37, 47, 143, 195n3, 197n25, 202n17, 231n75. See
also medications; medicine



Heisenberg, Martin, 103–4



Hirsi Ali, Ayaan, 46, 207n17



Hitchens, Christopher, 174



homelessness, 70–71



homosexuality, 63, 74, 179, 233n48, 235n64. See also gay marriage



Hood, Bruce, 151



human ancestors, 114, 159, 190, 218–19n5



Human Genome Project, 160, 164–65, 235n69



Hume, David, 10, 38, 42, 196n13, 196n16, 203n20, 237n82



hypocrisy, 90



identifiable victim effect, 69, 208n25



illness. See health



illusory-truth effect, 223n26



in-group versus out-group, 90, 101–2



Inbar, Y., 233n48



indirect reciprocity, 206–7n7



induction, 131–32, 227n57



inequality. See race and racism; socioeconomic inequality



information processing, 102–3, 117–18, 220n17



instrumental aggression, 213n78, 215n90



intelligent design. See Creationist “science”



internet, 123, 187



intolerance, 138–39, 173–74



involuntary actions, 105–6



Inzlicht, M., 227n40



Iraq, 122, 202–3n19



is/ought distinction, 38, 42, 196n13, 203–4nn 21–22



Islam:



British Muslims, 90, 212n60



and Danish cartoon controversy, 74–75, 179



liberal view of threat of, 90



martyrdom and jihad in, 23, 63, 74, 155–56



punishment of apostates and, 74–75, 90



Qur’an and, 78, 89



socioeconomic status of radicals, 231n8



war against radical Islam, 5, 202–3n19 See also religion



Israeli kibbutzim, 73



jealousy, 50–53



Jeffries, Jim, 178



Johnson, Jack, 178



Jost, John, 124–25



Joyce, Richard, 207–8n19



Judaism. See religion



justice, 78–80, 106, 109, 110–11, 135–36, 209n42. See also criminal justice
system



Kahneman, Daniel, 75, 184–87, 208n25



Kant, Immanuel, 81–82, 199n10, 204n24, 210n45, 210n49



Kaplan, Jonas T., 153



Kapogiannis, D., 233n48



Kiehl, Kent, 215n90



kin selection, 56, 57



kindness, 8, 38, 80



Kirshenbaum, Sheril, 174–76



knowledge, 11, 31, 115, 116, 123–24, 127–31, 196–97n22, 203n19. See also facts



Konner, Mel, 205n28



Kroto, Harold, 23



Ku Klux Klan, 41, 178. See also race and racism



language, 114–15, 131, 151, 159, 212n58, 218n1, 218n5, 219nn 7–8



The Language of God (Collins), 160–73



legal system. See criminal justice system; justice



Lewis, C. S., 162–63



liberals. See secular liberals



libertarianism, 217n111



Libet, Benjamin, 103, 215n97



lie detection, 44, 133–36, 206n37, 229–30n66, 230–31n69



loss aversion, 75–77, 209n35



Mackie, J. L., 198n4



Manson, Charles, 162



Mao Zedong, 23



Marr, David, 220n17



martyrdom, 23, 63, 74, 155



Marx, Karl, 145



mathematics, 235–36n76



McGonigal, Jane, 208n27



Mead, Margaret, 20



medications, 83, 84, 110, 230n66



medicine, 36, 37, 47, 77, 143, 184, 202n17, 231n75. See also health



memes, 20–21



memory, 116, 212n71, 234n54



Mill, John Stuart, 5, 199n10, 207n12



Miller, Geoffrey, 56



Miller, Kenneth, 173, 237n97



Miller, William Ian, 215n93



mind, 83–85, 110, 119, 158–59, 180. See also brain science; brain structures;
theory of mind



misogyny, 43, 196n9



Moll, Jorge, 91–92, 212n64, 213n78



Monty Hall Problem, 86, 211–12n54



Mooney, Chris, 174–76



Moore, G. E., 10, 12, 196n16



moral brain, 91–95



moral experts, 36, 198n6, 202n17



moral landscape:



Bad Life and Good Life in, 15–21, 38–42



facts and values in, 10–14



flawed conceptions of morality and, 53



importance of belief and, 14



meaning of, 7–10



moral progress and, 177–79, 188, 191



problem of religion and, 2, 22–25



suffering and, 21–22 See also morality; values; and headings beginning with
moral

moral law, 33, 38, 161, 169–70



moral paradox, 67–77



moral persuasion, 49–50



moral philosophy, 81–82, 197–98n1, 199n10, 225n35. See also specific
philosophers



moral realism, 62, 64–67



moral relativism, 27, 36, 45–46, 191, 204n21, 205n28



moral responsibility, 106–12, 216–17n109



moral science, 46–53



moral truth:



answers in practice and answers in principle for, 3, 30–31, 60, 191



consensus and, 31–32, 34



difficulties in discussion of, 27–38



disagreements concerning, 35–37



Hume’s is/ought distinction, 38, 42, 196n13



moral blindness in name of tolerance, 42–46



moral controversy and nullification of possibility of, 85–86



objectivity versus subjectivity and, 29–31, 198n4



religion and, 2, 33, 46, 62–63, 78, 146, 191



scientific context for, 1–4, 28, 46–53



scientists’ reluctance to take stand on, 6–7, 10–11, 22–25, 191



well-being related to, 1–4, 6, 28, 32–37, 87, 203–4n21



and worst possible misery for everyone, 38–42, 204n22



morality:



brain regions affecting moral cognition, 91–95



chess compared with, 8, 207n17



contractual versus beehive approaches to, 89



evil and, 100–102



evolutionary origins of, 50–53



Greene on, 64–66, 208n20



Haidt on, 85–91, 180–81



illusion of free will and, 102–6, 110–12, 215n97, 216n102, 216–17n102



inaccuracy of intuitive morality, 36



interchangeability of perspective and, 80–81



intractability of disagreements on, 87–88



liberal notions of, 86–87



loss aversion and, 75–77, 209n35



motivation for, 91–92



norms of, 80–82



peak/end rule and, 77



personal versus impersonal moral dilemmas, 93–95, 213–14n79



principles versus universal conception of, 8



recent development of, 59



religion and, 2, 33, 46, 62–63, 78, 146, 191



right and wrong answers about well-being, 64–67



scientific context for, 1–4, 11, 28, 46–53, 80



universal foundation of, 190–91



well-being and moral hierarchy across human societies, 60–62



well-being related to, 1–4, 6, 28, 32–37, 87, 203–4n21 See also evil;
good/goodness; moral landscape; moral truth; values; and headings beginning
with moral



motivation, 91–92, 126, 227n44



MRI. See neuroimaging research



multicultural epistemology, 47–48



murder, 1, 18–19, 34, 107–8, 108, 110–11, 133, 135–36, 158, 177–78, 205n24. See
also violence



Muslims. See Islam



Nash, John, 205n24



National Academy of Sciences, 6, 134, 157–58, 238n99



National Institutes of Health (NIH), 6, 153, 160–62, 173, 237n96



National Research Council, 134



natural selection, 13–14, 48–49, 147–48, 149. See also evolution



naturalistic fallacy, 10



Nature (journal), 6, 137, 163–64, 168–69, 237–38n99



Nazism, 23, 35, 47, 81



Neanderthals, 114, 218–19n5



neuroeconomics, 229n61



neuroethics, 206n37



neuroimaging research:



on awareness of conscious decisions, 103



on belief, disbelief, and uncertainty, 120–22, 126, 133, 152–54, 225–26n35,
229n62, 233nn48–49



on cooperation, 92, 189



on deception, 229–30n66



functional magnetic resonance imaging (fMRI), 75, 103, 120–22, 126, 127, 153,
215n90, 220–21n18, 229n62



lie detection and, 44, 135, 230–31n69



limitations of, 220–21n18, 222n22, 230–31n69



on loss aversion, 75



on morality, 64



multivariate approach to, 229n62



neuroeconomics and, 229n61



neuroethics of, 206n37



on placebo effect, 230n66



on psychopathy, 97–98, 215n90



on reasoning, 132, 228–29n61



on religion, 152–54, 233nn48–49



reverse inference problem in, 212n71, 224n34



violence and medial prefrontal cortex tumor, 107



See also brain science; brain structures



neuroscience. See brain science; brain structures



New Atheists, 174–75



New Guinea, 110–11



NIH. See National Institutes of Health (NIH)



non-cognitivism, 225n35



norepinephrine, 226n35



Nozick, Robert, 210–11n50



nutrition. See food



Obama, Barack, 43, 160, 172



objectivity, 11, 29–31, 30–31, 47, 48, 198n4



obsessive-compulsive disorder (OCD), 127, 152, 226n35



open question argument, 10, 12



ought, 38, 42, 196n13, 203nn 21–22



out-group versus in-group, 90, 101–2



oxytocin, 9, 44, 205n26



paradox. See moral paradox



Parfit, Derek, 71–72, 208n29, 208–9n30



Paul, Gregory, 146, 147



PCL-R. See Psychopathy Checklist—Revised (PCL-R)



peak/end rule, 77, 184



permanent defection orientation, 99–100



philosophy, 62, 179–81. See also moral philosophy; and specific philosophers



physicalism, 179–80



physics, 36, 48, 53, 87, 130, 179



Pinker, Steven, 13, 46, 197n28, 215n93



Pizarro, D. A., 209n36



Platonic Form of the Good, 30



Poldrack, R. A., 209n35, 212n71



political conservatives, 124–25



Polkinghorne, John, 166



polygraphy, 134. See also lie detection



Popper, Karl, 10



Popular Religiosity Versus Secularism Scale, 146



population ethics, 68–71



pornography, 90, 95–96



positive psychology, 181–84



positive test strategy, 223n26



prayer. See religion



preference reversal, 211n51



President’s Commission for the Study of Bioethical Issues, 43



President’s Council on Bioethics, 23, 197n28



prisons, 109, 212–13n75



propositional knowledge, 116, 196–97n22



psychiatric hospitals, 141–42



psychology, 77, 82, 140–42, 145, 147, 151, 181–84. See also specific
psychologists



psychopathy, 18–19, 95–100, 108, 204–5n24, 212–14nn 75–79, 214n87, 214–15nn
89–90



Psychopathy Checklist—Revised (PCL-R), 97



punishment:



in afterlife, 18



altruistic punishment, 92



of apostates in Islam, 74–75, 90



capital punishment, 128, 136



corporal punishment, 3, 214n88



retributive justice and, 1, 106, 109, 110–11



Putnam, Hilary, 202n16



quantum mechanics, 124, 179, 215–16n101



race and racism, 45, 47, 53, 79, 146, 177–79, 235n69



randomness, 130–31



rape, 35, 43, 95–96, 199–201n14, 232n19



rational materialism, 128



rationality. See reasoning



Rawls, John, 77, 78–81, 208n29, 209n42, 210n46



reactive aggression, 213n78, 215n90



reasoning:



analogical reasoning, 227n57



belief and, 122, 131–33



biases in, 132, 142–43



emotion and, 126–31



induction versus deduction, 131–32, 227n57



motivated reasoning, 227n44



neuroimaging research on, 132, 228–29n61



religious faith versus, 158–76



syllogistic reasoning, 228n61



systematic errors in, 123



reciprocal altruism, 56, 57, 92



relativism. See cultural relativism; moral relativism



religion:



afterlife and, 18, 33



belief in God’s existence, 6–7, 25, 158, 159, 165–66



belief in Jesus, 137–38



brain science and, 128, 152–54, 232n37, 233nn 48–49, 234n54



Burton on, 129



children and, 151



cognitive templates for, 150–51



corporal punishment in schools and, 3



Einstein on, 202n18, 236n77



in Europe, 145–46



evolution and, 147–52



God as Creator, 164



Golden Rule and, 78, 209n45



happiness from, 231–32n15



industrialization and, 145



Jesus as Son of God, 162–63, 167–68



of Judaism, 33, 38



miracles and, 167–68, 237n82



moral law and, 33, 38, 161, 169–70



morality and, 2, 33, 46, 62–63, 78, 146, 191



mysticism and, 128, 235n76



prayer and, 148, 152, 168



problems of, 6, 22–25, 157, 203n19, 227n45



prophecies and, 154–55



reason versus, 158–76



religious practices, 148–49



resurrection of the dead, 166–67



revelation and, 78



science versus, 6, 24–25



scientists’ belief in, 159–76, 237–38n99



scriptures of, 78, 89, 150, 236–37n82



sexual abuse scandal in Catholic Church, 35, 199–201n14



significance of, 154–58, 199n9



social health of least religious countries, 146–47



societal insecurity and, 146–47



soul and, 110, 158–59, 171, 179, 235n66



states of mind at core of, 165



in United States, 145–47, 149–50, 158, 234–35n64



witchcraft compared with, 129–30 See also Catholic Church; Islam



religious conservatives, 5–6, 46, 53, 86, 89, 90, 158, 180–81



remembering self, 184–87



Repugnant Conclusion argument, 71



responsibility. See moral responsibility



retributive justice, 1, 106, 109, 110–11



reverse inference problem, 212n71, 224n34



right and wrong. See evil; good/goodness; morality; values



risk and risk tolerance, 128, 143, 226n35



Rosenhan, David L., 141–42



Ruse, Michael, 48



Rushdie, Salman, 46



Russell, Bertrand, 78



Sai Baba, Sathya, 167–68



Salk Institute, 23–24



sanity, legal definition of, 98



Savoy, R. L., 229n62



schadenfreude, 113, 222n18



schizophrenia, 127, 142, 152, 162, 195n3, 205n24



Schrödinger, Erwin, 213n77



science:



belief and, 144



bias of, 47–48



concessions made to religious dogmatism by, 5–6, 22–23



consensus versus controversy in, 31, 198n6



“consilience” in, 8



definition of, 37



doubts about authority of, 47–48



Einstein on religion and, 202n18, 236n77



epistemic values of, 202n16



funding for, 24



growth of scientific knowledge, 124



hostility against, by general public and governments, 24



humility of scientists, 124



hypothesis testing in, 116



moral truth and, 1–4, 28, 46–53



narrow definition of, 29



objectivity and, 29–30, 47, 48



philosophy and, 179–81



religion versus, 6, 24–25



religious beliefs of scientists, 159–76, 237–38n99



reluctance of, to take stand on moral issues, 6–7, 10–11, 22–25, 191



tools of, 29



validity in, 143–44



values and, 1–4, 11, 28, 49–53, 143–44, 189–91, 202n16 See also brain science;
brain structures; facts; neuroimaging research; and specific scientists



scientism, 46–47



SCNT. See somatic-cell nuclear transfer (SCNT)



Scripps Survey Research Center, 88



Searle, John, 29



secular liberals, 5–6, 46, 86–87, 89, 90, 125–26, 180–81



self-defeating behaviors, 82–85, 211n51



selfishness, 56, 57–59, 82, 83, 91–92, 97



sensory discrimination, 228–29n61



serotonin, 152, 232n37



sexism. See women



sexual abuse scandal in Catholic Church, 35, 199–201n14



sexual selection, 56, 57



Shadlen, M. N., 228n61



Sheldrake, Rupert, 169



Shweder, Richard A., 205n28



sins, 77, 106. See also evil



slavery, 87



Slovic, Paul, 69, 208n25



Smith, Adam, 57–59



social-intuitionist model, 85–88



socially constructed phenomena, 198



socioeconomic inequality, 24–25, 146, 231n8



sociopathy, 95, 213n78. See also psychopathy



Sokal, Alan, 167, 236n81



somatic-cell nuclear transfer (SCNT), 172–73



soul, 110, 158–59, 171, 179, 235n66



speech. See language



Spence, S. A., 229n66



Spinoza, B. S. F., 120



Stanovich, K. E., 227n38



Stark, Rodney, 148



subjective well-being (SWB), 231–32n15. See also well-being



subjectivity, 29–31, 77, 112, 159



Successful Societies Scale, 146



suffering:



of animals, 63, 171, 198–99n8, 210–11n50, 214n88



goodness of, 21–22



of homeless, 70–71



identifiable victim effect and, 69



injustice and, 80



lack of concern for, 63, 69–70, 208nn 25–26



from misunderstanding emphasis on human well-being, 199n11



reduction of memory of, 77



See also psychopathy



suicide, 182. See also martyrdom



supersense, 151



Supreme Court, 106, 135



SWB. See subjective well-being (SWB)



Symons, Donald, 46



synesthete, 131



Taliban, 36–37, 42, 43



Tanzania, 156–57



TED conference, 197n1, 204n24



Temperament and Character Inventory, 232n37



Templeton Foundation, 24, 169



teratoma, 172



terrorism, 23, 88–89, 133. See also Islam



theft prevention, 206n1



theory of mind, 98–99



Thompson, J. J., 212n67



Three Mile Island Effect, 68



tit for tat orientation, 99



tolerance of moral difference, 42–46



Tom, S. M., 209n35



Tomasello, Michael, 57



Trepel, C., 209n35



Trivers, Robert, 56



truth. See belief; facts; lie detection; moral truth



truth bias, 120, 223n26



“Twinkie defense,” 217n109



Uhlmann, E. L., 209n36



uncertainty, 120–22, 127, 154, 225–26n35



unconscious, 122–23, 128–29



unpleasant surprise principle, 81



Unscientific America (Mooney and Kirshenbaum), 174–76



utility theory, 211n51



values:



beliefs about, 14



consciousness and, 32–33, 41–42, 62



definition of, 12



evolutionary account of, 13



facts and, 4, 10–14, 24, 122, 143–44



knowledge and, 31



Mackie on objective values, 198n4



personal versus collective well-being, 42, 187–88



possibility of wrong values, 21



religious conservatives versus secular liberals on, 5–6



science and, 1–4, 11, 28, 49–53, 143–44, 189–91, 202n16



tolerance and, 42–46



well-being related to, 1–4, 6, 28, 32–37 See also evil; good/goodness; moral
landscape; moral truth; morality



vasopressin, 9



vengeance, 1, 110–11, 215n93



violence, 100–101, 107–8, 177–78, 213n75. See also aggression; murder



voluntary actions, 105–6



Warren, Rick, 198n2



wars, 101, 122, 177, 202–3n19, 215n93, 219n7, 227n38



Watson, James D., 47, 235n69



Weber, Max, 145



Weinberg, Steven, 23, 48



well-being:



affective forecasting and, 183–84



of animals, 41–42, 198–99n8, 210–11n50



Aristotle on, 195n9



Bad Life versus Good Life, 15–21, 38–42, 195–96n9



caring about others’ well-being, 40, 57–59, 82, 83



change in, and natural laws, 12–13



consciousness and, 32–33, 41–42, 62



definition of, 11–12, 12, 39



disagreements concerning, 35–37



early childhood experience and, 9–10



and equal value of all human lives, 199n8



evolution and, 13



experiencing self and remembering self, 184–87



fairness and, 77–82, 209n42



future of happiness, 177–91



of individuals and global humanity, 33–34



justice and, 78–79



kindness and, 8, 38, 80



knowledge and, 203n19



maximization of, for self and others, 82–85



mental states and capacities influencing, 64



misunderstanding of emphasis of, 199n11



moral hierarchy of, across human societies, 60–62



morality and values related to, 1–4, 6, 28, 32–37, 87, 203–4n21



personal versus collective well-being, 42, 187–88



positive psychology on, 181–84



problems with concept of, 38–39



questions on, 34



rational understanding and scientific study of, 6, 7, 11, 41–42



religion and, 199n9



right and wrong answers about, 64–67



subjective well-being (SWB), 231–32n15



trade-offs regarding and exceptions to, 199n12



worst possible misery for everyone versus, 38–42, 204n22 See also
good/goodness; moral landscape; morality; values



West, R. F., 227n38



Westen, Drew, 227n44



Westergaard, Kurt, 74



Willingham, Cameron Todd, 136



Wilson, E. O., 48



witchcraft, 129–30



Wittgenstein, Ludwig, 131



women:



antisocial behavior and, 215n89



bride burning, 42



burqas for and veiling of, 27, 42, 42–45, 65, 74, 196n9, 207n17



forced marriage of, 42, 43



genital mutilation of females, 27, 42, 46



health issues of, 47



as priests, 34–35



as property of men, 50, 207n17



Taliban’s goals regarding, 37



See also rape



World Values Survey, 231–32n15



worst possible misery for everyone, 38–42, 204n22



Wright, N. T., 166



Zaidel, E., 216n104





ABOUT THE AUTHOR





Sam Harris is the author of the New York Times bestsellers The End of Faith and
Letter to a Christian Nation. The End of Faith won the 2005 PEN Award for
Nonfiction. His writing has been published in over fifteen languages. He and
his work have been discussed in Newsweek, TIME, The New York Times, Scientific
American, Nature, Rolling Stone, and many other publications. His writing has
appeared in Newsweek, The New York Times, the Los Angeles Times, The Times
(London), the Boston Globe, The Atlantic, Annals of Neurology, and elsewhere.
Dr. Harris is cofounder and CEO of Project Reason, a nonprofit foundation
devoted to spreading scientific knowledge and secular values in society. He
received a degree in philosophy from Stanford University and a PhD in
neuroscience from UCLA. His website is www.samharris.org.

